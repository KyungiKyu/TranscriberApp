2024-01-19 12:55:22,153 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-19 12:55:22,155 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-19 12:55:22,403 INFO transcription All nescessary class variables are declared and working!
2024-01-19 12:56:15,461 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-19 12:56:15,463 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-19 12:56:15,697 INFO transcription All nescessary class variables are declared and working!
2024-01-19 12:57:31,345 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-19 12:57:31,346 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-19 12:57:31,570 INFO transcription All nescessary class variables are declared and working!
2024-01-19 12:57:43,811 INFO __main__ Error: File could not be copied.
2024-01-19 12:58:33,424 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-19 12:58:33,426 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-19 12:58:33,657 INFO transcription All nescessary class variables are declared and working!
2024-01-19 12:58:46,629 INFO __main__ Error: File could not be copied.
2024-01-19 12:59:10,494 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\DATA\\test\\test.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-19 12:59:10,524 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-19 12:59:10,612 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B985A361D0>
2024-01-19 12:59:10,612 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B9FBD80320> server_hostname='api.openai.com' timeout=5.0
2024-01-19 12:59:10,634 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B985A36B10>
2024-01-19 12:59:10,634 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-19 12:59:10,634 DEBUG httpcore.http11 send_request_headers.complete
2024-01-19 12:59:10,635 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-19 12:59:10,784 DEBUG httpcore.http11 send_request_body.complete
2024-01-19 12:59:10,784 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-19 12:59:12,066 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 19 Jan 2024 11:59:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'487'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1ec77b304822d334b020a8a6301b7902'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=FY5WYhMUCjhse__g9JdZfm0feXHkBrrs59mRUskZjJ0-1705665547-1-AYDkhdsinOnCEAU9Pe4c9Vz2z5NM9lKOKtuT/HNGAtYzflXAly6rtRFkBGf5V1PTur4zSSQqsL/ocyr1lkbQUkE=; path=/; expires=Fri, 19-Jan-24 12:29:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=pKKYdOPrZjt04wPmjTZD_qwLDZNaPFUwM.S0DdUUopg-1705665547449-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'847ee8deb8f15b9e-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-19 12:59:12,068 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-19 12:59:12,068 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-19 12:59:12,068 DEBUG httpcore.http11 receive_response_body.complete
2024-01-19 12:59:12,068 DEBUG httpcore.http11 response_closed.started
2024-01-19 12:59:12,068 DEBUG httpcore.http11 response_closed.complete
2024-01-19 12:59:12,069 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-19 12:59:12,079 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \nVersuchen wir es einfach nochmal. Test, Test, Test, Test, Test. Juckt ja jetzt kein, ähm, joa.'}], 'model': 'gpt-4'}}
2024-01-19 12:59:12,086 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \nVersuchen wir es einfach nochmal. Test, Test, Test, Test, Test. Juckt ja jetzt kein, ähm, joa.'}], 'model': 'gpt-4'}}
2024-01-19 12:59:12,087 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-19 12:59:12,087 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-19 12:59:12,088 DEBUG httpcore.http11 send_request_headers.complete
2024-01-19 12:59:12,088 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-19 12:59:12,088 DEBUG httpcore.http11 send_request_body.complete
2024-01-19 12:59:12,088 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-19 12:59:12,108 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B985A6EFD0>
2024-01-19 12:59:12,108 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B9FBD80320> server_hostname='api.openai.com' timeout=5.0
2024-01-19 12:59:12,133 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B985A6F3D0>
2024-01-19 12:59:12,133 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-19 12:59:12,134 DEBUG httpcore.http11 send_request_headers.complete
2024-01-19 12:59:12,134 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-19 12:59:12,134 DEBUG httpcore.http11 send_request_body.complete
2024-01-19 12:59:12,134 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-19 12:59:15,715 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 19 Jan 2024 11:59:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'3426'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9856'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'864ms'), (b'x-request-id', b'f446ca821950b0e4d4e99bc45cdb702f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'847ee8e7cf4e5b9e-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-19 12:59:15,716 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-19 12:59:15,716 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-19 12:59:15,717 DEBUG httpcore.http11 receive_response_body.complete
2024-01-19 12:59:15,717 DEBUG httpcore.http11 response_closed.started
2024-01-19 12:59:15,717 DEBUG httpcore.http11 response_closed.complete
2024-01-19 12:59:15,717 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-19 12:59:19,174 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 19 Jan 2024 11:59:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'6783'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'9758'), (b'x-ratelimit-reset-requests', b'17.178s'), (b'x-ratelimit-reset-tokens', b'1.446s'), (b'x-request-id', b'7177ba2aa3d6535885e0c29f89ec01a9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'847ee8e81f755d48-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-19 12:59:19,175 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-19 12:59:19,175 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-19 12:59:19,175 DEBUG httpcore.http11 receive_response_body.complete
2024-01-19 12:59:19,175 DEBUG httpcore.http11 response_closed.started
2024-01-19 12:59:19,175 DEBUG httpcore.http11 response_closed.complete
2024-01-19 12:59:19,176 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-19 13:02:01,667 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-19 13:02:01,668 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-19 13:02:01,904 INFO transcription All nescessary class variables are declared and working!
2024-01-19 13:02:17,653 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-19 13:02:17,655 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-19 13:02:17,910 INFO transcription All nescessary class variables are declared and working!
2024-01-19 13:02:27,141 INFO __main__ Error: File could not be copied.
2024-01-19 13:02:51,465 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-19 13:02:51,467 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-19 13:02:51,717 INFO transcription All nescessary class variables are declared and working!
2024-01-19 13:03:08,455 INFO __main__ Error: File could not be copied.
2024-01-19 13:04:40,181 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-19 13:04:40,183 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-19 13:04:40,415 INFO transcription All nescessary class variables are declared and working!
2024-01-19 13:04:48,733 INFO __main__ Error: File could not be copied.
2024-01-19 13:11:18,790 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-19 13:11:18,792 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-19 13:11:19,018 INFO transcription All nescessary class variables are declared and working!
2024-01-19 13:11:52,218 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-19 13:11:52,219 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-19 13:11:52,446 INFO transcription All nescessary class variables are declared and working!
2024-01-19 13:13:01,265 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-19 13:13:01,266 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-19 13:13:01,504 INFO transcription All nescessary class variables are declared and working!
2024-01-19 13:15:01,517 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-19 13:15:01,519 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-19 13:15:01,761 INFO transcription All nescessary class variables are declared and working!
2024-01-19 13:16:09,875 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-19 13:16:09,876 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-19 13:16:10,108 INFO transcription All nescessary class variables are declared and working!
2024-01-19 13:18:46,540 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-19 13:18:46,542 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-19 13:18:46,771 INFO transcription All nescessary class variables are declared and working!
2024-01-19 13:18:57,590 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-19 13:18:57,591 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-19 13:18:57,839 INFO transcription All nescessary class variables are declared and working!
2024-01-19 13:19:47,576 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-19 13:19:47,578 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-19 13:19:47,802 INFO transcription All nescessary class variables are declared and working!
2024-01-19 13:21:15,602 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-19 13:21:15,604 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-19 13:21:15,829 INFO transcription All nescessary class variables are declared and working!
2024-01-19 13:22:20,473 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\DATA\\JP Performance - Ihr fragt, ich antworte!\\JP Performance - Ihr fragt, ich antworte! .mp4'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-19 13:22:20,502 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-19 13:22:20,586 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000260FA4EBED0>
2024-01-19 13:22:20,586 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000260F9A50320> server_hostname='api.openai.com' timeout=5.0
2024-01-19 13:22:20,603 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000260FA4EB310>
2024-01-19 13:22:20,604 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-19 13:22:20,604 DEBUG httpcore.http11 send_request_headers.complete
2024-01-19 13:22:20,604 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-19 13:23:16,685 DEBUG httpcore.http11 send_request_body.complete
2024-01-19 13:23:16,685 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-19 13:23:23,222 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Fri, 19 Jan 2024 12:23:18 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'520'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0b2bf585332e582c1f3e301d831da009'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=lLk_VE6k7jIeTJxVGNHP6B_G7Na9gQExcq6jsOkERAw-1705666998-1-Af9lvrrVMeDGWQyye7UPWMJxFO+Mfugp9/lImlgHDkEUjPcLq4FuZDR02xIDxjGP1iN+AazTDnEKwi1V1NnFs6M=; path=/; expires=Fri, 19-Jan-24 12:53:18 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Kzqiu8.ruvL94cQn_TMVWBphrT1Z5HD3GzzWBWctbAM-1705666998577-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'847f0acddc292c35-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-19 13:23:23,223 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-19 13:23:23,223 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-19 13:23:23,224 DEBUG httpcore.http11 receive_response_body.complete
2024-01-19 13:23:23,224 DEBUG httpcore.http11 response_closed.started
2024-01-19 13:23:23,224 DEBUG httpcore.http11 response_closed.complete
2024-01-19 13:23:23,224 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-19 13:23:23,224 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-19 13:23:23,243 DEBUG openai._base_client Not retrying
2024-01-19 13:23:23,243 DEBUG openai._base_client Re-raising status error
2024-01-20 11:04:49,924 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 11:04:49,939 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 11:04:50,249 INFO transcription All nescessary class variables are declared and working!
2024-01-20 11:07:37,181 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\DATA\\videoplayback (1)\\videoplayback (1).mp3'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 11:07:37,210 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 11:07:37,297 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000255F9DCAF50>
2024-01-20 11:07:37,297 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000255F9210320> server_hostname='api.openai.com' timeout=5.0
2024-01-20 11:07:37,321 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025581577690>
2024-01-20 11:07:37,323 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 11:07:37,323 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 11:07:37,323 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 11:08:04,956 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 11:08:04,956 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 11:08:08,792 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 10:08:07 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'561'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5f96930762511cef3024da276261d0df'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=V7BwA1uQaHh9pwquK1W.pQEepGMIoxKw0g5wLbj3NpY-1705745287-1-ATEYfStRPfttVS8ViiNwzSLr82a9KJkilaIjTxbey1cHf76YJ2NVLsdlBEbtRm08QeWG8tAoAF2uLYYCHzR+LlU=; path=/; expires=Sat, 20-Jan-24 10:38:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=oUWruPSAE1452DNgEeePglHQJ00ObvzsJfK.ist1QU0-1705745287661-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848682eb49e9995d-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 11:08:08,793 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 11:08:08,794 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 11:08:08,794 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 11:08:08,794 DEBUG httpcore.http11 response_closed.started
2024-01-20 11:08:08,794 DEBUG httpcore.http11 response_closed.complete
2024-01-20 11:08:08,794 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 11:08:08,794 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 11:08:08,811 DEBUG openai._base_client Not retrying
2024-01-20 11:08:08,811 DEBUG openai._base_client Re-raising status error
2024-01-20 11:44:30,349 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 11:44:30,351 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 11:44:30,580 INFO transcription All nescessary class variables are declared and working!
2024-01-20 11:44:36,590 INFO transcription Current recording SessionID is: 51f7c8953d85493ebff322d6e4dbfbd3
2024-01-20 11:44:36,591 INFO transcription Started Microphone Thread for session 51f7c8953d85493ebff322d6e4dbfbd3!
2024-01-20 11:44:36,592 INFO transcription Opening Stream for device Microsoft Sound Mapper - Input...
2024-01-20 11:44:36,592 INFO transcription Started System sounds Thread for session 51f7c8953d85493ebff322d6e4dbfbd3!
2024-01-20 11:44:36,593 INFO transcription Opening Stream for device Stereo Mix (Realtek USB Audio)...
2024-01-20 11:44:36,608 INFO transcription Stream for Microphone Microsoft Sound Mapper - Input open!
2024-01-20 11:44:36,669 INFO transcription Stream for Microphone Stereo Mix (Realtek USB Audio) open!
2024-01-20 11:45:15,950 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1135)
           2	RESUME(arg=0, lineno=1135)
           4	LOAD_FAST(arg=0, lineno=1138)
           6	LOAD_CONST(arg=1, lineno=1138)
           8	BINARY_SUBSCR(arg=None, lineno=1138)
          18	STORE_FAST(arg=3, lineno=1138)
          20	LOAD_FAST(arg=1, lineno=1139)
          22	UNARY_NEGATIVE(arg=None, lineno=1139)
          24	LOAD_FAST(arg=3, lineno=1139)
          26	SWAP(arg=2, lineno=1139)
          28	COPY(arg=2, lineno=1139)
          30	COMPARE_OP(arg=1, lineno=1139)
          36	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
          38	LOAD_FAST(arg=1, lineno=1139)
          40	COMPARE_OP(arg=1, lineno=1139)
          46	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
          48	JUMP_FORWARD(arg=2, lineno=1139)
>         50	POP_TOP(arg=None, lineno=1139)
          52	JUMP_FORWARD(arg=2, lineno=1139)
>         54	LOAD_CONST(arg=1, lineno=1140)
          56	STORE_FAST(arg=3, lineno=1140)
>         58	LOAD_FAST(arg=0, lineno=1142)
          60	LOAD_CONST(arg=2, lineno=1142)
          62	BINARY_SUBSCR(arg=None, lineno=1142)
          72	STORE_FAST(arg=4, lineno=1142)
          74	LOAD_FAST(arg=1, lineno=1143)
          76	UNARY_NEGATIVE(arg=None, lineno=1143)
          78	LOAD_FAST(arg=4, lineno=1143)
          80	SWAP(arg=2, lineno=1143)
          82	COPY(arg=2, lineno=1143)
          84	COMPARE_OP(arg=1, lineno=1143)
          90	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
          92	LOAD_FAST(arg=1, lineno=1143)
          94	COMPARE_OP(arg=1, lineno=1143)
         100	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
         102	JUMP_FORWARD(arg=2, lineno=1143)
>        104	POP_TOP(arg=None, lineno=1143)
         106	JUMP_FORWARD(arg=2, lineno=1143)
>        108	LOAD_CONST(arg=1, lineno=1144)
         110	STORE_FAST(arg=4, lineno=1144)
>        112	LOAD_FAST(arg=2, lineno=1146)
         114	POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
         116	LOAD_GLOBAL(arg=1, lineno=1147)
         128	LOAD_ATTR(arg=1, lineno=1147)
         138	LOAD_FAST(arg=3, lineno=1147)
         140	PRECALL(arg=1, lineno=1147)
         144	CALL(arg=1, lineno=1147)
         154	LOAD_GLOBAL(arg=1, lineno=1147)
         166	LOAD_ATTR(arg=1, lineno=1147)
         176	LOAD_FAST(arg=4, lineno=1147)
         178	PRECALL(arg=1, lineno=1147)
         182	CALL(arg=1, lineno=1147)
         192	COMPARE_OP(arg=3, lineno=1147)
         198	RETURN_VALUE(arg=None, lineno=1147)
>        200	LOAD_GLOBAL(arg=1, lineno=1149)
         212	LOAD_ATTR(arg=2, lineno=1149)
         222	LOAD_FAST(arg=3, lineno=1149)
         224	PRECALL(arg=1, lineno=1149)
         228	CALL(arg=1, lineno=1149)
         238	LOAD_GLOBAL(arg=1, lineno=1149)
         250	LOAD_ATTR(arg=2, lineno=1149)
         260	LOAD_FAST(arg=4, lineno=1149)
         262	PRECALL(arg=1, lineno=1149)
         266	CALL(arg=1, lineno=1149)
         276	COMPARE_OP(arg=3, lineno=1149)
         282	RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow stack: []
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1135)
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow stack []
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1135)
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow stack []
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1138)
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow stack []
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1138)
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1138)
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow dispatch pc=18, inst=STORE_FAST(arg=3, lineno=1138)
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow stack []
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow dispatch pc=22, inst=UNARY_NEGATIVE(arg=None, lineno=1139)
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow stack ['$threshold20.3']
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow dispatch pc=24, inst=LOAD_FAST(arg=3, lineno=1139)
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow stack ['$22unary_negative.4']
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow dispatch pc=26, inst=SWAP(arg=2, lineno=1139)
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow stack ['$22unary_negative.4', '$x024.5']
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow dispatch pc=28, inst=COPY(arg=2, lineno=1139)
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4']
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow dispatch pc=30, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4', '$x024.5']
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow dispatch pc=36, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow stack ['$x024.5', '$30compare_op.6']
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow end state. edges=[Edge(pc=38, stack=('$x024.5',), blockstack=(), npush=0), Edge(pc=50, stack=('$x024.5',), blockstack=(), npush=0)]
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow pending: deque([State(pc_initial=38 nstack_initial=1), State(pc_initial=50 nstack_initial=1)])
2024-01-20 11:45:15,951 DEBUG numba.core.byteflow stack: ['$phi38.0']
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=38 nstack_initial=1)
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow stack ['$phi38.0']
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow dispatch pc=40, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow stack ['$phi38.0', '$threshold38.1']
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow dispatch pc=46, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow stack ['$40compare_op.2']
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow end state. edges=[Edge(pc=48, stack=(), blockstack=(), npush=0), Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow pending: deque([State(pc_initial=50 nstack_initial=1), State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow stack: ['$phi50.0']
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=50 nstack_initial=1)
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow dispatch pc=50, inst=POP_TOP(arg=None, lineno=1139)
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow stack ['$phi50.0']
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow dispatch pc=52, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow stack []
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow pending: deque([State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow stack: []
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=48 nstack_initial=0)
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow dispatch pc=48, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow stack []
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow end state. edges=[Edge(pc=54, stack=(), blockstack=(), npush=0)]
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0)])
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow stack: []
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=58 nstack_initial=0)
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow dispatch pc=58, inst=LOAD_FAST(arg=0, lineno=1142)
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow stack []
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow dispatch pc=60, inst=LOAD_CONST(arg=2, lineno=1142)
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow stack ['$x58.0']
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow dispatch pc=62, inst=BINARY_SUBSCR(arg=None, lineno=1142)
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow stack ['$x58.0', '$const60.1']
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow dispatch pc=72, inst=STORE_FAST(arg=4, lineno=1142)
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow stack ['$62binary_subscr.2']
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow dispatch pc=74, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow stack []
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow dispatch pc=76, inst=UNARY_NEGATIVE(arg=None, lineno=1143)
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow stack ['$threshold74.3']
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow dispatch pc=78, inst=LOAD_FAST(arg=4, lineno=1143)
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow stack ['$76unary_negative.4']
2024-01-20 11:45:15,952 DEBUG numba.core.byteflow dispatch pc=80, inst=SWAP(arg=2, lineno=1143)
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow stack ['$76unary_negative.4', '$x178.5']
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow dispatch pc=82, inst=COPY(arg=2, lineno=1143)
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4']
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow dispatch pc=84, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4', '$x178.5']
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow dispatch pc=90, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow stack ['$x178.5', '$84compare_op.6']
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow end state. edges=[Edge(pc=92, stack=('$x178.5',), blockstack=(), npush=0), Edge(pc=104, stack=('$x178.5',), blockstack=(), npush=0)]
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow pending: deque([State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow stack: []
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=54 nstack_initial=0)
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=1, lineno=1140)
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow stack []
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow dispatch pc=56, inst=STORE_FAST(arg=3, lineno=1140)
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow stack ['$const54.0']
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow pending: deque([State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0)])
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow stack: ['$phi92.0']
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=92 nstack_initial=1)
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow dispatch pc=92, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow stack ['$phi92.0']
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow dispatch pc=94, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow stack ['$phi92.0', '$threshold92.1']
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow dispatch pc=100, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow stack ['$94compare_op.2']
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow end state. edges=[Edge(pc=102, stack=(), blockstack=(), npush=0), Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow pending: deque([State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow stack: ['$phi104.0']
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=104 nstack_initial=1)
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow dispatch pc=104, inst=POP_TOP(arg=None, lineno=1143)
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow stack ['$phi104.0']
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow dispatch pc=106, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow stack []
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow stack: []
2024-01-20 11:45:15,953 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=102 nstack_initial=0)
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow dispatch pc=102, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow stack []
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow end state. edges=[Edge(pc=108, stack=(), blockstack=(), npush=0)]
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0)])
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow stack: []
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=112 nstack_initial=0)
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow dispatch pc=112, inst=LOAD_FAST(arg=2, lineno=1146)
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow stack []
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow dispatch pc=114, inst=POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow stack ['$zero_pos112.0']
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow end state. edges=[Edge(pc=116, stack=(), blockstack=(), npush=0), Edge(pc=200, stack=(), blockstack=(), npush=0)]
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow pending: deque([State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow stack: []
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=108 nstack_initial=0)
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow dispatch pc=108, inst=LOAD_CONST(arg=1, lineno=1144)
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow stack []
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow dispatch pc=110, inst=STORE_FAST(arg=4, lineno=1144)
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow stack ['$const108.0']
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow pending: deque([State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow stack: []
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=116 nstack_initial=0)
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow dispatch pc=116, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow stack []
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow dispatch pc=128, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow stack ['$null$116.1', '$116load_global.0']
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow dispatch pc=138, inst=LOAD_FAST(arg=3, lineno=1147)
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2']
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow dispatch pc=140, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow dispatch pc=144, inst=CALL(arg=1, lineno=1147)
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow dispatch pc=154, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow stack ['$144call.4']
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow dispatch pc=166, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$154load_global.5']
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow dispatch pc=176, inst=LOAD_FAST(arg=4, lineno=1147)
2024-01-20 11:45:15,954 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7']
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow dispatch pc=178, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow dispatch pc=182, inst=CALL(arg=1, lineno=1147)
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow dispatch pc=192, inst=COMPARE_OP(arg=3, lineno=1147)
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow stack ['$144call.4', '$182call.9']
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow dispatch pc=198, inst=RETURN_VALUE(arg=None, lineno=1147)
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow stack ['$192compare_op.10']
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow pending: deque([State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow stack: []
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=200 nstack_initial=0)
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow dispatch pc=200, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow stack []
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow dispatch pc=212, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow stack ['$null$200.1', '$200load_global.0']
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow dispatch pc=222, inst=LOAD_FAST(arg=3, lineno=1149)
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2']
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow dispatch pc=224, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow dispatch pc=228, inst=CALL(arg=1, lineno=1149)
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow dispatch pc=238, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow stack ['$228call.4']
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow dispatch pc=250, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$238load_global.5']
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow dispatch pc=260, inst=LOAD_FAST(arg=4, lineno=1149)
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7']
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow dispatch pc=262, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow dispatch pc=266, inst=CALL(arg=1, lineno=1149)
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow dispatch pc=276, inst=COMPARE_OP(arg=3, lineno=1149)
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow stack ['$228call.4', '$266call.9']
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow dispatch pc=282, inst=RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow stack ['$276compare_op.10']
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0)])
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=38 nstack_initial=1): {'$phi38.0'},
             State(pc_initial=48 nstack_initial=0): set(),
             State(pc_initial=50 nstack_initial=1): set(),
             State(pc_initial=54 nstack_initial=0): set(),
             State(pc_initial=58 nstack_initial=0): set(),
             State(pc_initial=92 nstack_initial=1): {'$phi92.0'},
             State(pc_initial=102 nstack_initial=0): set(),
             State(pc_initial=104 nstack_initial=1): set(),
             State(pc_initial=108 nstack_initial=0): set(),
             State(pc_initial=112 nstack_initial=0): set(),
             State(pc_initial=116 nstack_initial=0): set(),
             State(pc_initial=200 nstack_initial=0): set()})
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow defmap: {'$phi104.0': State(pc_initial=58 nstack_initial=0),
 '$phi38.0': State(pc_initial=0 nstack_initial=0),
 '$phi50.0': State(pc_initial=0 nstack_initial=0),
 '$phi92.0': State(pc_initial=58 nstack_initial=0)}
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 11:45:15,955 DEBUG numba.core.byteflow keep phismap: {'$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
 '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}}
2024-01-20 11:45:15,957 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi38.0': '$x024.5'},
             State(pc_initial=58 nstack_initial=0): {'$phi92.0': '$x178.5'}})
2024-01-20 11:45:15,957 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 11:45:15,957 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'value': '$8binary_subscr.2'}), (20, {'res': '$threshold20.3'}), (22, {'value': '$threshold20.3', 'res': '$22unary_negative.4'}), (24, {'res': '$x024.5'}), (30, {'lhs': '$22unary_negative.4', 'rhs': '$x024.5', 'res': '$30compare_op.6'}), (32, {}), (34, {}), (36, {'pred': '$30compare_op.6'})), outgoing_phis={'$phi38.0': '$x024.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={38: ('$x024.5',), 50: ('$x024.5',)})
2024-01-20 11:45:15,957 DEBUG numba.core.byteflow block_infos State(pc_initial=38 nstack_initial=1):
AdaptBlockInfo(insts=((38, {'res': '$threshold38.1'}), (40, {'lhs': '$phi38.0', 'rhs': '$threshold38.1', 'res': '$40compare_op.2'}), (42, {}), (44, {}), (46, {'pred': '$40compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={48: (), 58: ()})
2024-01-20 11:45:15,957 DEBUG numba.core.byteflow block_infos State(pc_initial=48 nstack_initial=0):
AdaptBlockInfo(insts=((48, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={54: ()})
2024-01-20 11:45:15,957 DEBUG numba.core.byteflow block_infos State(pc_initial=50 nstack_initial=1):
AdaptBlockInfo(insts=((52, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 11:45:15,957 DEBUG numba.core.byteflow block_infos State(pc_initial=54 nstack_initial=0):
AdaptBlockInfo(insts=((54, {'res': '$const54.0'}), (56, {'value': '$const54.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 11:45:15,957 DEBUG numba.core.byteflow block_infos State(pc_initial=58 nstack_initial=0):
AdaptBlockInfo(insts=((58, {'res': '$x58.0'}), (60, {'res': '$const60.1'}), (62, {'index': '$const60.1', 'target': '$x58.0', 'res': '$62binary_subscr.2'}), (64, {}), (66, {}), (68, {}), (70, {}), (72, {'value': '$62binary_subscr.2'}), (74, {'res': '$threshold74.3'}), (76, {'value': '$threshold74.3', 'res': '$76unary_negative.4'}), (78, {'res': '$x178.5'}), (84, {'lhs': '$76unary_negative.4', 'rhs': '$x178.5', 'res': '$84compare_op.6'}), (86, {}), (88, {}), (90, {'pred': '$84compare_op.6'})), outgoing_phis={'$phi92.0': '$x178.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={92: ('$x178.5',), 104: ('$x178.5',)})
2024-01-20 11:45:15,957 DEBUG numba.core.byteflow block_infos State(pc_initial=92 nstack_initial=1):
AdaptBlockInfo(insts=((92, {'res': '$threshold92.1'}), (94, {'lhs': '$phi92.0', 'rhs': '$threshold92.1', 'res': '$94compare_op.2'}), (96, {}), (98, {}), (100, {'pred': '$94compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={102: (), 112: ()})
2024-01-20 11:45:15,957 DEBUG numba.core.byteflow block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={108: ()})
2024-01-20 11:45:15,957 DEBUG numba.core.byteflow block_infos State(pc_initial=104 nstack_initial=1):
AdaptBlockInfo(insts=((106, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 11:45:15,957 DEBUG numba.core.byteflow block_infos State(pc_initial=108 nstack_initial=0):
AdaptBlockInfo(insts=((108, {'res': '$const108.0'}), (110, {'value': '$const108.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 11:45:15,957 DEBUG numba.core.byteflow block_infos State(pc_initial=112 nstack_initial=0):
AdaptBlockInfo(insts=((112, {'res': '$zero_pos112.0'}), (114, {'pred': '$zero_pos112.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={116: (), 200: ()})
2024-01-20 11:45:15,957 DEBUG numba.core.byteflow block_infos State(pc_initial=116 nstack_initial=0):
AdaptBlockInfo(insts=((116, {'idx': 0, 'res': '$116load_global.0'}), (118, {}), (120, {}), (122, {}), (124, {}), (126, {}), (128, {'item': '$116load_global.0', 'res': '$128load_attr.2'}), (130, {}), (132, {}), (134, {}), (136, {}), (138, {'res': '$x0138.3'}), (140, {}), (142, {}), (144, {'func': '$128load_attr.2', 'args': ['$x0138.3'], 'kw_names': None, 'res': '$144call.4'}), (146, {}), (148, {}), (150, {}), (152, {}), (154, {'idx': 0, 'res': '$154load_global.5'}), (156, {}), (158, {}), (160, {}), (162, {}), (164, {}), (166, {'item': '$154load_global.5', 'res': '$166load_attr.7'}), (168, {}), (170, {}), (172, {}), (174, {}), (176, {'res': '$x1176.8'}), (178, {}), (180, {}), (182, {'func': '$166load_attr.7', 'args': ['$x1176.8'], 'kw_names': None, 'res': '$182call.9'}), (184, {}), (186, {}), (188, {}), (190, {}), (192, {'lhs': '$144call.4', 'rhs': '$182call.9', 'res': '$192compare_op.10'}), (194, {}), (196, {}), (198, {'retval': '$192compare_op.10', 'castval': '$198return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 11:45:15,957 DEBUG numba.core.byteflow block_infos State(pc_initial=200 nstack_initial=0):
AdaptBlockInfo(insts=((200, {'idx': 0, 'res': '$200load_global.0'}), (202, {}), (204, {}), (206, {}), (208, {}), (210, {}), (212, {'item': '$200load_global.0', 'res': '$212load_attr.2'}), (214, {}), (216, {}), (218, {}), (220, {}), (222, {'res': '$x0222.3'}), (224, {}), (226, {}), (228, {'func': '$212load_attr.2', 'args': ['$x0222.3'], 'kw_names': None, 'res': '$228call.4'}), (230, {}), (232, {}), (234, {}), (236, {}), (238, {'idx': 0, 'res': '$238load_global.5'}), (240, {}), (242, {}), (244, {}), (246, {}), (248, {}), (250, {'item': '$238load_global.5', 'res': '$250load_attr.7'}), (252, {}), (254, {}), (256, {}), (258, {}), (260, {'res': '$x1260.8'}), (262, {}), (264, {}), (266, {'func': '$250load_attr.7', 'args': ['$x1260.8'], 'kw_names': None, 'res': '$266call.9'}), (268, {}), (270, {}), (272, {}), (274, {}), (276, {'lhs': '$228call.4', 'rhs': '$266call.9', 'res': '$276compare_op.10'}), (278, {}), (280, {}), (282, {'retval': '$276compare_op.10', 'castval': '$282return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 11:45:15,958 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const6.1 = const(int, 0)                ['$const6.1']
    x0 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$const6.1', 'x', 'x0']
    $22unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$22unary_negative.4', 'threshold']
    $30compare_op.6 = $22unary_negative.4 <= x0 ['$22unary_negative.4', '$30compare_op.6', 'x0']
    bool36 = global(bool: <class 'bool'>)    ['bool36']
    $36pred = call bool36($30compare_op.6, func=bool36, args=(Var($30compare_op.6, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$30compare_op.6', '$36pred', 'bool36']
    $phi38.0 = x0                            ['$phi38.0', 'x0']
    branch $36pred, 38, 50                   ['$36pred']
label 38:
    $40compare_op.2 = $phi38.0 <= threshold  ['$40compare_op.2', '$phi38.0', 'threshold']
    bool46 = global(bool: <class 'bool'>)    ['bool46']
    $46pred = call bool46($40compare_op.2, func=bool46, args=(Var($40compare_op.2, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$40compare_op.2', '$46pred', 'bool46']
    branch $46pred, 48, 58                   ['$46pred']
label 48:
    jump 54                                  []
label 50:
    jump 58                                  []
label 54:
    x0 = const(int, 0)                       ['x0']
    jump 58                                  []
label 58:
    $const60.1 = const(int, -1)              ['$const60.1']
    x1 = getitem(value=x, index=$const60.1, fn=<built-in function getitem>) ['$const60.1', 'x', 'x1']
    $76unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$76unary_negative.4', 'threshold']
    $84compare_op.6 = $76unary_negative.4 <= x1 ['$76unary_negative.4', '$84compare_op.6', 'x1']
    bool90 = global(bool: <class 'bool'>)    ['bool90']
    $90pred = call bool90($84compare_op.6, func=bool90, args=(Var($84compare_op.6, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$84compare_op.6', '$90pred', 'bool90']
    $phi92.0 = x1                            ['$phi92.0', 'x1']
    branch $90pred, 92, 104                  ['$90pred']
label 92:
    $94compare_op.2 = $phi92.0 <= threshold  ['$94compare_op.2', '$phi92.0', 'threshold']
    bool100 = global(bool: <class 'bool'>)   ['bool100']
    $100pred = call bool100($94compare_op.2, func=bool100, args=(Var($94compare_op.2, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$100pred', '$94compare_op.2', 'bool100']
    branch $100pred, 102, 112                ['$100pred']
label 102:
    jump 108                                 []
label 104:
    jump 112                                 []
label 108:
    x1 = const(int, 0)                       ['x1']
    jump 112                                 []
label 112:
    bool114 = global(bool: <class 'bool'>)   ['bool114']
    $114pred = call bool114(zero_pos, func=bool114, args=(Var(zero_pos, audio.py:1135),), kws=(), vararg=None, varkwarg=None, target=None) ['$114pred', 'bool114', 'zero_pos']
    branch $114pred, 116, 200                ['$114pred']
label 116:
    $116load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$116load_global.0']
    $128load_attr.2 = getattr(value=$116load_global.0, attr=signbit) ['$116load_global.0', '$128load_attr.2']
    $144call.4 = call $128load_attr.2(x0, func=$128load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$128load_attr.2', '$144call.4', 'x0']
    $154load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$154load_global.5']
    $166load_attr.7 = getattr(value=$154load_global.5, attr=signbit) ['$154load_global.5', '$166load_attr.7']
    $182call.9 = call $166load_attr.7(x1, func=$166load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$166load_attr.7', '$182call.9', 'x1']
    $192compare_op.10 = $144call.4 != $182call.9 ['$144call.4', '$182call.9', '$192compare_op.10']
    $198return_value.11 = cast(value=$192compare_op.10) ['$192compare_op.10', '$198return_value.11']
    return $198return_value.11               ['$198return_value.11']
label 200:
    $200load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$200load_global.0']
    $212load_attr.2 = getattr(value=$200load_global.0, attr=sign) ['$200load_global.0', '$212load_attr.2']
    $228call.4 = call $212load_attr.2(x0, func=$212load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$212load_attr.2', '$228call.4', 'x0']
    $238load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$238load_global.5']
    $250load_attr.7 = getattr(value=$238load_global.5, attr=sign) ['$238load_global.5', '$250load_attr.7']
    $266call.9 = call $250load_attr.7(x1, func=$250load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$250load_attr.7', '$266call.9', 'x1']
    $276compare_op.10 = $228call.4 != $266call.9 ['$228call.4', '$266call.9', '$276compare_op.10']
    $282return_value.11 = cast(value=$276compare_op.10) ['$276compare_op.10', '$282return_value.11']
    return $282return_value.11               ['$282return_value.11']

2024-01-20 11:45:16,415 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1039)
           2	RESUME(arg=0, lineno=1039)
           4	LOAD_FAST(arg=0, lineno=1042)
           6	LOAD_CONST(arg=1, lineno=1042)
           8	BINARY_SUBSCR(arg=None, lineno=1042)
          18	LOAD_FAST(arg=0, lineno=1042)
          20	LOAD_CONST(arg=2, lineno=1042)
          22	BINARY_SUBSCR(arg=None, lineno=1042)
          32	COMPARE_OP(arg=4, lineno=1042)
          38	LOAD_FAST(arg=0, lineno=1042)
          40	LOAD_CONST(arg=1, lineno=1042)
          42	BINARY_SUBSCR(arg=None, lineno=1042)
          52	LOAD_FAST(arg=0, lineno=1042)
          54	LOAD_CONST(arg=3, lineno=1042)
          56	BINARY_SUBSCR(arg=None, lineno=1042)
          66	COMPARE_OP(arg=5, lineno=1042)
          72	BINARY_OP(arg=1, lineno=1042)
          76	RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 11:45:16,415 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 11:45:16,415 DEBUG numba.core.byteflow stack: []
2024-01-20 11:45:16,415 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 11:45:16,415 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1039)
2024-01-20 11:45:16,415 DEBUG numba.core.byteflow stack []
2024-01-20 11:45:16,415 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1039)
2024-01-20 11:45:16,415 DEBUG numba.core.byteflow stack []
2024-01-20 11:45:16,415 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 11:45:16,415 DEBUG numba.core.byteflow stack []
2024-01-20 11:45:16,415 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 11:45:16,415 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 11:45:16,415 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1042)
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=4, lineno=1042)
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1042)
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=5, lineno=1042)
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1042)
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow defmap: {}
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 11:45:16,416 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 11:45:16,417 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 > $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 >= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 11:45:16,417 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1045)
           2	RESUME(arg=0, lineno=1045)
           4	LOAD_FAST(arg=0, lineno=1048)
           6	LOAD_CONST(arg=1, lineno=1048)
           8	BINARY_SUBSCR(arg=None, lineno=1048)
          18	LOAD_FAST(arg=0, lineno=1048)
          20	LOAD_CONST(arg=2, lineno=1048)
          22	BINARY_SUBSCR(arg=None, lineno=1048)
          32	COMPARE_OP(arg=0, lineno=1048)
          38	LOAD_FAST(arg=0, lineno=1048)
          40	LOAD_CONST(arg=1, lineno=1048)
          42	BINARY_SUBSCR(arg=None, lineno=1048)
          52	LOAD_FAST(arg=0, lineno=1048)
          54	LOAD_CONST(arg=3, lineno=1048)
          56	BINARY_SUBSCR(arg=None, lineno=1048)
          66	COMPARE_OP(arg=1, lineno=1048)
          72	BINARY_OP(arg=1, lineno=1048)
          76	RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow stack: []
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1045)
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow stack []
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1045)
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow stack []
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow stack []
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1048)
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=0, lineno=1048)
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1048)
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=1, lineno=1048)
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1048)
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 11:45:16,418 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 11:45:16,419 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 11:45:16,419 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 11:45:16,419 DEBUG numba.core.byteflow defmap: {}
2024-01-20 11:45:16,419 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 11:45:16,419 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 11:45:16,419 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 11:45:16,419 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 11:45:16,419 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 11:45:16,419 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 11:45:16,419 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 < $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 <= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 11:45:16,832 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_combined_c764f8d1b6b545838de8f62c78130ca9.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 11:45:16,864 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 11:45:16,943 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FFFAEFB110>
2024-01-20 11:45:16,943 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001FFC5CD4560> server_hostname='api.openai.com' timeout=5.0
2024-01-20 11:45:16,964 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FFFAEFBA10>
2024-01-20 11:45:16,964 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 11:45:16,965 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 11:45:16,965 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 11:45:17,236 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 11:45:17,236 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 11:45:20,456 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 10:45:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'1507'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'18967ae2dce11fbd43325776f3e3e29b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=OaczLgefDfijLL5DFZ58Jy1x44ylB3SIENhtZHRxqYE-1705747519-1-AQzBrLBvHMJJtjBYP6g5HmWQtu777yKVCWdnTw9S6knXZXdfiCZf6GZTeiMADR+YLv9E5hFj8o82IOXQ1zPblyA=; path=/; expires=Sat, 20-Jan-24 11:15:19 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=ao.thvRKs2uPJQHfuTsIsMufeD58ShwhYjeRma.ASKo-1705747519282-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8486ba15cac42c3d-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 11:45:20,458 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 11:45:20,458 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 11:45:20,459 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 11:45:20,459 DEBUG httpcore.http11 response_closed.started
2024-01-20 11:45:20,459 DEBUG httpcore.http11 response_closed.complete
2024-01-20 11:45:20,459 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 11:52:22,659 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 11:52:22,660 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 11:52:22,886 INFO transcription All nescessary class variables are declared and working!
2024-01-20 11:54:31,088 INFO transcription Current recording SessionID is: f3b95e920e1c47299d72a72c325827fb
2024-01-20 11:54:31,089 INFO transcription Started Microphone Thread for session f3b95e920e1c47299d72a72c325827fb!
2024-01-20 11:54:31,090 INFO transcription Opening Stream for device Microsoft Sound Mapper - Input...
2024-01-20 11:54:31,091 INFO transcription Started System sounds Thread for session f3b95e920e1c47299d72a72c325827fb!
2024-01-20 11:54:31,091 INFO transcription Opening Stream for device Stereo Mix (Realtek USB Audio)...
2024-01-20 11:54:31,105 INFO transcription Stream for Microphone Microsoft Sound Mapper - Input open!
2024-01-20 11:54:31,165 INFO transcription Stream for Microphone Stereo Mix (Realtek USB Audio) open!
2024-01-20 11:54:57,178 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1135)
           2	RESUME(arg=0, lineno=1135)
           4	LOAD_FAST(arg=0, lineno=1138)
           6	LOAD_CONST(arg=1, lineno=1138)
           8	BINARY_SUBSCR(arg=None, lineno=1138)
          18	STORE_FAST(arg=3, lineno=1138)
          20	LOAD_FAST(arg=1, lineno=1139)
          22	UNARY_NEGATIVE(arg=None, lineno=1139)
          24	LOAD_FAST(arg=3, lineno=1139)
          26	SWAP(arg=2, lineno=1139)
          28	COPY(arg=2, lineno=1139)
          30	COMPARE_OP(arg=1, lineno=1139)
          36	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
          38	LOAD_FAST(arg=1, lineno=1139)
          40	COMPARE_OP(arg=1, lineno=1139)
          46	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
          48	JUMP_FORWARD(arg=2, lineno=1139)
>         50	POP_TOP(arg=None, lineno=1139)
          52	JUMP_FORWARD(arg=2, lineno=1139)
>         54	LOAD_CONST(arg=1, lineno=1140)
          56	STORE_FAST(arg=3, lineno=1140)
>         58	LOAD_FAST(arg=0, lineno=1142)
          60	LOAD_CONST(arg=2, lineno=1142)
          62	BINARY_SUBSCR(arg=None, lineno=1142)
          72	STORE_FAST(arg=4, lineno=1142)
          74	LOAD_FAST(arg=1, lineno=1143)
          76	UNARY_NEGATIVE(arg=None, lineno=1143)
          78	LOAD_FAST(arg=4, lineno=1143)
          80	SWAP(arg=2, lineno=1143)
          82	COPY(arg=2, lineno=1143)
          84	COMPARE_OP(arg=1, lineno=1143)
          90	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
          92	LOAD_FAST(arg=1, lineno=1143)
          94	COMPARE_OP(arg=1, lineno=1143)
         100	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
         102	JUMP_FORWARD(arg=2, lineno=1143)
>        104	POP_TOP(arg=None, lineno=1143)
         106	JUMP_FORWARD(arg=2, lineno=1143)
>        108	LOAD_CONST(arg=1, lineno=1144)
         110	STORE_FAST(arg=4, lineno=1144)
>        112	LOAD_FAST(arg=2, lineno=1146)
         114	POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
         116	LOAD_GLOBAL(arg=1, lineno=1147)
         128	LOAD_ATTR(arg=1, lineno=1147)
         138	LOAD_FAST(arg=3, lineno=1147)
         140	PRECALL(arg=1, lineno=1147)
         144	CALL(arg=1, lineno=1147)
         154	LOAD_GLOBAL(arg=1, lineno=1147)
         166	LOAD_ATTR(arg=1, lineno=1147)
         176	LOAD_FAST(arg=4, lineno=1147)
         178	PRECALL(arg=1, lineno=1147)
         182	CALL(arg=1, lineno=1147)
         192	COMPARE_OP(arg=3, lineno=1147)
         198	RETURN_VALUE(arg=None, lineno=1147)
>        200	LOAD_GLOBAL(arg=1, lineno=1149)
         212	LOAD_ATTR(arg=2, lineno=1149)
         222	LOAD_FAST(arg=3, lineno=1149)
         224	PRECALL(arg=1, lineno=1149)
         228	CALL(arg=1, lineno=1149)
         238	LOAD_GLOBAL(arg=1, lineno=1149)
         250	LOAD_ATTR(arg=2, lineno=1149)
         260	LOAD_FAST(arg=4, lineno=1149)
         262	PRECALL(arg=1, lineno=1149)
         266	CALL(arg=1, lineno=1149)
         276	COMPARE_OP(arg=3, lineno=1149)
         282	RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow stack: []
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1135)
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow stack []
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1135)
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow stack []
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1138)
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow stack []
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1138)
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1138)
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow dispatch pc=18, inst=STORE_FAST(arg=3, lineno=1138)
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow stack []
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow dispatch pc=22, inst=UNARY_NEGATIVE(arg=None, lineno=1139)
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow stack ['$threshold20.3']
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow dispatch pc=24, inst=LOAD_FAST(arg=3, lineno=1139)
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow stack ['$22unary_negative.4']
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow dispatch pc=26, inst=SWAP(arg=2, lineno=1139)
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow stack ['$22unary_negative.4', '$x024.5']
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow dispatch pc=28, inst=COPY(arg=2, lineno=1139)
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4']
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow dispatch pc=30, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4', '$x024.5']
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow dispatch pc=36, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow stack ['$x024.5', '$30compare_op.6']
2024-01-20 11:54:57,179 DEBUG numba.core.byteflow end state. edges=[Edge(pc=38, stack=('$x024.5',), blockstack=(), npush=0), Edge(pc=50, stack=('$x024.5',), blockstack=(), npush=0)]
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow pending: deque([State(pc_initial=38 nstack_initial=1), State(pc_initial=50 nstack_initial=1)])
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow stack: ['$phi38.0']
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=38 nstack_initial=1)
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow stack ['$phi38.0']
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow dispatch pc=40, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow stack ['$phi38.0', '$threshold38.1']
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow dispatch pc=46, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow stack ['$40compare_op.2']
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow end state. edges=[Edge(pc=48, stack=(), blockstack=(), npush=0), Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow pending: deque([State(pc_initial=50 nstack_initial=1), State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow stack: ['$phi50.0']
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=50 nstack_initial=1)
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow dispatch pc=50, inst=POP_TOP(arg=None, lineno=1139)
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow stack ['$phi50.0']
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow dispatch pc=52, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow stack []
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow pending: deque([State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow stack: []
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=48 nstack_initial=0)
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow dispatch pc=48, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow stack []
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow end state. edges=[Edge(pc=54, stack=(), blockstack=(), npush=0)]
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0)])
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow stack: []
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=58 nstack_initial=0)
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow dispatch pc=58, inst=LOAD_FAST(arg=0, lineno=1142)
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow stack []
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow dispatch pc=60, inst=LOAD_CONST(arg=2, lineno=1142)
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow stack ['$x58.0']
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow dispatch pc=62, inst=BINARY_SUBSCR(arg=None, lineno=1142)
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow stack ['$x58.0', '$const60.1']
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow dispatch pc=72, inst=STORE_FAST(arg=4, lineno=1142)
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow stack ['$62binary_subscr.2']
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow dispatch pc=74, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow stack []
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow dispatch pc=76, inst=UNARY_NEGATIVE(arg=None, lineno=1143)
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow stack ['$threshold74.3']
2024-01-20 11:54:57,180 DEBUG numba.core.byteflow dispatch pc=78, inst=LOAD_FAST(arg=4, lineno=1143)
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow stack ['$76unary_negative.4']
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow dispatch pc=80, inst=SWAP(arg=2, lineno=1143)
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow stack ['$76unary_negative.4', '$x178.5']
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow dispatch pc=82, inst=COPY(arg=2, lineno=1143)
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4']
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow dispatch pc=84, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4', '$x178.5']
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow dispatch pc=90, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow stack ['$x178.5', '$84compare_op.6']
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow end state. edges=[Edge(pc=92, stack=('$x178.5',), blockstack=(), npush=0), Edge(pc=104, stack=('$x178.5',), blockstack=(), npush=0)]
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow pending: deque([State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow stack: []
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=54 nstack_initial=0)
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=1, lineno=1140)
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow stack []
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow dispatch pc=56, inst=STORE_FAST(arg=3, lineno=1140)
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow stack ['$const54.0']
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow pending: deque([State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0)])
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow stack: ['$phi92.0']
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=92 nstack_initial=1)
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow dispatch pc=92, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow stack ['$phi92.0']
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow dispatch pc=94, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow stack ['$phi92.0', '$threshold92.1']
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow dispatch pc=100, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow stack ['$94compare_op.2']
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow end state. edges=[Edge(pc=102, stack=(), blockstack=(), npush=0), Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow pending: deque([State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow stack: ['$phi104.0']
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=104 nstack_initial=1)
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow dispatch pc=104, inst=POP_TOP(arg=None, lineno=1143)
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow stack ['$phi104.0']
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow dispatch pc=106, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow stack []
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 11:54:57,181 DEBUG numba.core.byteflow pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow stack: []
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=102 nstack_initial=0)
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow dispatch pc=102, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow stack []
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow end state. edges=[Edge(pc=108, stack=(), blockstack=(), npush=0)]
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0)])
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow stack: []
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=112 nstack_initial=0)
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow dispatch pc=112, inst=LOAD_FAST(arg=2, lineno=1146)
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow stack []
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow dispatch pc=114, inst=POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow stack ['$zero_pos112.0']
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow end state. edges=[Edge(pc=116, stack=(), blockstack=(), npush=0), Edge(pc=200, stack=(), blockstack=(), npush=0)]
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow pending: deque([State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow stack: []
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=108 nstack_initial=0)
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow dispatch pc=108, inst=LOAD_CONST(arg=1, lineno=1144)
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow stack []
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow dispatch pc=110, inst=STORE_FAST(arg=4, lineno=1144)
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow stack ['$const108.0']
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow pending: deque([State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow stack: []
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=116 nstack_initial=0)
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow dispatch pc=116, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow stack []
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow dispatch pc=128, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow stack ['$null$116.1', '$116load_global.0']
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow dispatch pc=138, inst=LOAD_FAST(arg=3, lineno=1147)
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2']
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow dispatch pc=140, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow dispatch pc=144, inst=CALL(arg=1, lineno=1147)
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow dispatch pc=154, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow stack ['$144call.4']
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow dispatch pc=166, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$154load_global.5']
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow dispatch pc=176, inst=LOAD_FAST(arg=4, lineno=1147)
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7']
2024-01-20 11:54:57,182 DEBUG numba.core.byteflow dispatch pc=178, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow dispatch pc=182, inst=CALL(arg=1, lineno=1147)
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow dispatch pc=192, inst=COMPARE_OP(arg=3, lineno=1147)
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow stack ['$144call.4', '$182call.9']
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow dispatch pc=198, inst=RETURN_VALUE(arg=None, lineno=1147)
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow stack ['$192compare_op.10']
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow pending: deque([State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow stack: []
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=200 nstack_initial=0)
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow dispatch pc=200, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow stack []
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow dispatch pc=212, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow stack ['$null$200.1', '$200load_global.0']
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow dispatch pc=222, inst=LOAD_FAST(arg=3, lineno=1149)
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2']
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow dispatch pc=224, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow dispatch pc=228, inst=CALL(arg=1, lineno=1149)
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow dispatch pc=238, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow stack ['$228call.4']
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow dispatch pc=250, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$238load_global.5']
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow dispatch pc=260, inst=LOAD_FAST(arg=4, lineno=1149)
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7']
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow dispatch pc=262, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow dispatch pc=266, inst=CALL(arg=1, lineno=1149)
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow dispatch pc=276, inst=COMPARE_OP(arg=3, lineno=1149)
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow stack ['$228call.4', '$266call.9']
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow dispatch pc=282, inst=RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow stack ['$276compare_op.10']
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0)])
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 11:54:57,183 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=38 nstack_initial=1): {'$phi38.0'},
             State(pc_initial=48 nstack_initial=0): set(),
             State(pc_initial=50 nstack_initial=1): set(),
             State(pc_initial=54 nstack_initial=0): set(),
             State(pc_initial=58 nstack_initial=0): set(),
             State(pc_initial=92 nstack_initial=1): {'$phi92.0'},
             State(pc_initial=102 nstack_initial=0): set(),
             State(pc_initial=104 nstack_initial=1): set(),
             State(pc_initial=108 nstack_initial=0): set(),
             State(pc_initial=112 nstack_initial=0): set(),
             State(pc_initial=116 nstack_initial=0): set(),
             State(pc_initial=200 nstack_initial=0): set()})
2024-01-20 11:54:57,184 DEBUG numba.core.byteflow defmap: {'$phi104.0': State(pc_initial=58 nstack_initial=0),
 '$phi38.0': State(pc_initial=0 nstack_initial=0),
 '$phi50.0': State(pc_initial=0 nstack_initial=0),
 '$phi92.0': State(pc_initial=58 nstack_initial=0)}
2024-01-20 11:54:57,184 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 11:54:57,184 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 11:54:57,184 DEBUG numba.core.byteflow keep phismap: {'$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
 '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}}
2024-01-20 11:54:57,184 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi38.0': '$x024.5'},
             State(pc_initial=58 nstack_initial=0): {'$phi92.0': '$x178.5'}})
2024-01-20 11:54:57,184 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 11:54:57,184 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'value': '$8binary_subscr.2'}), (20, {'res': '$threshold20.3'}), (22, {'value': '$threshold20.3', 'res': '$22unary_negative.4'}), (24, {'res': '$x024.5'}), (30, {'lhs': '$22unary_negative.4', 'rhs': '$x024.5', 'res': '$30compare_op.6'}), (32, {}), (34, {}), (36, {'pred': '$30compare_op.6'})), outgoing_phis={'$phi38.0': '$x024.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={38: ('$x024.5',), 50: ('$x024.5',)})
2024-01-20 11:54:57,184 DEBUG numba.core.byteflow block_infos State(pc_initial=38 nstack_initial=1):
AdaptBlockInfo(insts=((38, {'res': '$threshold38.1'}), (40, {'lhs': '$phi38.0', 'rhs': '$threshold38.1', 'res': '$40compare_op.2'}), (42, {}), (44, {}), (46, {'pred': '$40compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={48: (), 58: ()})
2024-01-20 11:54:57,184 DEBUG numba.core.byteflow block_infos State(pc_initial=48 nstack_initial=0):
AdaptBlockInfo(insts=((48, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={54: ()})
2024-01-20 11:54:57,184 DEBUG numba.core.byteflow block_infos State(pc_initial=50 nstack_initial=1):
AdaptBlockInfo(insts=((52, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 11:54:57,184 DEBUG numba.core.byteflow block_infos State(pc_initial=54 nstack_initial=0):
AdaptBlockInfo(insts=((54, {'res': '$const54.0'}), (56, {'value': '$const54.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 11:54:57,184 DEBUG numba.core.byteflow block_infos State(pc_initial=58 nstack_initial=0):
AdaptBlockInfo(insts=((58, {'res': '$x58.0'}), (60, {'res': '$const60.1'}), (62, {'index': '$const60.1', 'target': '$x58.0', 'res': '$62binary_subscr.2'}), (64, {}), (66, {}), (68, {}), (70, {}), (72, {'value': '$62binary_subscr.2'}), (74, {'res': '$threshold74.3'}), (76, {'value': '$threshold74.3', 'res': '$76unary_negative.4'}), (78, {'res': '$x178.5'}), (84, {'lhs': '$76unary_negative.4', 'rhs': '$x178.5', 'res': '$84compare_op.6'}), (86, {}), (88, {}), (90, {'pred': '$84compare_op.6'})), outgoing_phis={'$phi92.0': '$x178.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={92: ('$x178.5',), 104: ('$x178.5',)})
2024-01-20 11:54:57,184 DEBUG numba.core.byteflow block_infos State(pc_initial=92 nstack_initial=1):
AdaptBlockInfo(insts=((92, {'res': '$threshold92.1'}), (94, {'lhs': '$phi92.0', 'rhs': '$threshold92.1', 'res': '$94compare_op.2'}), (96, {}), (98, {}), (100, {'pred': '$94compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={102: (), 112: ()})
2024-01-20 11:54:57,184 DEBUG numba.core.byteflow block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={108: ()})
2024-01-20 11:54:57,184 DEBUG numba.core.byteflow block_infos State(pc_initial=104 nstack_initial=1):
AdaptBlockInfo(insts=((106, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 11:54:57,184 DEBUG numba.core.byteflow block_infos State(pc_initial=108 nstack_initial=0):
AdaptBlockInfo(insts=((108, {'res': '$const108.0'}), (110, {'value': '$const108.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 11:54:57,184 DEBUG numba.core.byteflow block_infos State(pc_initial=112 nstack_initial=0):
AdaptBlockInfo(insts=((112, {'res': '$zero_pos112.0'}), (114, {'pred': '$zero_pos112.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={116: (), 200: ()})
2024-01-20 11:54:57,184 DEBUG numba.core.byteflow block_infos State(pc_initial=116 nstack_initial=0):
AdaptBlockInfo(insts=((116, {'idx': 0, 'res': '$116load_global.0'}), (118, {}), (120, {}), (122, {}), (124, {}), (126, {}), (128, {'item': '$116load_global.0', 'res': '$128load_attr.2'}), (130, {}), (132, {}), (134, {}), (136, {}), (138, {'res': '$x0138.3'}), (140, {}), (142, {}), (144, {'func': '$128load_attr.2', 'args': ['$x0138.3'], 'kw_names': None, 'res': '$144call.4'}), (146, {}), (148, {}), (150, {}), (152, {}), (154, {'idx': 0, 'res': '$154load_global.5'}), (156, {}), (158, {}), (160, {}), (162, {}), (164, {}), (166, {'item': '$154load_global.5', 'res': '$166load_attr.7'}), (168, {}), (170, {}), (172, {}), (174, {}), (176, {'res': '$x1176.8'}), (178, {}), (180, {}), (182, {'func': '$166load_attr.7', 'args': ['$x1176.8'], 'kw_names': None, 'res': '$182call.9'}), (184, {}), (186, {}), (188, {}), (190, {}), (192, {'lhs': '$144call.4', 'rhs': '$182call.9', 'res': '$192compare_op.10'}), (194, {}), (196, {}), (198, {'retval': '$192compare_op.10', 'castval': '$198return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 11:54:57,184 DEBUG numba.core.byteflow block_infos State(pc_initial=200 nstack_initial=0):
AdaptBlockInfo(insts=((200, {'idx': 0, 'res': '$200load_global.0'}), (202, {}), (204, {}), (206, {}), (208, {}), (210, {}), (212, {'item': '$200load_global.0', 'res': '$212load_attr.2'}), (214, {}), (216, {}), (218, {}), (220, {}), (222, {'res': '$x0222.3'}), (224, {}), (226, {}), (228, {'func': '$212load_attr.2', 'args': ['$x0222.3'], 'kw_names': None, 'res': '$228call.4'}), (230, {}), (232, {}), (234, {}), (236, {}), (238, {'idx': 0, 'res': '$238load_global.5'}), (240, {}), (242, {}), (244, {}), (246, {}), (248, {}), (250, {'item': '$238load_global.5', 'res': '$250load_attr.7'}), (252, {}), (254, {}), (256, {}), (258, {}), (260, {'res': '$x1260.8'}), (262, {}), (264, {}), (266, {'func': '$250load_attr.7', 'args': ['$x1260.8'], 'kw_names': None, 'res': '$266call.9'}), (268, {}), (270, {}), (272, {}), (274, {}), (276, {'lhs': '$228call.4', 'rhs': '$266call.9', 'res': '$276compare_op.10'}), (278, {}), (280, {}), (282, {'retval': '$276compare_op.10', 'castval': '$282return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 11:54:57,185 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const6.1 = const(int, 0)                ['$const6.1']
    x0 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$const6.1', 'x', 'x0']
    $22unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$22unary_negative.4', 'threshold']
    $30compare_op.6 = $22unary_negative.4 <= x0 ['$22unary_negative.4', '$30compare_op.6', 'x0']
    bool36 = global(bool: <class 'bool'>)    ['bool36']
    $36pred = call bool36($30compare_op.6, func=bool36, args=(Var($30compare_op.6, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$30compare_op.6', '$36pred', 'bool36']
    $phi38.0 = x0                            ['$phi38.0', 'x0']
    branch $36pred, 38, 50                   ['$36pred']
label 38:
    $40compare_op.2 = $phi38.0 <= threshold  ['$40compare_op.2', '$phi38.0', 'threshold']
    bool46 = global(bool: <class 'bool'>)    ['bool46']
    $46pred = call bool46($40compare_op.2, func=bool46, args=(Var($40compare_op.2, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$40compare_op.2', '$46pred', 'bool46']
    branch $46pred, 48, 58                   ['$46pred']
label 48:
    jump 54                                  []
label 50:
    jump 58                                  []
label 54:
    x0 = const(int, 0)                       ['x0']
    jump 58                                  []
label 58:
    $const60.1 = const(int, -1)              ['$const60.1']
    x1 = getitem(value=x, index=$const60.1, fn=<built-in function getitem>) ['$const60.1', 'x', 'x1']
    $76unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$76unary_negative.4', 'threshold']
    $84compare_op.6 = $76unary_negative.4 <= x1 ['$76unary_negative.4', '$84compare_op.6', 'x1']
    bool90 = global(bool: <class 'bool'>)    ['bool90']
    $90pred = call bool90($84compare_op.6, func=bool90, args=(Var($84compare_op.6, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$84compare_op.6', '$90pred', 'bool90']
    $phi92.0 = x1                            ['$phi92.0', 'x1']
    branch $90pred, 92, 104                  ['$90pred']
label 92:
    $94compare_op.2 = $phi92.0 <= threshold  ['$94compare_op.2', '$phi92.0', 'threshold']
    bool100 = global(bool: <class 'bool'>)   ['bool100']
    $100pred = call bool100($94compare_op.2, func=bool100, args=(Var($94compare_op.2, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$100pred', '$94compare_op.2', 'bool100']
    branch $100pred, 102, 112                ['$100pred']
label 102:
    jump 108                                 []
label 104:
    jump 112                                 []
label 108:
    x1 = const(int, 0)                       ['x1']
    jump 112                                 []
label 112:
    bool114 = global(bool: <class 'bool'>)   ['bool114']
    $114pred = call bool114(zero_pos, func=bool114, args=(Var(zero_pos, audio.py:1135),), kws=(), vararg=None, varkwarg=None, target=None) ['$114pred', 'bool114', 'zero_pos']
    branch $114pred, 116, 200                ['$114pred']
label 116:
    $116load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$116load_global.0']
    $128load_attr.2 = getattr(value=$116load_global.0, attr=signbit) ['$116load_global.0', '$128load_attr.2']
    $144call.4 = call $128load_attr.2(x0, func=$128load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$128load_attr.2', '$144call.4', 'x0']
    $154load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$154load_global.5']
    $166load_attr.7 = getattr(value=$154load_global.5, attr=signbit) ['$154load_global.5', '$166load_attr.7']
    $182call.9 = call $166load_attr.7(x1, func=$166load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$166load_attr.7', '$182call.9', 'x1']
    $192compare_op.10 = $144call.4 != $182call.9 ['$144call.4', '$182call.9', '$192compare_op.10']
    $198return_value.11 = cast(value=$192compare_op.10) ['$192compare_op.10', '$198return_value.11']
    return $198return_value.11               ['$198return_value.11']
label 200:
    $200load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$200load_global.0']
    $212load_attr.2 = getattr(value=$200load_global.0, attr=sign) ['$200load_global.0', '$212load_attr.2']
    $228call.4 = call $212load_attr.2(x0, func=$212load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$212load_attr.2', '$228call.4', 'x0']
    $238load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$238load_global.5']
    $250load_attr.7 = getattr(value=$238load_global.5, attr=sign) ['$238load_global.5', '$250load_attr.7']
    $266call.9 = call $250load_attr.7(x1, func=$250load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$250load_attr.7', '$266call.9', 'x1']
    $276compare_op.10 = $228call.4 != $266call.9 ['$228call.4', '$266call.9', '$276compare_op.10']
    $282return_value.11 = cast(value=$276compare_op.10) ['$276compare_op.10', '$282return_value.11']
    return $282return_value.11               ['$282return_value.11']

2024-01-20 11:54:57,446 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1039)
           2	RESUME(arg=0, lineno=1039)
           4	LOAD_FAST(arg=0, lineno=1042)
           6	LOAD_CONST(arg=1, lineno=1042)
           8	BINARY_SUBSCR(arg=None, lineno=1042)
          18	LOAD_FAST(arg=0, lineno=1042)
          20	LOAD_CONST(arg=2, lineno=1042)
          22	BINARY_SUBSCR(arg=None, lineno=1042)
          32	COMPARE_OP(arg=4, lineno=1042)
          38	LOAD_FAST(arg=0, lineno=1042)
          40	LOAD_CONST(arg=1, lineno=1042)
          42	BINARY_SUBSCR(arg=None, lineno=1042)
          52	LOAD_FAST(arg=0, lineno=1042)
          54	LOAD_CONST(arg=3, lineno=1042)
          56	BINARY_SUBSCR(arg=None, lineno=1042)
          66	COMPARE_OP(arg=5, lineno=1042)
          72	BINARY_OP(arg=1, lineno=1042)
          76	RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 11:54:57,446 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 11:54:57,446 DEBUG numba.core.byteflow stack: []
2024-01-20 11:54:57,446 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 11:54:57,446 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1039)
2024-01-20 11:54:57,446 DEBUG numba.core.byteflow stack []
2024-01-20 11:54:57,446 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1039)
2024-01-20 11:54:57,446 DEBUG numba.core.byteflow stack []
2024-01-20 11:54:57,446 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 11:54:57,446 DEBUG numba.core.byteflow stack []
2024-01-20 11:54:57,446 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 11:54:57,446 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 11:54:57,446 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 11:54:57,446 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 11:54:57,446 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 11:54:57,446 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 11:54:57,446 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1042)
2024-01-20 11:54:57,446 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=4, lineno=1042)
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1042)
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=5, lineno=1042)
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1042)
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow defmap: {}
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 11:54:57,447 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 11:54:57,448 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 > $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 >= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 11:54:57,448 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1045)
           2	RESUME(arg=0, lineno=1045)
           4	LOAD_FAST(arg=0, lineno=1048)
           6	LOAD_CONST(arg=1, lineno=1048)
           8	BINARY_SUBSCR(arg=None, lineno=1048)
          18	LOAD_FAST(arg=0, lineno=1048)
          20	LOAD_CONST(arg=2, lineno=1048)
          22	BINARY_SUBSCR(arg=None, lineno=1048)
          32	COMPARE_OP(arg=0, lineno=1048)
          38	LOAD_FAST(arg=0, lineno=1048)
          40	LOAD_CONST(arg=1, lineno=1048)
          42	BINARY_SUBSCR(arg=None, lineno=1048)
          52	LOAD_FAST(arg=0, lineno=1048)
          54	LOAD_CONST(arg=3, lineno=1048)
          56	BINARY_SUBSCR(arg=None, lineno=1048)
          66	COMPARE_OP(arg=1, lineno=1048)
          72	BINARY_OP(arg=1, lineno=1048)
          76	RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 11:54:57,448 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow stack: []
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1045)
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow stack []
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1045)
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow stack []
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow stack []
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1048)
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=0, lineno=1048)
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1048)
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=1, lineno=1048)
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1048)
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow defmap: {}
2024-01-20 11:54:57,449 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 11:54:57,450 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 11:54:57,450 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 11:54:57,450 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 11:54:57,450 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 11:54:57,450 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 11:54:57,450 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 < $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 <= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 11:54:57,713 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_combined_cddad0b558a94337ae29780f03f0057e.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 11:54:57,744 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 11:54:57,930 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022485B99E90>
2024-01-20 11:54:57,930 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000224D08C45F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 11:54:57,949 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022485C16CD0>
2024-01-20 11:54:57,949 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 11:54:57,950 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 11:54:57,950 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 11:54:58,500 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 11:54:58,500 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 11:55:00,424 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 10:54:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'1098'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a76ca0eb45b379db97ab3e298b99842f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=JqOWmc3x6EUFObYYgPrY4l5lDsn1Wo8uJKAMR9gnpOE-1705748099-1-AZ11KnORcLUgQ+tC+OAnQupdQfCJB1yZgzW7tyzqPquEIre2JIgp0kF1LYMdwlCdPHMegKdzzKI3OBXYxQUYLJo=; path=/; expires=Sat, 20-Jan-24 11:24:59 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=d1IdRNHsBEcdU6QokRn8z59jA4K5_PwAPThQzp4RBGE-1705748099241-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8486c844d84e906a-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 11:55:00,426 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 11:55:00,427 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 11:55:00,428 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 11:55:00,428 DEBUG httpcore.http11 response_closed.started
2024-01-20 11:55:00,428 DEBUG httpcore.http11 response_closed.complete
2024-01-20 11:55:00,428 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 11:57:42,516 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 11:57:42,518 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 11:57:42,765 INFO transcription All nescessary class variables are declared and working!
2024-01-20 11:59:45,633 INFO transcription Current recording SessionID is: eeabff2a40fc43f4b4c39d46fcec33ca
2024-01-20 11:59:45,634 INFO transcription Started Microphone Thread for session eeabff2a40fc43f4b4c39d46fcec33ca!
2024-01-20 11:59:45,635 INFO transcription Opening Stream for device Microsoft Sound Mapper - Input...
2024-01-20 11:59:45,636 INFO transcription Started System sounds Thread for session eeabff2a40fc43f4b4c39d46fcec33ca!
2024-01-20 11:59:45,636 INFO transcription Opening Stream for device Stereo Mix (Realtek USB Audio)...
2024-01-20 11:59:45,648 INFO transcription Stream for Microphone Microsoft Sound Mapper - Input open!
2024-01-20 11:59:45,707 INFO transcription Stream for Microphone Stereo Mix (Realtek USB Audio) open!
2024-01-20 11:59:53,619 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1135)
           2	RESUME(arg=0, lineno=1135)
           4	LOAD_FAST(arg=0, lineno=1138)
           6	LOAD_CONST(arg=1, lineno=1138)
           8	BINARY_SUBSCR(arg=None, lineno=1138)
          18	STORE_FAST(arg=3, lineno=1138)
          20	LOAD_FAST(arg=1, lineno=1139)
          22	UNARY_NEGATIVE(arg=None, lineno=1139)
          24	LOAD_FAST(arg=3, lineno=1139)
          26	SWAP(arg=2, lineno=1139)
          28	COPY(arg=2, lineno=1139)
          30	COMPARE_OP(arg=1, lineno=1139)
          36	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
          38	LOAD_FAST(arg=1, lineno=1139)
          40	COMPARE_OP(arg=1, lineno=1139)
          46	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
          48	JUMP_FORWARD(arg=2, lineno=1139)
>         50	POP_TOP(arg=None, lineno=1139)
          52	JUMP_FORWARD(arg=2, lineno=1139)
>         54	LOAD_CONST(arg=1, lineno=1140)
          56	STORE_FAST(arg=3, lineno=1140)
>         58	LOAD_FAST(arg=0, lineno=1142)
          60	LOAD_CONST(arg=2, lineno=1142)
          62	BINARY_SUBSCR(arg=None, lineno=1142)
          72	STORE_FAST(arg=4, lineno=1142)
          74	LOAD_FAST(arg=1, lineno=1143)
          76	UNARY_NEGATIVE(arg=None, lineno=1143)
          78	LOAD_FAST(arg=4, lineno=1143)
          80	SWAP(arg=2, lineno=1143)
          82	COPY(arg=2, lineno=1143)
          84	COMPARE_OP(arg=1, lineno=1143)
          90	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
          92	LOAD_FAST(arg=1, lineno=1143)
          94	COMPARE_OP(arg=1, lineno=1143)
         100	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
         102	JUMP_FORWARD(arg=2, lineno=1143)
>        104	POP_TOP(arg=None, lineno=1143)
         106	JUMP_FORWARD(arg=2, lineno=1143)
>        108	LOAD_CONST(arg=1, lineno=1144)
         110	STORE_FAST(arg=4, lineno=1144)
>        112	LOAD_FAST(arg=2, lineno=1146)
         114	POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
         116	LOAD_GLOBAL(arg=1, lineno=1147)
         128	LOAD_ATTR(arg=1, lineno=1147)
         138	LOAD_FAST(arg=3, lineno=1147)
         140	PRECALL(arg=1, lineno=1147)
         144	CALL(arg=1, lineno=1147)
         154	LOAD_GLOBAL(arg=1, lineno=1147)
         166	LOAD_ATTR(arg=1, lineno=1147)
         176	LOAD_FAST(arg=4, lineno=1147)
         178	PRECALL(arg=1, lineno=1147)
         182	CALL(arg=1, lineno=1147)
         192	COMPARE_OP(arg=3, lineno=1147)
         198	RETURN_VALUE(arg=None, lineno=1147)
>        200	LOAD_GLOBAL(arg=1, lineno=1149)
         212	LOAD_ATTR(arg=2, lineno=1149)
         222	LOAD_FAST(arg=3, lineno=1149)
         224	PRECALL(arg=1, lineno=1149)
         228	CALL(arg=1, lineno=1149)
         238	LOAD_GLOBAL(arg=1, lineno=1149)
         250	LOAD_ATTR(arg=2, lineno=1149)
         260	LOAD_FAST(arg=4, lineno=1149)
         262	PRECALL(arg=1, lineno=1149)
         266	CALL(arg=1, lineno=1149)
         276	COMPARE_OP(arg=3, lineno=1149)
         282	RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 11:59:53,619 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 11:59:53,619 DEBUG numba.core.byteflow stack: []
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1135)
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow stack []
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1135)
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow stack []
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1138)
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow stack []
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1138)
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1138)
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow dispatch pc=18, inst=STORE_FAST(arg=3, lineno=1138)
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow stack []
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow dispatch pc=22, inst=UNARY_NEGATIVE(arg=None, lineno=1139)
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow stack ['$threshold20.3']
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow dispatch pc=24, inst=LOAD_FAST(arg=3, lineno=1139)
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow stack ['$22unary_negative.4']
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow dispatch pc=26, inst=SWAP(arg=2, lineno=1139)
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow stack ['$22unary_negative.4', '$x024.5']
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow dispatch pc=28, inst=COPY(arg=2, lineno=1139)
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4']
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow dispatch pc=30, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4', '$x024.5']
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow dispatch pc=36, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow stack ['$x024.5', '$30compare_op.6']
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow end state. edges=[Edge(pc=38, stack=('$x024.5',), blockstack=(), npush=0), Edge(pc=50, stack=('$x024.5',), blockstack=(), npush=0)]
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow pending: deque([State(pc_initial=38 nstack_initial=1), State(pc_initial=50 nstack_initial=1)])
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow stack: ['$phi38.0']
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=38 nstack_initial=1)
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow stack ['$phi38.0']
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow dispatch pc=40, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 11:59:53,620 DEBUG numba.core.byteflow stack ['$phi38.0', '$threshold38.1']
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow dispatch pc=46, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow stack ['$40compare_op.2']
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow end state. edges=[Edge(pc=48, stack=(), blockstack=(), npush=0), Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow pending: deque([State(pc_initial=50 nstack_initial=1), State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow stack: ['$phi50.0']
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=50 nstack_initial=1)
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow dispatch pc=50, inst=POP_TOP(arg=None, lineno=1139)
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow stack ['$phi50.0']
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow dispatch pc=52, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow stack []
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow pending: deque([State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow stack: []
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=48 nstack_initial=0)
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow dispatch pc=48, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow stack []
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow end state. edges=[Edge(pc=54, stack=(), blockstack=(), npush=0)]
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0)])
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow stack: []
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=58 nstack_initial=0)
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow dispatch pc=58, inst=LOAD_FAST(arg=0, lineno=1142)
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow stack []
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow dispatch pc=60, inst=LOAD_CONST(arg=2, lineno=1142)
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow stack ['$x58.0']
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow dispatch pc=62, inst=BINARY_SUBSCR(arg=None, lineno=1142)
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow stack ['$x58.0', '$const60.1']
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow dispatch pc=72, inst=STORE_FAST(arg=4, lineno=1142)
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow stack ['$62binary_subscr.2']
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow dispatch pc=74, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow stack []
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow dispatch pc=76, inst=UNARY_NEGATIVE(arg=None, lineno=1143)
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow stack ['$threshold74.3']
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow dispatch pc=78, inst=LOAD_FAST(arg=4, lineno=1143)
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow stack ['$76unary_negative.4']
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow dispatch pc=80, inst=SWAP(arg=2, lineno=1143)
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow stack ['$76unary_negative.4', '$x178.5']
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow dispatch pc=82, inst=COPY(arg=2, lineno=1143)
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4']
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow dispatch pc=84, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4', '$x178.5']
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow dispatch pc=90, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow stack ['$x178.5', '$84compare_op.6']
2024-01-20 11:59:53,621 DEBUG numba.core.byteflow end state. edges=[Edge(pc=92, stack=('$x178.5',), blockstack=(), npush=0), Edge(pc=104, stack=('$x178.5',), blockstack=(), npush=0)]
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow pending: deque([State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow stack: []
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=54 nstack_initial=0)
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=1, lineno=1140)
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow stack []
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow dispatch pc=56, inst=STORE_FAST(arg=3, lineno=1140)
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow stack ['$const54.0']
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow pending: deque([State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0)])
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow stack: ['$phi92.0']
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=92 nstack_initial=1)
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow dispatch pc=92, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow stack ['$phi92.0']
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow dispatch pc=94, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow stack ['$phi92.0', '$threshold92.1']
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow dispatch pc=100, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow stack ['$94compare_op.2']
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow end state. edges=[Edge(pc=102, stack=(), blockstack=(), npush=0), Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow pending: deque([State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow stack: ['$phi104.0']
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=104 nstack_initial=1)
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow dispatch pc=104, inst=POP_TOP(arg=None, lineno=1143)
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow stack ['$phi104.0']
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow dispatch pc=106, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow stack []
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow stack: []
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=102 nstack_initial=0)
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow dispatch pc=102, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow stack []
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow end state. edges=[Edge(pc=108, stack=(), blockstack=(), npush=0)]
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0)])
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow stack: []
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=112 nstack_initial=0)
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow dispatch pc=112, inst=LOAD_FAST(arg=2, lineno=1146)
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow stack []
2024-01-20 11:59:53,622 DEBUG numba.core.byteflow dispatch pc=114, inst=POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow stack ['$zero_pos112.0']
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow end state. edges=[Edge(pc=116, stack=(), blockstack=(), npush=0), Edge(pc=200, stack=(), blockstack=(), npush=0)]
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow pending: deque([State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow stack: []
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=108 nstack_initial=0)
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow dispatch pc=108, inst=LOAD_CONST(arg=1, lineno=1144)
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow stack []
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow dispatch pc=110, inst=STORE_FAST(arg=4, lineno=1144)
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow stack ['$const108.0']
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow pending: deque([State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow stack: []
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=116 nstack_initial=0)
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow dispatch pc=116, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow stack []
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow dispatch pc=128, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow stack ['$null$116.1', '$116load_global.0']
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow dispatch pc=138, inst=LOAD_FAST(arg=3, lineno=1147)
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2']
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow dispatch pc=140, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow dispatch pc=144, inst=CALL(arg=1, lineno=1147)
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow dispatch pc=154, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow stack ['$144call.4']
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow dispatch pc=166, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$154load_global.5']
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow dispatch pc=176, inst=LOAD_FAST(arg=4, lineno=1147)
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7']
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow dispatch pc=178, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow dispatch pc=182, inst=CALL(arg=1, lineno=1147)
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow dispatch pc=192, inst=COMPARE_OP(arg=3, lineno=1147)
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow stack ['$144call.4', '$182call.9']
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow dispatch pc=198, inst=RETURN_VALUE(arg=None, lineno=1147)
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow stack ['$192compare_op.10']
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow pending: deque([State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow stack: []
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=200 nstack_initial=0)
2024-01-20 11:59:53,623 DEBUG numba.core.byteflow dispatch pc=200, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow stack []
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow dispatch pc=212, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow stack ['$null$200.1', '$200load_global.0']
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow dispatch pc=222, inst=LOAD_FAST(arg=3, lineno=1149)
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2']
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow dispatch pc=224, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow dispatch pc=228, inst=CALL(arg=1, lineno=1149)
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow dispatch pc=238, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow stack ['$228call.4']
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow dispatch pc=250, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$238load_global.5']
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow dispatch pc=260, inst=LOAD_FAST(arg=4, lineno=1149)
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7']
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow dispatch pc=262, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow dispatch pc=266, inst=CALL(arg=1, lineno=1149)
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow dispatch pc=276, inst=COMPARE_OP(arg=3, lineno=1149)
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow stack ['$228call.4', '$266call.9']
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow dispatch pc=282, inst=RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow stack ['$276compare_op.10']
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0)])
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=38 nstack_initial=1): {'$phi38.0'},
             State(pc_initial=48 nstack_initial=0): set(),
             State(pc_initial=50 nstack_initial=1): set(),
             State(pc_initial=54 nstack_initial=0): set(),
             State(pc_initial=58 nstack_initial=0): set(),
             State(pc_initial=92 nstack_initial=1): {'$phi92.0'},
             State(pc_initial=102 nstack_initial=0): set(),
             State(pc_initial=104 nstack_initial=1): set(),
             State(pc_initial=108 nstack_initial=0): set(),
             State(pc_initial=112 nstack_initial=0): set(),
             State(pc_initial=116 nstack_initial=0): set(),
             State(pc_initial=200 nstack_initial=0): set()})
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow defmap: {'$phi104.0': State(pc_initial=58 nstack_initial=0),
 '$phi38.0': State(pc_initial=0 nstack_initial=0),
 '$phi50.0': State(pc_initial=0 nstack_initial=0),
 '$phi92.0': State(pc_initial=58 nstack_initial=0)}
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 11:59:53,624 DEBUG numba.core.byteflow keep phismap: {'$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
 '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}}
2024-01-20 11:59:53,625 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi38.0': '$x024.5'},
             State(pc_initial=58 nstack_initial=0): {'$phi92.0': '$x178.5'}})
2024-01-20 11:59:53,625 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 11:59:53,625 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'value': '$8binary_subscr.2'}), (20, {'res': '$threshold20.3'}), (22, {'value': '$threshold20.3', 'res': '$22unary_negative.4'}), (24, {'res': '$x024.5'}), (30, {'lhs': '$22unary_negative.4', 'rhs': '$x024.5', 'res': '$30compare_op.6'}), (32, {}), (34, {}), (36, {'pred': '$30compare_op.6'})), outgoing_phis={'$phi38.0': '$x024.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={38: ('$x024.5',), 50: ('$x024.5',)})
2024-01-20 11:59:53,625 DEBUG numba.core.byteflow block_infos State(pc_initial=38 nstack_initial=1):
AdaptBlockInfo(insts=((38, {'res': '$threshold38.1'}), (40, {'lhs': '$phi38.0', 'rhs': '$threshold38.1', 'res': '$40compare_op.2'}), (42, {}), (44, {}), (46, {'pred': '$40compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={48: (), 58: ()})
2024-01-20 11:59:53,625 DEBUG numba.core.byteflow block_infos State(pc_initial=48 nstack_initial=0):
AdaptBlockInfo(insts=((48, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={54: ()})
2024-01-20 11:59:53,625 DEBUG numba.core.byteflow block_infos State(pc_initial=50 nstack_initial=1):
AdaptBlockInfo(insts=((52, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 11:59:53,625 DEBUG numba.core.byteflow block_infos State(pc_initial=54 nstack_initial=0):
AdaptBlockInfo(insts=((54, {'res': '$const54.0'}), (56, {'value': '$const54.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 11:59:53,625 DEBUG numba.core.byteflow block_infos State(pc_initial=58 nstack_initial=0):
AdaptBlockInfo(insts=((58, {'res': '$x58.0'}), (60, {'res': '$const60.1'}), (62, {'index': '$const60.1', 'target': '$x58.0', 'res': '$62binary_subscr.2'}), (64, {}), (66, {}), (68, {}), (70, {}), (72, {'value': '$62binary_subscr.2'}), (74, {'res': '$threshold74.3'}), (76, {'value': '$threshold74.3', 'res': '$76unary_negative.4'}), (78, {'res': '$x178.5'}), (84, {'lhs': '$76unary_negative.4', 'rhs': '$x178.5', 'res': '$84compare_op.6'}), (86, {}), (88, {}), (90, {'pred': '$84compare_op.6'})), outgoing_phis={'$phi92.0': '$x178.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={92: ('$x178.5',), 104: ('$x178.5',)})
2024-01-20 11:59:53,625 DEBUG numba.core.byteflow block_infos State(pc_initial=92 nstack_initial=1):
AdaptBlockInfo(insts=((92, {'res': '$threshold92.1'}), (94, {'lhs': '$phi92.0', 'rhs': '$threshold92.1', 'res': '$94compare_op.2'}), (96, {}), (98, {}), (100, {'pred': '$94compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={102: (), 112: ()})
2024-01-20 11:59:53,625 DEBUG numba.core.byteflow block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={108: ()})
2024-01-20 11:59:53,625 DEBUG numba.core.byteflow block_infos State(pc_initial=104 nstack_initial=1):
AdaptBlockInfo(insts=((106, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 11:59:53,625 DEBUG numba.core.byteflow block_infos State(pc_initial=108 nstack_initial=0):
AdaptBlockInfo(insts=((108, {'res': '$const108.0'}), (110, {'value': '$const108.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 11:59:53,625 DEBUG numba.core.byteflow block_infos State(pc_initial=112 nstack_initial=0):
AdaptBlockInfo(insts=((112, {'res': '$zero_pos112.0'}), (114, {'pred': '$zero_pos112.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={116: (), 200: ()})
2024-01-20 11:59:53,625 DEBUG numba.core.byteflow block_infos State(pc_initial=116 nstack_initial=0):
AdaptBlockInfo(insts=((116, {'idx': 0, 'res': '$116load_global.0'}), (118, {}), (120, {}), (122, {}), (124, {}), (126, {}), (128, {'item': '$116load_global.0', 'res': '$128load_attr.2'}), (130, {}), (132, {}), (134, {}), (136, {}), (138, {'res': '$x0138.3'}), (140, {}), (142, {}), (144, {'func': '$128load_attr.2', 'args': ['$x0138.3'], 'kw_names': None, 'res': '$144call.4'}), (146, {}), (148, {}), (150, {}), (152, {}), (154, {'idx': 0, 'res': '$154load_global.5'}), (156, {}), (158, {}), (160, {}), (162, {}), (164, {}), (166, {'item': '$154load_global.5', 'res': '$166load_attr.7'}), (168, {}), (170, {}), (172, {}), (174, {}), (176, {'res': '$x1176.8'}), (178, {}), (180, {}), (182, {'func': '$166load_attr.7', 'args': ['$x1176.8'], 'kw_names': None, 'res': '$182call.9'}), (184, {}), (186, {}), (188, {}), (190, {}), (192, {'lhs': '$144call.4', 'rhs': '$182call.9', 'res': '$192compare_op.10'}), (194, {}), (196, {}), (198, {'retval': '$192compare_op.10', 'castval': '$198return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 11:59:53,625 DEBUG numba.core.byteflow block_infos State(pc_initial=200 nstack_initial=0):
AdaptBlockInfo(insts=((200, {'idx': 0, 'res': '$200load_global.0'}), (202, {}), (204, {}), (206, {}), (208, {}), (210, {}), (212, {'item': '$200load_global.0', 'res': '$212load_attr.2'}), (214, {}), (216, {}), (218, {}), (220, {}), (222, {'res': '$x0222.3'}), (224, {}), (226, {}), (228, {'func': '$212load_attr.2', 'args': ['$x0222.3'], 'kw_names': None, 'res': '$228call.4'}), (230, {}), (232, {}), (234, {}), (236, {}), (238, {'idx': 0, 'res': '$238load_global.5'}), (240, {}), (242, {}), (244, {}), (246, {}), (248, {}), (250, {'item': '$238load_global.5', 'res': '$250load_attr.7'}), (252, {}), (254, {}), (256, {}), (258, {}), (260, {'res': '$x1260.8'}), (262, {}), (264, {}), (266, {'func': '$250load_attr.7', 'args': ['$x1260.8'], 'kw_names': None, 'res': '$266call.9'}), (268, {}), (270, {}), (272, {}), (274, {}), (276, {'lhs': '$228call.4', 'rhs': '$266call.9', 'res': '$276compare_op.10'}), (278, {}), (280, {}), (282, {'retval': '$276compare_op.10', 'castval': '$282return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 11:59:53,626 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const6.1 = const(int, 0)                ['$const6.1']
    x0 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$const6.1', 'x', 'x0']
    $22unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$22unary_negative.4', 'threshold']
    $30compare_op.6 = $22unary_negative.4 <= x0 ['$22unary_negative.4', '$30compare_op.6', 'x0']
    bool36 = global(bool: <class 'bool'>)    ['bool36']
    $36pred = call bool36($30compare_op.6, func=bool36, args=(Var($30compare_op.6, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$30compare_op.6', '$36pred', 'bool36']
    $phi38.0 = x0                            ['$phi38.0', 'x0']
    branch $36pred, 38, 50                   ['$36pred']
label 38:
    $40compare_op.2 = $phi38.0 <= threshold  ['$40compare_op.2', '$phi38.0', 'threshold']
    bool46 = global(bool: <class 'bool'>)    ['bool46']
    $46pred = call bool46($40compare_op.2, func=bool46, args=(Var($40compare_op.2, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$40compare_op.2', '$46pred', 'bool46']
    branch $46pred, 48, 58                   ['$46pred']
label 48:
    jump 54                                  []
label 50:
    jump 58                                  []
label 54:
    x0 = const(int, 0)                       ['x0']
    jump 58                                  []
label 58:
    $const60.1 = const(int, -1)              ['$const60.1']
    x1 = getitem(value=x, index=$const60.1, fn=<built-in function getitem>) ['$const60.1', 'x', 'x1']
    $76unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$76unary_negative.4', 'threshold']
    $84compare_op.6 = $76unary_negative.4 <= x1 ['$76unary_negative.4', '$84compare_op.6', 'x1']
    bool90 = global(bool: <class 'bool'>)    ['bool90']
    $90pred = call bool90($84compare_op.6, func=bool90, args=(Var($84compare_op.6, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$84compare_op.6', '$90pred', 'bool90']
    $phi92.0 = x1                            ['$phi92.0', 'x1']
    branch $90pred, 92, 104                  ['$90pred']
label 92:
    $94compare_op.2 = $phi92.0 <= threshold  ['$94compare_op.2', '$phi92.0', 'threshold']
    bool100 = global(bool: <class 'bool'>)   ['bool100']
    $100pred = call bool100($94compare_op.2, func=bool100, args=(Var($94compare_op.2, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$100pred', '$94compare_op.2', 'bool100']
    branch $100pred, 102, 112                ['$100pred']
label 102:
    jump 108                                 []
label 104:
    jump 112                                 []
label 108:
    x1 = const(int, 0)                       ['x1']
    jump 112                                 []
label 112:
    bool114 = global(bool: <class 'bool'>)   ['bool114']
    $114pred = call bool114(zero_pos, func=bool114, args=(Var(zero_pos, audio.py:1135),), kws=(), vararg=None, varkwarg=None, target=None) ['$114pred', 'bool114', 'zero_pos']
    branch $114pred, 116, 200                ['$114pred']
label 116:
    $116load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$116load_global.0']
    $128load_attr.2 = getattr(value=$116load_global.0, attr=signbit) ['$116load_global.0', '$128load_attr.2']
    $144call.4 = call $128load_attr.2(x0, func=$128load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$128load_attr.2', '$144call.4', 'x0']
    $154load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$154load_global.5']
    $166load_attr.7 = getattr(value=$154load_global.5, attr=signbit) ['$154load_global.5', '$166load_attr.7']
    $182call.9 = call $166load_attr.7(x1, func=$166load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$166load_attr.7', '$182call.9', 'x1']
    $192compare_op.10 = $144call.4 != $182call.9 ['$144call.4', '$182call.9', '$192compare_op.10']
    $198return_value.11 = cast(value=$192compare_op.10) ['$192compare_op.10', '$198return_value.11']
    return $198return_value.11               ['$198return_value.11']
label 200:
    $200load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$200load_global.0']
    $212load_attr.2 = getattr(value=$200load_global.0, attr=sign) ['$200load_global.0', '$212load_attr.2']
    $228call.4 = call $212load_attr.2(x0, func=$212load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$212load_attr.2', '$228call.4', 'x0']
    $238load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$238load_global.5']
    $250load_attr.7 = getattr(value=$238load_global.5, attr=sign) ['$238load_global.5', '$250load_attr.7']
    $266call.9 = call $250load_attr.7(x1, func=$250load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$250load_attr.7', '$266call.9', 'x1']
    $276compare_op.10 = $228call.4 != $266call.9 ['$228call.4', '$266call.9', '$276compare_op.10']
    $282return_value.11 = cast(value=$276compare_op.10) ['$276compare_op.10', '$282return_value.11']
    return $282return_value.11               ['$282return_value.11']

2024-01-20 11:59:53,856 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1039)
           2	RESUME(arg=0, lineno=1039)
           4	LOAD_FAST(arg=0, lineno=1042)
           6	LOAD_CONST(arg=1, lineno=1042)
           8	BINARY_SUBSCR(arg=None, lineno=1042)
          18	LOAD_FAST(arg=0, lineno=1042)
          20	LOAD_CONST(arg=2, lineno=1042)
          22	BINARY_SUBSCR(arg=None, lineno=1042)
          32	COMPARE_OP(arg=4, lineno=1042)
          38	LOAD_FAST(arg=0, lineno=1042)
          40	LOAD_CONST(arg=1, lineno=1042)
          42	BINARY_SUBSCR(arg=None, lineno=1042)
          52	LOAD_FAST(arg=0, lineno=1042)
          54	LOAD_CONST(arg=3, lineno=1042)
          56	BINARY_SUBSCR(arg=None, lineno=1042)
          66	COMPARE_OP(arg=5, lineno=1042)
          72	BINARY_OP(arg=1, lineno=1042)
          76	RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 11:59:53,856 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 11:59:53,856 DEBUG numba.core.byteflow stack: []
2024-01-20 11:59:53,856 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 11:59:53,856 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1039)
2024-01-20 11:59:53,856 DEBUG numba.core.byteflow stack []
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1039)
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow stack []
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow stack []
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1042)
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=4, lineno=1042)
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1042)
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=5, lineno=1042)
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1042)
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 11:59:53,857 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 11:59:53,858 DEBUG numba.core.byteflow defmap: {}
2024-01-20 11:59:53,858 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 11:59:53,858 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 11:59:53,858 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 11:59:53,858 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 11:59:53,858 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 11:59:53,858 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 11:59:53,858 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 > $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 >= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 11:59:53,859 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1045)
           2	RESUME(arg=0, lineno=1045)
           4	LOAD_FAST(arg=0, lineno=1048)
           6	LOAD_CONST(arg=1, lineno=1048)
           8	BINARY_SUBSCR(arg=None, lineno=1048)
          18	LOAD_FAST(arg=0, lineno=1048)
          20	LOAD_CONST(arg=2, lineno=1048)
          22	BINARY_SUBSCR(arg=None, lineno=1048)
          32	COMPARE_OP(arg=0, lineno=1048)
          38	LOAD_FAST(arg=0, lineno=1048)
          40	LOAD_CONST(arg=1, lineno=1048)
          42	BINARY_SUBSCR(arg=None, lineno=1048)
          52	LOAD_FAST(arg=0, lineno=1048)
          54	LOAD_CONST(arg=3, lineno=1048)
          56	BINARY_SUBSCR(arg=None, lineno=1048)
          66	COMPARE_OP(arg=1, lineno=1048)
          72	BINARY_OP(arg=1, lineno=1048)
          76	RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow stack: []
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1045)
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow stack []
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1045)
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow stack []
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow stack []
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1048)
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=0, lineno=1048)
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1048)
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 11:59:53,859 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 11:59:53,860 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=1, lineno=1048)
2024-01-20 11:59:53,860 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 11:59:53,860 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1048)
2024-01-20 11:59:53,860 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 11:59:53,860 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 11:59:53,860 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 11:59:53,860 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 11:59:53,860 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 11:59:53,860 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 11:59:53,860 DEBUG numba.core.byteflow defmap: {}
2024-01-20 11:59:53,860 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 11:59:53,860 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 11:59:53,860 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 11:59:53,860 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 11:59:53,860 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 11:59:53,860 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 11:59:53,860 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 < $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 <= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 11:59:54,105 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_combined_45bb4136704b429c8e73f1b3722a900a.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 11:59:54,139 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 11:59:54,214 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002215E1267D0>
2024-01-20 11:59:54,214 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000002217F4FC5F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 11:59:54,232 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002216092AAD0>
2024-01-20 11:59:54,232 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 11:59:54,233 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 11:59:54,233 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 11:59:54,292 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 11:59:54,292 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 11:59:55,195 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 10:59:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'411'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3842f442f589fd5ee43f5668d4da0f43'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ELumBFve8sQkxO4RUYctxw6yVUMB2ga8U4Wqeg71vn8-1705748394-1-AZIhlsCDfsenIvVTwdnAf0Nyl1oemOeJOfLJaFkiAFtvZmKuYLjwzV+MJ4EGg8qhTDaDDfDeHcLaSKtQKCpAZv0=; path=/; expires=Sat, 20-Jan-24 11:29:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=4m_RlCQ5FXbp60Ee8wRbuiX6V_u5xKQv7st_MDZ0Oqw-1705748394006-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8486cf809b67190f-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 11:59:55,197 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 11:59:55,197 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 11:59:55,198 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 11:59:55,198 DEBUG httpcore.http11 response_closed.started
2024-01-20 11:59:55,198 DEBUG httpcore.http11 response_closed.complete
2024-01-20 11:59:55,198 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 12:00:19,496 INFO __main__ [WinError 183] Cannot create a file when that file already exists: 'C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\DATA\\test'
2024-01-20 12:00:52,726 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\DATA\\test\\test.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 12:00:52,728 DEBUG httpcore.connection close.started
2024-01-20 12:00:52,728 DEBUG httpcore.connection close.complete
2024-01-20 12:00:52,729 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 12:00:52,773 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002216095D850>
2024-01-20 12:00:52,773 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000002217F4FC5F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 12:00:52,793 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002216095D910>
2024-01-20 12:00:52,794 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 12:00:52,794 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 12:00:52,794 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 12:00:52,867 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 12:00:52,867 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 12:00:53,960 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 11:00:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'467'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'91614ebd31c7bebf1109f7b4a591979b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8486d0ee9c91696a-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 12:00:53,960 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 12:00:53,960 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 12:00:53,961 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 12:00:53,961 DEBUG httpcore.http11 response_closed.started
2024-01-20 12:00:53,961 DEBUG httpcore.http11 response_closed.complete
2024-01-20 12:00:53,961 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 12:01:16,089 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 12:01:16,091 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 12:01:16,345 INFO transcription All nescessary class variables are declared and working!
2024-01-20 12:03:32,185 INFO transcription Current recording SessionID is: fdb98711c801475d8a356ee98d0b1649
2024-01-20 12:03:32,187 INFO transcription Started Microphone Thread for session fdb98711c801475d8a356ee98d0b1649!
2024-01-20 12:03:32,188 INFO transcription Opening Stream for device Microsoft Sound Mapper - Input...
2024-01-20 12:03:32,188 INFO transcription Started System sounds Thread for session fdb98711c801475d8a356ee98d0b1649!
2024-01-20 12:03:32,188 INFO transcription Opening Stream for device Stereo Mix (Realtek USB Audio)...
2024-01-20 12:03:32,203 INFO transcription Stream for Microphone Microsoft Sound Mapper - Input open!
2024-01-20 12:03:32,266 INFO transcription Stream for Microphone Stereo Mix (Realtek USB Audio) open!
2024-01-20 12:03:39,227 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1135)
           2	RESUME(arg=0, lineno=1135)
           4	LOAD_FAST(arg=0, lineno=1138)
           6	LOAD_CONST(arg=1, lineno=1138)
           8	BINARY_SUBSCR(arg=None, lineno=1138)
          18	STORE_FAST(arg=3, lineno=1138)
          20	LOAD_FAST(arg=1, lineno=1139)
          22	UNARY_NEGATIVE(arg=None, lineno=1139)
          24	LOAD_FAST(arg=3, lineno=1139)
          26	SWAP(arg=2, lineno=1139)
          28	COPY(arg=2, lineno=1139)
          30	COMPARE_OP(arg=1, lineno=1139)
          36	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
          38	LOAD_FAST(arg=1, lineno=1139)
          40	COMPARE_OP(arg=1, lineno=1139)
          46	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
          48	JUMP_FORWARD(arg=2, lineno=1139)
>         50	POP_TOP(arg=None, lineno=1139)
          52	JUMP_FORWARD(arg=2, lineno=1139)
>         54	LOAD_CONST(arg=1, lineno=1140)
          56	STORE_FAST(arg=3, lineno=1140)
>         58	LOAD_FAST(arg=0, lineno=1142)
          60	LOAD_CONST(arg=2, lineno=1142)
          62	BINARY_SUBSCR(arg=None, lineno=1142)
          72	STORE_FAST(arg=4, lineno=1142)
          74	LOAD_FAST(arg=1, lineno=1143)
          76	UNARY_NEGATIVE(arg=None, lineno=1143)
          78	LOAD_FAST(arg=4, lineno=1143)
          80	SWAP(arg=2, lineno=1143)
          82	COPY(arg=2, lineno=1143)
          84	COMPARE_OP(arg=1, lineno=1143)
          90	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
          92	LOAD_FAST(arg=1, lineno=1143)
          94	COMPARE_OP(arg=1, lineno=1143)
         100	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
         102	JUMP_FORWARD(arg=2, lineno=1143)
>        104	POP_TOP(arg=None, lineno=1143)
         106	JUMP_FORWARD(arg=2, lineno=1143)
>        108	LOAD_CONST(arg=1, lineno=1144)
         110	STORE_FAST(arg=4, lineno=1144)
>        112	LOAD_FAST(arg=2, lineno=1146)
         114	POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
         116	LOAD_GLOBAL(arg=1, lineno=1147)
         128	LOAD_ATTR(arg=1, lineno=1147)
         138	LOAD_FAST(arg=3, lineno=1147)
         140	PRECALL(arg=1, lineno=1147)
         144	CALL(arg=1, lineno=1147)
         154	LOAD_GLOBAL(arg=1, lineno=1147)
         166	LOAD_ATTR(arg=1, lineno=1147)
         176	LOAD_FAST(arg=4, lineno=1147)
         178	PRECALL(arg=1, lineno=1147)
         182	CALL(arg=1, lineno=1147)
         192	COMPARE_OP(arg=3, lineno=1147)
         198	RETURN_VALUE(arg=None, lineno=1147)
>        200	LOAD_GLOBAL(arg=1, lineno=1149)
         212	LOAD_ATTR(arg=2, lineno=1149)
         222	LOAD_FAST(arg=3, lineno=1149)
         224	PRECALL(arg=1, lineno=1149)
         228	CALL(arg=1, lineno=1149)
         238	LOAD_GLOBAL(arg=1, lineno=1149)
         250	LOAD_ATTR(arg=2, lineno=1149)
         260	LOAD_FAST(arg=4, lineno=1149)
         262	PRECALL(arg=1, lineno=1149)
         266	CALL(arg=1, lineno=1149)
         276	COMPARE_OP(arg=3, lineno=1149)
         282	RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 12:03:39,227 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 12:03:39,227 DEBUG numba.core.byteflow stack: []
2024-01-20 12:03:39,227 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 12:03:39,227 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1135)
2024-01-20 12:03:39,227 DEBUG numba.core.byteflow stack []
2024-01-20 12:03:39,227 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1135)
2024-01-20 12:03:39,227 DEBUG numba.core.byteflow stack []
2024-01-20 12:03:39,227 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1138)
2024-01-20 12:03:39,227 DEBUG numba.core.byteflow stack []
2024-01-20 12:03:39,227 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1138)
2024-01-20 12:03:39,227 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1138)
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow dispatch pc=18, inst=STORE_FAST(arg=3, lineno=1138)
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow stack []
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow dispatch pc=22, inst=UNARY_NEGATIVE(arg=None, lineno=1139)
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow stack ['$threshold20.3']
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow dispatch pc=24, inst=LOAD_FAST(arg=3, lineno=1139)
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow stack ['$22unary_negative.4']
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow dispatch pc=26, inst=SWAP(arg=2, lineno=1139)
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow stack ['$22unary_negative.4', '$x024.5']
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow dispatch pc=28, inst=COPY(arg=2, lineno=1139)
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4']
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow dispatch pc=30, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4', '$x024.5']
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow dispatch pc=36, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow stack ['$x024.5', '$30compare_op.6']
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow end state. edges=[Edge(pc=38, stack=('$x024.5',), blockstack=(), npush=0), Edge(pc=50, stack=('$x024.5',), blockstack=(), npush=0)]
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow pending: deque([State(pc_initial=38 nstack_initial=1), State(pc_initial=50 nstack_initial=1)])
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow stack: ['$phi38.0']
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=38 nstack_initial=1)
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow stack ['$phi38.0']
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow dispatch pc=40, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow stack ['$phi38.0', '$threshold38.1']
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow dispatch pc=46, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow stack ['$40compare_op.2']
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow end state. edges=[Edge(pc=48, stack=(), blockstack=(), npush=0), Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow pending: deque([State(pc_initial=50 nstack_initial=1), State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow stack: ['$phi50.0']
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=50 nstack_initial=1)
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow dispatch pc=50, inst=POP_TOP(arg=None, lineno=1139)
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow stack ['$phi50.0']
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow dispatch pc=52, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow stack []
2024-01-20 12:03:39,228 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow pending: deque([State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow stack: []
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=48 nstack_initial=0)
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow dispatch pc=48, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow stack []
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow end state. edges=[Edge(pc=54, stack=(), blockstack=(), npush=0)]
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0)])
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow stack: []
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=58 nstack_initial=0)
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow dispatch pc=58, inst=LOAD_FAST(arg=0, lineno=1142)
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow stack []
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow dispatch pc=60, inst=LOAD_CONST(arg=2, lineno=1142)
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow stack ['$x58.0']
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow dispatch pc=62, inst=BINARY_SUBSCR(arg=None, lineno=1142)
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow stack ['$x58.0', '$const60.1']
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow dispatch pc=72, inst=STORE_FAST(arg=4, lineno=1142)
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow stack ['$62binary_subscr.2']
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow dispatch pc=74, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow stack []
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow dispatch pc=76, inst=UNARY_NEGATIVE(arg=None, lineno=1143)
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow stack ['$threshold74.3']
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow dispatch pc=78, inst=LOAD_FAST(arg=4, lineno=1143)
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow stack ['$76unary_negative.4']
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow dispatch pc=80, inst=SWAP(arg=2, lineno=1143)
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow stack ['$76unary_negative.4', '$x178.5']
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow dispatch pc=82, inst=COPY(arg=2, lineno=1143)
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4']
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow dispatch pc=84, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4', '$x178.5']
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow dispatch pc=90, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow stack ['$x178.5', '$84compare_op.6']
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow end state. edges=[Edge(pc=92, stack=('$x178.5',), blockstack=(), npush=0), Edge(pc=104, stack=('$x178.5',), blockstack=(), npush=0)]
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow pending: deque([State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow stack: []
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=54 nstack_initial=0)
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=1, lineno=1140)
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow stack []
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow dispatch pc=56, inst=STORE_FAST(arg=3, lineno=1140)
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow stack ['$const54.0']
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow pending: deque([State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0)])
2024-01-20 12:03:39,229 DEBUG numba.core.byteflow stack: ['$phi92.0']
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=92 nstack_initial=1)
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow dispatch pc=92, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow stack ['$phi92.0']
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow dispatch pc=94, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow stack ['$phi92.0', '$threshold92.1']
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow dispatch pc=100, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow stack ['$94compare_op.2']
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow end state. edges=[Edge(pc=102, stack=(), blockstack=(), npush=0), Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow pending: deque([State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow stack: ['$phi104.0']
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=104 nstack_initial=1)
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow dispatch pc=104, inst=POP_TOP(arg=None, lineno=1143)
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow stack ['$phi104.0']
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow dispatch pc=106, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow stack []
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow stack: []
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=102 nstack_initial=0)
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow dispatch pc=102, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow stack []
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow end state. edges=[Edge(pc=108, stack=(), blockstack=(), npush=0)]
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0)])
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow stack: []
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=112 nstack_initial=0)
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow dispatch pc=112, inst=LOAD_FAST(arg=2, lineno=1146)
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow stack []
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow dispatch pc=114, inst=POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow stack ['$zero_pos112.0']
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow end state. edges=[Edge(pc=116, stack=(), blockstack=(), npush=0), Edge(pc=200, stack=(), blockstack=(), npush=0)]
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow pending: deque([State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow stack: []
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=108 nstack_initial=0)
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow dispatch pc=108, inst=LOAD_CONST(arg=1, lineno=1144)
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow stack []
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow dispatch pc=110, inst=STORE_FAST(arg=4, lineno=1144)
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow stack ['$const108.0']
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow pending: deque([State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow stack: []
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=116 nstack_initial=0)
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow dispatch pc=116, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 12:03:39,230 DEBUG numba.core.byteflow stack []
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow dispatch pc=128, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow stack ['$null$116.1', '$116load_global.0']
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow dispatch pc=138, inst=LOAD_FAST(arg=3, lineno=1147)
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2']
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow dispatch pc=140, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow dispatch pc=144, inst=CALL(arg=1, lineno=1147)
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow dispatch pc=154, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow stack ['$144call.4']
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow dispatch pc=166, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$154load_global.5']
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow dispatch pc=176, inst=LOAD_FAST(arg=4, lineno=1147)
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7']
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow dispatch pc=178, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow dispatch pc=182, inst=CALL(arg=1, lineno=1147)
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow dispatch pc=192, inst=COMPARE_OP(arg=3, lineno=1147)
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow stack ['$144call.4', '$182call.9']
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow dispatch pc=198, inst=RETURN_VALUE(arg=None, lineno=1147)
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow stack ['$192compare_op.10']
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow pending: deque([State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow stack: []
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=200 nstack_initial=0)
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow dispatch pc=200, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow stack []
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow dispatch pc=212, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow stack ['$null$200.1', '$200load_global.0']
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow dispatch pc=222, inst=LOAD_FAST(arg=3, lineno=1149)
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2']
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow dispatch pc=224, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow dispatch pc=228, inst=CALL(arg=1, lineno=1149)
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow dispatch pc=238, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow stack ['$228call.4']
2024-01-20 12:03:39,231 DEBUG numba.core.byteflow dispatch pc=250, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$238load_global.5']
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow dispatch pc=260, inst=LOAD_FAST(arg=4, lineno=1149)
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7']
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow dispatch pc=262, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow dispatch pc=266, inst=CALL(arg=1, lineno=1149)
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow dispatch pc=276, inst=COMPARE_OP(arg=3, lineno=1149)
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow stack ['$228call.4', '$266call.9']
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow dispatch pc=282, inst=RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow stack ['$276compare_op.10']
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=38 nstack_initial=1): {'$phi38.0'},
             State(pc_initial=48 nstack_initial=0): set(),
             State(pc_initial=50 nstack_initial=1): set(),
             State(pc_initial=54 nstack_initial=0): set(),
             State(pc_initial=58 nstack_initial=0): set(),
             State(pc_initial=92 nstack_initial=1): {'$phi92.0'},
             State(pc_initial=102 nstack_initial=0): set(),
             State(pc_initial=104 nstack_initial=1): set(),
             State(pc_initial=108 nstack_initial=0): set(),
             State(pc_initial=112 nstack_initial=0): set(),
             State(pc_initial=116 nstack_initial=0): set(),
             State(pc_initial=200 nstack_initial=0): set()})
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow defmap: {'$phi104.0': State(pc_initial=58 nstack_initial=0),
 '$phi38.0': State(pc_initial=0 nstack_initial=0),
 '$phi50.0': State(pc_initial=0 nstack_initial=0),
 '$phi92.0': State(pc_initial=58 nstack_initial=0)}
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow keep phismap: {'$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
 '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}}
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi38.0': '$x024.5'},
             State(pc_initial=58 nstack_initial=0): {'$phi92.0': '$x178.5'}})
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'value': '$8binary_subscr.2'}), (20, {'res': '$threshold20.3'}), (22, {'value': '$threshold20.3', 'res': '$22unary_negative.4'}), (24, {'res': '$x024.5'}), (30, {'lhs': '$22unary_negative.4', 'rhs': '$x024.5', 'res': '$30compare_op.6'}), (32, {}), (34, {}), (36, {'pred': '$30compare_op.6'})), outgoing_phis={'$phi38.0': '$x024.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={38: ('$x024.5',), 50: ('$x024.5',)})
2024-01-20 12:03:39,232 DEBUG numba.core.byteflow block_infos State(pc_initial=38 nstack_initial=1):
AdaptBlockInfo(insts=((38, {'res': '$threshold38.1'}), (40, {'lhs': '$phi38.0', 'rhs': '$threshold38.1', 'res': '$40compare_op.2'}), (42, {}), (44, {}), (46, {'pred': '$40compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={48: (), 58: ()})
2024-01-20 12:03:39,233 DEBUG numba.core.byteflow block_infos State(pc_initial=48 nstack_initial=0):
AdaptBlockInfo(insts=((48, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={54: ()})
2024-01-20 12:03:39,233 DEBUG numba.core.byteflow block_infos State(pc_initial=50 nstack_initial=1):
AdaptBlockInfo(insts=((52, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 12:03:39,233 DEBUG numba.core.byteflow block_infos State(pc_initial=54 nstack_initial=0):
AdaptBlockInfo(insts=((54, {'res': '$const54.0'}), (56, {'value': '$const54.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 12:03:39,233 DEBUG numba.core.byteflow block_infos State(pc_initial=58 nstack_initial=0):
AdaptBlockInfo(insts=((58, {'res': '$x58.0'}), (60, {'res': '$const60.1'}), (62, {'index': '$const60.1', 'target': '$x58.0', 'res': '$62binary_subscr.2'}), (64, {}), (66, {}), (68, {}), (70, {}), (72, {'value': '$62binary_subscr.2'}), (74, {'res': '$threshold74.3'}), (76, {'value': '$threshold74.3', 'res': '$76unary_negative.4'}), (78, {'res': '$x178.5'}), (84, {'lhs': '$76unary_negative.4', 'rhs': '$x178.5', 'res': '$84compare_op.6'}), (86, {}), (88, {}), (90, {'pred': '$84compare_op.6'})), outgoing_phis={'$phi92.0': '$x178.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={92: ('$x178.5',), 104: ('$x178.5',)})
2024-01-20 12:03:39,233 DEBUG numba.core.byteflow block_infos State(pc_initial=92 nstack_initial=1):
AdaptBlockInfo(insts=((92, {'res': '$threshold92.1'}), (94, {'lhs': '$phi92.0', 'rhs': '$threshold92.1', 'res': '$94compare_op.2'}), (96, {}), (98, {}), (100, {'pred': '$94compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={102: (), 112: ()})
2024-01-20 12:03:39,233 DEBUG numba.core.byteflow block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={108: ()})
2024-01-20 12:03:39,233 DEBUG numba.core.byteflow block_infos State(pc_initial=104 nstack_initial=1):
AdaptBlockInfo(insts=((106, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 12:03:39,233 DEBUG numba.core.byteflow block_infos State(pc_initial=108 nstack_initial=0):
AdaptBlockInfo(insts=((108, {'res': '$const108.0'}), (110, {'value': '$const108.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 12:03:39,233 DEBUG numba.core.byteflow block_infos State(pc_initial=112 nstack_initial=0):
AdaptBlockInfo(insts=((112, {'res': '$zero_pos112.0'}), (114, {'pred': '$zero_pos112.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={116: (), 200: ()})
2024-01-20 12:03:39,233 DEBUG numba.core.byteflow block_infos State(pc_initial=116 nstack_initial=0):
AdaptBlockInfo(insts=((116, {'idx': 0, 'res': '$116load_global.0'}), (118, {}), (120, {}), (122, {}), (124, {}), (126, {}), (128, {'item': '$116load_global.0', 'res': '$128load_attr.2'}), (130, {}), (132, {}), (134, {}), (136, {}), (138, {'res': '$x0138.3'}), (140, {}), (142, {}), (144, {'func': '$128load_attr.2', 'args': ['$x0138.3'], 'kw_names': None, 'res': '$144call.4'}), (146, {}), (148, {}), (150, {}), (152, {}), (154, {'idx': 0, 'res': '$154load_global.5'}), (156, {}), (158, {}), (160, {}), (162, {}), (164, {}), (166, {'item': '$154load_global.5', 'res': '$166load_attr.7'}), (168, {}), (170, {}), (172, {}), (174, {}), (176, {'res': '$x1176.8'}), (178, {}), (180, {}), (182, {'func': '$166load_attr.7', 'args': ['$x1176.8'], 'kw_names': None, 'res': '$182call.9'}), (184, {}), (186, {}), (188, {}), (190, {}), (192, {'lhs': '$144call.4', 'rhs': '$182call.9', 'res': '$192compare_op.10'}), (194, {}), (196, {}), (198, {'retval': '$192compare_op.10', 'castval': '$198return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:03:39,233 DEBUG numba.core.byteflow block_infos State(pc_initial=200 nstack_initial=0):
AdaptBlockInfo(insts=((200, {'idx': 0, 'res': '$200load_global.0'}), (202, {}), (204, {}), (206, {}), (208, {}), (210, {}), (212, {'item': '$200load_global.0', 'res': '$212load_attr.2'}), (214, {}), (216, {}), (218, {}), (220, {}), (222, {'res': '$x0222.3'}), (224, {}), (226, {}), (228, {'func': '$212load_attr.2', 'args': ['$x0222.3'], 'kw_names': None, 'res': '$228call.4'}), (230, {}), (232, {}), (234, {}), (236, {}), (238, {'idx': 0, 'res': '$238load_global.5'}), (240, {}), (242, {}), (244, {}), (246, {}), (248, {}), (250, {'item': '$238load_global.5', 'res': '$250load_attr.7'}), (252, {}), (254, {}), (256, {}), (258, {}), (260, {'res': '$x1260.8'}), (262, {}), (264, {}), (266, {'func': '$250load_attr.7', 'args': ['$x1260.8'], 'kw_names': None, 'res': '$266call.9'}), (268, {}), (270, {}), (272, {}), (274, {}), (276, {'lhs': '$228call.4', 'rhs': '$266call.9', 'res': '$276compare_op.10'}), (278, {}), (280, {}), (282, {'retval': '$276compare_op.10', 'castval': '$282return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:03:39,234 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const6.1 = const(int, 0)                ['$const6.1']
    x0 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$const6.1', 'x', 'x0']
    $22unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$22unary_negative.4', 'threshold']
    $30compare_op.6 = $22unary_negative.4 <= x0 ['$22unary_negative.4', '$30compare_op.6', 'x0']
    bool36 = global(bool: <class 'bool'>)    ['bool36']
    $36pred = call bool36($30compare_op.6, func=bool36, args=(Var($30compare_op.6, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$30compare_op.6', '$36pred', 'bool36']
    $phi38.0 = x0                            ['$phi38.0', 'x0']
    branch $36pred, 38, 50                   ['$36pred']
label 38:
    $40compare_op.2 = $phi38.0 <= threshold  ['$40compare_op.2', '$phi38.0', 'threshold']
    bool46 = global(bool: <class 'bool'>)    ['bool46']
    $46pred = call bool46($40compare_op.2, func=bool46, args=(Var($40compare_op.2, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$40compare_op.2', '$46pred', 'bool46']
    branch $46pred, 48, 58                   ['$46pred']
label 48:
    jump 54                                  []
label 50:
    jump 58                                  []
label 54:
    x0 = const(int, 0)                       ['x0']
    jump 58                                  []
label 58:
    $const60.1 = const(int, -1)              ['$const60.1']
    x1 = getitem(value=x, index=$const60.1, fn=<built-in function getitem>) ['$const60.1', 'x', 'x1']
    $76unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$76unary_negative.4', 'threshold']
    $84compare_op.6 = $76unary_negative.4 <= x1 ['$76unary_negative.4', '$84compare_op.6', 'x1']
    bool90 = global(bool: <class 'bool'>)    ['bool90']
    $90pred = call bool90($84compare_op.6, func=bool90, args=(Var($84compare_op.6, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$84compare_op.6', '$90pred', 'bool90']
    $phi92.0 = x1                            ['$phi92.0', 'x1']
    branch $90pred, 92, 104                  ['$90pred']
label 92:
    $94compare_op.2 = $phi92.0 <= threshold  ['$94compare_op.2', '$phi92.0', 'threshold']
    bool100 = global(bool: <class 'bool'>)   ['bool100']
    $100pred = call bool100($94compare_op.2, func=bool100, args=(Var($94compare_op.2, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$100pred', '$94compare_op.2', 'bool100']
    branch $100pred, 102, 112                ['$100pred']
label 102:
    jump 108                                 []
label 104:
    jump 112                                 []
label 108:
    x1 = const(int, 0)                       ['x1']
    jump 112                                 []
label 112:
    bool114 = global(bool: <class 'bool'>)   ['bool114']
    $114pred = call bool114(zero_pos, func=bool114, args=(Var(zero_pos, audio.py:1135),), kws=(), vararg=None, varkwarg=None, target=None) ['$114pred', 'bool114', 'zero_pos']
    branch $114pred, 116, 200                ['$114pred']
label 116:
    $116load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$116load_global.0']
    $128load_attr.2 = getattr(value=$116load_global.0, attr=signbit) ['$116load_global.0', '$128load_attr.2']
    $144call.4 = call $128load_attr.2(x0, func=$128load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$128load_attr.2', '$144call.4', 'x0']
    $154load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$154load_global.5']
    $166load_attr.7 = getattr(value=$154load_global.5, attr=signbit) ['$154load_global.5', '$166load_attr.7']
    $182call.9 = call $166load_attr.7(x1, func=$166load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$166load_attr.7', '$182call.9', 'x1']
    $192compare_op.10 = $144call.4 != $182call.9 ['$144call.4', '$182call.9', '$192compare_op.10']
    $198return_value.11 = cast(value=$192compare_op.10) ['$192compare_op.10', '$198return_value.11']
    return $198return_value.11               ['$198return_value.11']
label 200:
    $200load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$200load_global.0']
    $212load_attr.2 = getattr(value=$200load_global.0, attr=sign) ['$200load_global.0', '$212load_attr.2']
    $228call.4 = call $212load_attr.2(x0, func=$212load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$212load_attr.2', '$228call.4', 'x0']
    $238load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$238load_global.5']
    $250load_attr.7 = getattr(value=$238load_global.5, attr=sign) ['$238load_global.5', '$250load_attr.7']
    $266call.9 = call $250load_attr.7(x1, func=$250load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$250load_attr.7', '$266call.9', 'x1']
    $276compare_op.10 = $228call.4 != $266call.9 ['$228call.4', '$266call.9', '$276compare_op.10']
    $282return_value.11 = cast(value=$276compare_op.10) ['$276compare_op.10', '$282return_value.11']
    return $282return_value.11               ['$282return_value.11']

2024-01-20 12:03:39,467 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1039)
           2	RESUME(arg=0, lineno=1039)
           4	LOAD_FAST(arg=0, lineno=1042)
           6	LOAD_CONST(arg=1, lineno=1042)
           8	BINARY_SUBSCR(arg=None, lineno=1042)
          18	LOAD_FAST(arg=0, lineno=1042)
          20	LOAD_CONST(arg=2, lineno=1042)
          22	BINARY_SUBSCR(arg=None, lineno=1042)
          32	COMPARE_OP(arg=4, lineno=1042)
          38	LOAD_FAST(arg=0, lineno=1042)
          40	LOAD_CONST(arg=1, lineno=1042)
          42	BINARY_SUBSCR(arg=None, lineno=1042)
          52	LOAD_FAST(arg=0, lineno=1042)
          54	LOAD_CONST(arg=3, lineno=1042)
          56	BINARY_SUBSCR(arg=None, lineno=1042)
          66	COMPARE_OP(arg=5, lineno=1042)
          72	BINARY_OP(arg=1, lineno=1042)
          76	RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow stack: []
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1039)
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow stack []
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1039)
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow stack []
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow stack []
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1042)
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=4, lineno=1042)
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1042)
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=5, lineno=1042)
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1042)
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 12:03:39,468 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 12:03:39,469 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 12:03:39,469 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:03:39,469 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 12:03:39,469 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 12:03:39,469 DEBUG numba.core.byteflow defmap: {}
2024-01-20 12:03:39,469 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:03:39,469 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:03:39,469 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 12:03:39,469 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 12:03:39,469 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 12:03:39,469 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:03:39,469 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 > $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 >= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 12:03:39,470 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1045)
           2	RESUME(arg=0, lineno=1045)
           4	LOAD_FAST(arg=0, lineno=1048)
           6	LOAD_CONST(arg=1, lineno=1048)
           8	BINARY_SUBSCR(arg=None, lineno=1048)
          18	LOAD_FAST(arg=0, lineno=1048)
          20	LOAD_CONST(arg=2, lineno=1048)
          22	BINARY_SUBSCR(arg=None, lineno=1048)
          32	COMPARE_OP(arg=0, lineno=1048)
          38	LOAD_FAST(arg=0, lineno=1048)
          40	LOAD_CONST(arg=1, lineno=1048)
          42	BINARY_SUBSCR(arg=None, lineno=1048)
          52	LOAD_FAST(arg=0, lineno=1048)
          54	LOAD_CONST(arg=3, lineno=1048)
          56	BINARY_SUBSCR(arg=None, lineno=1048)
          66	COMPARE_OP(arg=1, lineno=1048)
          72	BINARY_OP(arg=1, lineno=1048)
          76	RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow stack: []
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1045)
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow stack []
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1045)
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow stack []
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow stack []
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1048)
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=0, lineno=1048)
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:03:39,470 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 12:03:39,471 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1048)
2024-01-20 12:03:39,471 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 12:03:39,471 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:03:39,471 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 12:03:39,471 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=1, lineno=1048)
2024-01-20 12:03:39,471 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 12:03:39,471 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1048)
2024-01-20 12:03:39,471 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 12:03:39,471 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 12:03:39,471 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 12:03:39,471 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:03:39,471 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 12:03:39,471 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 12:03:39,471 DEBUG numba.core.byteflow defmap: {}
2024-01-20 12:03:39,471 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:03:39,471 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:03:39,471 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 12:03:39,471 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 12:03:39,471 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 12:03:39,471 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:03:39,471 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 < $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 <= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 12:03:39,719 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_combined_6074433f55d1407c9a8e4fbb2c746f46.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 12:03:39,752 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 12:03:39,828 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FDEA814610>
2024-01-20 12:03:39,828 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001FDB6170320> server_hostname='api.openai.com' timeout=5.0
2024-01-20 12:03:39,847 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FDEA7A6B50>
2024-01-20 12:03:39,847 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 12:03:39,848 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 12:03:39,848 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 12:03:39,908 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 12:03:39,909 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 12:03:40,817 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 11:03:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'388'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'11595bb730e7f927bdf7526e1bcc88c1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=AMrlsZT4g7PW7yCiTYpgqeYOcACjvyx5lKvRZVSnkL0-1705748619-1-AVq8HZugHcOw7GWbazLxqOx7Xbe44MOJ7QAVxqGXBYMvO97NkR1Zsrrsj1AEh3jOVB6Rw+bQWYZeyiCV818tDNY=; path=/; expires=Sat, 20-Jan-24 11:33:39 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=lGqHqV6nwSfXBlrrK9bNM_S7jLdRXxFV5HI73gOA6b0-1705748619623-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8486d502aeaf900c-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 12:03:40,819 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 12:03:40,819 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 12:03:40,819 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 12:03:40,819 DEBUG httpcore.http11 response_closed.started
2024-01-20 12:03:40,820 DEBUG httpcore.http11 response_closed.complete
2024-01-20 12:03:40,820 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 12:13:03,781 INFO transcription Current recording SessionID is: 3edcb8854b1744109a3317f384df4158
2024-01-20 12:13:03,782 INFO transcription Started Microphone Thread for session 3edcb8854b1744109a3317f384df4158!
2024-01-20 12:13:03,783 INFO transcription Opening Stream for device Microsoft Sound Mapper - Input...
2024-01-20 12:13:03,784 INFO transcription Started System sounds Thread for session 3edcb8854b1744109a3317f384df4158!
2024-01-20 12:13:03,784 INFO transcription Opening Stream for device Stereo Mix (Realtek USB Audio)...
2024-01-20 12:13:03,791 INFO transcription Stream for Microphone Microsoft Sound Mapper - Input open!
2024-01-20 12:13:03,852 INFO transcription Stream for Microphone Stereo Mix (Realtek USB Audio) open!
2024-01-20 12:13:10,836 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_combined_a959019eecb24a91a891a7e8abdc052f.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 12:13:10,838 DEBUG httpcore.connection close.started
2024-01-20 12:13:10,838 DEBUG httpcore.connection close.complete
2024-01-20 12:13:10,838 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 12:13:10,922 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FDEA8D1590>
2024-01-20 12:13:10,922 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001FDB6170320> server_hostname='api.openai.com' timeout=5.0
2024-01-20 12:13:10,945 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FDEA8E4C50>
2024-01-20 12:13:10,945 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 12:13:10,945 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 12:13:10,946 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 12:13:11,055 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 12:13:11,055 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 12:13:12,149 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 11:13:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'359'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a2ee316f51e7b172ebdb9e3ac77fcd35'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8486e2f3ff4b1ca9-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 12:13:12,150 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 12:13:12,150 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 12:13:12,150 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 12:13:12,150 DEBUG httpcore.http11 response_closed.started
2024-01-20 12:13:12,150 DEBUG httpcore.http11 response_closed.complete
2024-01-20 12:13:12,150 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 12:14:08,319 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 12:14:08,321 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 12:14:08,557 INFO transcription All nescessary class variables are declared and working!
2024-01-20 12:14:30,996 INFO transcription Current recording SessionID is: e0c275442dac49ffb4f8544dc25a81e8
2024-01-20 12:14:30,998 INFO transcription Started Microphone Thread for session e0c275442dac49ffb4f8544dc25a81e8!
2024-01-20 12:14:30,999 INFO transcription Opening Stream for device Microsoft Sound Mapper - Input...
2024-01-20 12:14:30,999 INFO transcription Started System sounds Thread for session e0c275442dac49ffb4f8544dc25a81e8!
2024-01-20 12:14:31,000 INFO transcription Opening Stream for device Stereo Mix (Realtek USB Audio)...
2024-01-20 12:14:31,014 INFO transcription Stream for Microphone Microsoft Sound Mapper - Input open!
2024-01-20 12:14:31,073 INFO transcription Stream for Microphone Stereo Mix (Realtek USB Audio) open!
2024-01-20 12:14:38,995 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1135)
           2	RESUME(arg=0, lineno=1135)
           4	LOAD_FAST(arg=0, lineno=1138)
           6	LOAD_CONST(arg=1, lineno=1138)
           8	BINARY_SUBSCR(arg=None, lineno=1138)
          18	STORE_FAST(arg=3, lineno=1138)
          20	LOAD_FAST(arg=1, lineno=1139)
          22	UNARY_NEGATIVE(arg=None, lineno=1139)
          24	LOAD_FAST(arg=3, lineno=1139)
          26	SWAP(arg=2, lineno=1139)
          28	COPY(arg=2, lineno=1139)
          30	COMPARE_OP(arg=1, lineno=1139)
          36	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
          38	LOAD_FAST(arg=1, lineno=1139)
          40	COMPARE_OP(arg=1, lineno=1139)
          46	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
          48	JUMP_FORWARD(arg=2, lineno=1139)
>         50	POP_TOP(arg=None, lineno=1139)
          52	JUMP_FORWARD(arg=2, lineno=1139)
>         54	LOAD_CONST(arg=1, lineno=1140)
          56	STORE_FAST(arg=3, lineno=1140)
>         58	LOAD_FAST(arg=0, lineno=1142)
          60	LOAD_CONST(arg=2, lineno=1142)
          62	BINARY_SUBSCR(arg=None, lineno=1142)
          72	STORE_FAST(arg=4, lineno=1142)
          74	LOAD_FAST(arg=1, lineno=1143)
          76	UNARY_NEGATIVE(arg=None, lineno=1143)
          78	LOAD_FAST(arg=4, lineno=1143)
          80	SWAP(arg=2, lineno=1143)
          82	COPY(arg=2, lineno=1143)
          84	COMPARE_OP(arg=1, lineno=1143)
          90	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
          92	LOAD_FAST(arg=1, lineno=1143)
          94	COMPARE_OP(arg=1, lineno=1143)
         100	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
         102	JUMP_FORWARD(arg=2, lineno=1143)
>        104	POP_TOP(arg=None, lineno=1143)
         106	JUMP_FORWARD(arg=2, lineno=1143)
>        108	LOAD_CONST(arg=1, lineno=1144)
         110	STORE_FAST(arg=4, lineno=1144)
>        112	LOAD_FAST(arg=2, lineno=1146)
         114	POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
         116	LOAD_GLOBAL(arg=1, lineno=1147)
         128	LOAD_ATTR(arg=1, lineno=1147)
         138	LOAD_FAST(arg=3, lineno=1147)
         140	PRECALL(arg=1, lineno=1147)
         144	CALL(arg=1, lineno=1147)
         154	LOAD_GLOBAL(arg=1, lineno=1147)
         166	LOAD_ATTR(arg=1, lineno=1147)
         176	LOAD_FAST(arg=4, lineno=1147)
         178	PRECALL(arg=1, lineno=1147)
         182	CALL(arg=1, lineno=1147)
         192	COMPARE_OP(arg=3, lineno=1147)
         198	RETURN_VALUE(arg=None, lineno=1147)
>        200	LOAD_GLOBAL(arg=1, lineno=1149)
         212	LOAD_ATTR(arg=2, lineno=1149)
         222	LOAD_FAST(arg=3, lineno=1149)
         224	PRECALL(arg=1, lineno=1149)
         228	CALL(arg=1, lineno=1149)
         238	LOAD_GLOBAL(arg=1, lineno=1149)
         250	LOAD_ATTR(arg=2, lineno=1149)
         260	LOAD_FAST(arg=4, lineno=1149)
         262	PRECALL(arg=1, lineno=1149)
         266	CALL(arg=1, lineno=1149)
         276	COMPARE_OP(arg=3, lineno=1149)
         282	RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 12:14:38,995 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow stack: []
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1135)
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow stack []
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1135)
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow stack []
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1138)
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow stack []
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1138)
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1138)
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow dispatch pc=18, inst=STORE_FAST(arg=3, lineno=1138)
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow stack []
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow dispatch pc=22, inst=UNARY_NEGATIVE(arg=None, lineno=1139)
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow stack ['$threshold20.3']
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow dispatch pc=24, inst=LOAD_FAST(arg=3, lineno=1139)
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow stack ['$22unary_negative.4']
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow dispatch pc=26, inst=SWAP(arg=2, lineno=1139)
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow stack ['$22unary_negative.4', '$x024.5']
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow dispatch pc=28, inst=COPY(arg=2, lineno=1139)
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4']
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow dispatch pc=30, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4', '$x024.5']
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow dispatch pc=36, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow stack ['$x024.5', '$30compare_op.6']
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow end state. edges=[Edge(pc=38, stack=('$x024.5',), blockstack=(), npush=0), Edge(pc=50, stack=('$x024.5',), blockstack=(), npush=0)]
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow pending: deque([State(pc_initial=38 nstack_initial=1), State(pc_initial=50 nstack_initial=1)])
2024-01-20 12:14:38,996 DEBUG numba.core.byteflow stack: ['$phi38.0']
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=38 nstack_initial=1)
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow stack ['$phi38.0']
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow dispatch pc=40, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow stack ['$phi38.0', '$threshold38.1']
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow dispatch pc=46, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow stack ['$40compare_op.2']
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow end state. edges=[Edge(pc=48, stack=(), blockstack=(), npush=0), Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow pending: deque([State(pc_initial=50 nstack_initial=1), State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow stack: ['$phi50.0']
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=50 nstack_initial=1)
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow dispatch pc=50, inst=POP_TOP(arg=None, lineno=1139)
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow stack ['$phi50.0']
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow dispatch pc=52, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow stack []
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow pending: deque([State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow stack: []
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=48 nstack_initial=0)
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow dispatch pc=48, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow stack []
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow end state. edges=[Edge(pc=54, stack=(), blockstack=(), npush=0)]
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0)])
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow stack: []
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=58 nstack_initial=0)
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow dispatch pc=58, inst=LOAD_FAST(arg=0, lineno=1142)
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow stack []
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow dispatch pc=60, inst=LOAD_CONST(arg=2, lineno=1142)
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow stack ['$x58.0']
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow dispatch pc=62, inst=BINARY_SUBSCR(arg=None, lineno=1142)
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow stack ['$x58.0', '$const60.1']
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow dispatch pc=72, inst=STORE_FAST(arg=4, lineno=1142)
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow stack ['$62binary_subscr.2']
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow dispatch pc=74, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow stack []
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow dispatch pc=76, inst=UNARY_NEGATIVE(arg=None, lineno=1143)
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow stack ['$threshold74.3']
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow dispatch pc=78, inst=LOAD_FAST(arg=4, lineno=1143)
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow stack ['$76unary_negative.4']
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow dispatch pc=80, inst=SWAP(arg=2, lineno=1143)
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow stack ['$76unary_negative.4', '$x178.5']
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow dispatch pc=82, inst=COPY(arg=2, lineno=1143)
2024-01-20 12:14:38,997 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4']
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow dispatch pc=84, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4', '$x178.5']
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow dispatch pc=90, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow stack ['$x178.5', '$84compare_op.6']
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow end state. edges=[Edge(pc=92, stack=('$x178.5',), blockstack=(), npush=0), Edge(pc=104, stack=('$x178.5',), blockstack=(), npush=0)]
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow pending: deque([State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow stack: []
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=54 nstack_initial=0)
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=1, lineno=1140)
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow stack []
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow dispatch pc=56, inst=STORE_FAST(arg=3, lineno=1140)
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow stack ['$const54.0']
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow pending: deque([State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0)])
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow stack: ['$phi92.0']
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=92 nstack_initial=1)
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow dispatch pc=92, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow stack ['$phi92.0']
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow dispatch pc=94, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow stack ['$phi92.0', '$threshold92.1']
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow dispatch pc=100, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow stack ['$94compare_op.2']
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow end state. edges=[Edge(pc=102, stack=(), blockstack=(), npush=0), Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow pending: deque([State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow stack: ['$phi104.0']
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=104 nstack_initial=1)
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow dispatch pc=104, inst=POP_TOP(arg=None, lineno=1143)
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow stack ['$phi104.0']
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow dispatch pc=106, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow stack []
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow stack: []
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=102 nstack_initial=0)
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow dispatch pc=102, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow stack []
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow end state. edges=[Edge(pc=108, stack=(), blockstack=(), npush=0)]
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0)])
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow stack: []
2024-01-20 12:14:38,998 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=112 nstack_initial=0)
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow dispatch pc=112, inst=LOAD_FAST(arg=2, lineno=1146)
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow stack []
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow dispatch pc=114, inst=POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow stack ['$zero_pos112.0']
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow end state. edges=[Edge(pc=116, stack=(), blockstack=(), npush=0), Edge(pc=200, stack=(), blockstack=(), npush=0)]
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow pending: deque([State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow stack: []
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=108 nstack_initial=0)
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow dispatch pc=108, inst=LOAD_CONST(arg=1, lineno=1144)
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow stack []
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow dispatch pc=110, inst=STORE_FAST(arg=4, lineno=1144)
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow stack ['$const108.0']
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow pending: deque([State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow stack: []
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=116 nstack_initial=0)
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow dispatch pc=116, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow stack []
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow dispatch pc=128, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow stack ['$null$116.1', '$116load_global.0']
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow dispatch pc=138, inst=LOAD_FAST(arg=3, lineno=1147)
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2']
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow dispatch pc=140, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow dispatch pc=144, inst=CALL(arg=1, lineno=1147)
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow dispatch pc=154, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow stack ['$144call.4']
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow dispatch pc=166, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$154load_global.5']
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow dispatch pc=176, inst=LOAD_FAST(arg=4, lineno=1147)
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7']
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow dispatch pc=178, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow dispatch pc=182, inst=CALL(arg=1, lineno=1147)
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow dispatch pc=192, inst=COMPARE_OP(arg=3, lineno=1147)
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow stack ['$144call.4', '$182call.9']
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow dispatch pc=198, inst=RETURN_VALUE(arg=None, lineno=1147)
2024-01-20 12:14:38,999 DEBUG numba.core.byteflow stack ['$192compare_op.10']
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow pending: deque([State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow stack: []
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=200 nstack_initial=0)
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow dispatch pc=200, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow stack []
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow dispatch pc=212, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow stack ['$null$200.1', '$200load_global.0']
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow dispatch pc=222, inst=LOAD_FAST(arg=3, lineno=1149)
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2']
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow dispatch pc=224, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow dispatch pc=228, inst=CALL(arg=1, lineno=1149)
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow dispatch pc=238, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow stack ['$228call.4']
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow dispatch pc=250, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$238load_global.5']
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow dispatch pc=260, inst=LOAD_FAST(arg=4, lineno=1149)
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7']
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow dispatch pc=262, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow dispatch pc=266, inst=CALL(arg=1, lineno=1149)
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow dispatch pc=276, inst=COMPARE_OP(arg=3, lineno=1149)
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow stack ['$228call.4', '$266call.9']
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow dispatch pc=282, inst=RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow stack ['$276compare_op.10']
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 12:14:39,000 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=38 nstack_initial=1): {'$phi38.0'},
             State(pc_initial=48 nstack_initial=0): set(),
             State(pc_initial=50 nstack_initial=1): set(),
             State(pc_initial=54 nstack_initial=0): set(),
             State(pc_initial=58 nstack_initial=0): set(),
             State(pc_initial=92 nstack_initial=1): {'$phi92.0'},
             State(pc_initial=102 nstack_initial=0): set(),
             State(pc_initial=104 nstack_initial=1): set(),
             State(pc_initial=108 nstack_initial=0): set(),
             State(pc_initial=112 nstack_initial=0): set(),
             State(pc_initial=116 nstack_initial=0): set(),
             State(pc_initial=200 nstack_initial=0): set()})
2024-01-20 12:14:39,001 DEBUG numba.core.byteflow defmap: {'$phi104.0': State(pc_initial=58 nstack_initial=0),
 '$phi38.0': State(pc_initial=0 nstack_initial=0),
 '$phi50.0': State(pc_initial=0 nstack_initial=0),
 '$phi92.0': State(pc_initial=58 nstack_initial=0)}
2024-01-20 12:14:39,001 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 12:14:39,001 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 12:14:39,001 DEBUG numba.core.byteflow keep phismap: {'$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
 '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}}
2024-01-20 12:14:39,001 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi38.0': '$x024.5'},
             State(pc_initial=58 nstack_initial=0): {'$phi92.0': '$x178.5'}})
2024-01-20 12:14:39,001 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 12:14:39,001 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'value': '$8binary_subscr.2'}), (20, {'res': '$threshold20.3'}), (22, {'value': '$threshold20.3', 'res': '$22unary_negative.4'}), (24, {'res': '$x024.5'}), (30, {'lhs': '$22unary_negative.4', 'rhs': '$x024.5', 'res': '$30compare_op.6'}), (32, {}), (34, {}), (36, {'pred': '$30compare_op.6'})), outgoing_phis={'$phi38.0': '$x024.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={38: ('$x024.5',), 50: ('$x024.5',)})
2024-01-20 12:14:39,001 DEBUG numba.core.byteflow block_infos State(pc_initial=38 nstack_initial=1):
AdaptBlockInfo(insts=((38, {'res': '$threshold38.1'}), (40, {'lhs': '$phi38.0', 'rhs': '$threshold38.1', 'res': '$40compare_op.2'}), (42, {}), (44, {}), (46, {'pred': '$40compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={48: (), 58: ()})
2024-01-20 12:14:39,001 DEBUG numba.core.byteflow block_infos State(pc_initial=48 nstack_initial=0):
AdaptBlockInfo(insts=((48, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={54: ()})
2024-01-20 12:14:39,001 DEBUG numba.core.byteflow block_infos State(pc_initial=50 nstack_initial=1):
AdaptBlockInfo(insts=((52, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 12:14:39,001 DEBUG numba.core.byteflow block_infos State(pc_initial=54 nstack_initial=0):
AdaptBlockInfo(insts=((54, {'res': '$const54.0'}), (56, {'value': '$const54.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 12:14:39,001 DEBUG numba.core.byteflow block_infos State(pc_initial=58 nstack_initial=0):
AdaptBlockInfo(insts=((58, {'res': '$x58.0'}), (60, {'res': '$const60.1'}), (62, {'index': '$const60.1', 'target': '$x58.0', 'res': '$62binary_subscr.2'}), (64, {}), (66, {}), (68, {}), (70, {}), (72, {'value': '$62binary_subscr.2'}), (74, {'res': '$threshold74.3'}), (76, {'value': '$threshold74.3', 'res': '$76unary_negative.4'}), (78, {'res': '$x178.5'}), (84, {'lhs': '$76unary_negative.4', 'rhs': '$x178.5', 'res': '$84compare_op.6'}), (86, {}), (88, {}), (90, {'pred': '$84compare_op.6'})), outgoing_phis={'$phi92.0': '$x178.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={92: ('$x178.5',), 104: ('$x178.5',)})
2024-01-20 12:14:39,001 DEBUG numba.core.byteflow block_infos State(pc_initial=92 nstack_initial=1):
AdaptBlockInfo(insts=((92, {'res': '$threshold92.1'}), (94, {'lhs': '$phi92.0', 'rhs': '$threshold92.1', 'res': '$94compare_op.2'}), (96, {}), (98, {}), (100, {'pred': '$94compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={102: (), 112: ()})
2024-01-20 12:14:39,001 DEBUG numba.core.byteflow block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={108: ()})
2024-01-20 12:14:39,001 DEBUG numba.core.byteflow block_infos State(pc_initial=104 nstack_initial=1):
AdaptBlockInfo(insts=((106, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 12:14:39,001 DEBUG numba.core.byteflow block_infos State(pc_initial=108 nstack_initial=0):
AdaptBlockInfo(insts=((108, {'res': '$const108.0'}), (110, {'value': '$const108.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 12:14:39,001 DEBUG numba.core.byteflow block_infos State(pc_initial=112 nstack_initial=0):
AdaptBlockInfo(insts=((112, {'res': '$zero_pos112.0'}), (114, {'pred': '$zero_pos112.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={116: (), 200: ()})
2024-01-20 12:14:39,001 DEBUG numba.core.byteflow block_infos State(pc_initial=116 nstack_initial=0):
AdaptBlockInfo(insts=((116, {'idx': 0, 'res': '$116load_global.0'}), (118, {}), (120, {}), (122, {}), (124, {}), (126, {}), (128, {'item': '$116load_global.0', 'res': '$128load_attr.2'}), (130, {}), (132, {}), (134, {}), (136, {}), (138, {'res': '$x0138.3'}), (140, {}), (142, {}), (144, {'func': '$128load_attr.2', 'args': ['$x0138.3'], 'kw_names': None, 'res': '$144call.4'}), (146, {}), (148, {}), (150, {}), (152, {}), (154, {'idx': 0, 'res': '$154load_global.5'}), (156, {}), (158, {}), (160, {}), (162, {}), (164, {}), (166, {'item': '$154load_global.5', 'res': '$166load_attr.7'}), (168, {}), (170, {}), (172, {}), (174, {}), (176, {'res': '$x1176.8'}), (178, {}), (180, {}), (182, {'func': '$166load_attr.7', 'args': ['$x1176.8'], 'kw_names': None, 'res': '$182call.9'}), (184, {}), (186, {}), (188, {}), (190, {}), (192, {'lhs': '$144call.4', 'rhs': '$182call.9', 'res': '$192compare_op.10'}), (194, {}), (196, {}), (198, {'retval': '$192compare_op.10', 'castval': '$198return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:14:39,001 DEBUG numba.core.byteflow block_infos State(pc_initial=200 nstack_initial=0):
AdaptBlockInfo(insts=((200, {'idx': 0, 'res': '$200load_global.0'}), (202, {}), (204, {}), (206, {}), (208, {}), (210, {}), (212, {'item': '$200load_global.0', 'res': '$212load_attr.2'}), (214, {}), (216, {}), (218, {}), (220, {}), (222, {'res': '$x0222.3'}), (224, {}), (226, {}), (228, {'func': '$212load_attr.2', 'args': ['$x0222.3'], 'kw_names': None, 'res': '$228call.4'}), (230, {}), (232, {}), (234, {}), (236, {}), (238, {'idx': 0, 'res': '$238load_global.5'}), (240, {}), (242, {}), (244, {}), (246, {}), (248, {}), (250, {'item': '$238load_global.5', 'res': '$250load_attr.7'}), (252, {}), (254, {}), (256, {}), (258, {}), (260, {'res': '$x1260.8'}), (262, {}), (264, {}), (266, {'func': '$250load_attr.7', 'args': ['$x1260.8'], 'kw_names': None, 'res': '$266call.9'}), (268, {}), (270, {}), (272, {}), (274, {}), (276, {'lhs': '$228call.4', 'rhs': '$266call.9', 'res': '$276compare_op.10'}), (278, {}), (280, {}), (282, {'retval': '$276compare_op.10', 'castval': '$282return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:14:39,002 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const6.1 = const(int, 0)                ['$const6.1']
    x0 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$const6.1', 'x', 'x0']
    $22unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$22unary_negative.4', 'threshold']
    $30compare_op.6 = $22unary_negative.4 <= x0 ['$22unary_negative.4', '$30compare_op.6', 'x0']
    bool36 = global(bool: <class 'bool'>)    ['bool36']
    $36pred = call bool36($30compare_op.6, func=bool36, args=(Var($30compare_op.6, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$30compare_op.6', '$36pred', 'bool36']
    $phi38.0 = x0                            ['$phi38.0', 'x0']
    branch $36pred, 38, 50                   ['$36pred']
label 38:
    $40compare_op.2 = $phi38.0 <= threshold  ['$40compare_op.2', '$phi38.0', 'threshold']
    bool46 = global(bool: <class 'bool'>)    ['bool46']
    $46pred = call bool46($40compare_op.2, func=bool46, args=(Var($40compare_op.2, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$40compare_op.2', '$46pred', 'bool46']
    branch $46pred, 48, 58                   ['$46pred']
label 48:
    jump 54                                  []
label 50:
    jump 58                                  []
label 54:
    x0 = const(int, 0)                       ['x0']
    jump 58                                  []
label 58:
    $const60.1 = const(int, -1)              ['$const60.1']
    x1 = getitem(value=x, index=$const60.1, fn=<built-in function getitem>) ['$const60.1', 'x', 'x1']
    $76unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$76unary_negative.4', 'threshold']
    $84compare_op.6 = $76unary_negative.4 <= x1 ['$76unary_negative.4', '$84compare_op.6', 'x1']
    bool90 = global(bool: <class 'bool'>)    ['bool90']
    $90pred = call bool90($84compare_op.6, func=bool90, args=(Var($84compare_op.6, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$84compare_op.6', '$90pred', 'bool90']
    $phi92.0 = x1                            ['$phi92.0', 'x1']
    branch $90pred, 92, 104                  ['$90pred']
label 92:
    $94compare_op.2 = $phi92.0 <= threshold  ['$94compare_op.2', '$phi92.0', 'threshold']
    bool100 = global(bool: <class 'bool'>)   ['bool100']
    $100pred = call bool100($94compare_op.2, func=bool100, args=(Var($94compare_op.2, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$100pred', '$94compare_op.2', 'bool100']
    branch $100pred, 102, 112                ['$100pred']
label 102:
    jump 108                                 []
label 104:
    jump 112                                 []
label 108:
    x1 = const(int, 0)                       ['x1']
    jump 112                                 []
label 112:
    bool114 = global(bool: <class 'bool'>)   ['bool114']
    $114pred = call bool114(zero_pos, func=bool114, args=(Var(zero_pos, audio.py:1135),), kws=(), vararg=None, varkwarg=None, target=None) ['$114pred', 'bool114', 'zero_pos']
    branch $114pred, 116, 200                ['$114pred']
label 116:
    $116load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$116load_global.0']
    $128load_attr.2 = getattr(value=$116load_global.0, attr=signbit) ['$116load_global.0', '$128load_attr.2']
    $144call.4 = call $128load_attr.2(x0, func=$128load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$128load_attr.2', '$144call.4', 'x0']
    $154load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$154load_global.5']
    $166load_attr.7 = getattr(value=$154load_global.5, attr=signbit) ['$154load_global.5', '$166load_attr.7']
    $182call.9 = call $166load_attr.7(x1, func=$166load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$166load_attr.7', '$182call.9', 'x1']
    $192compare_op.10 = $144call.4 != $182call.9 ['$144call.4', '$182call.9', '$192compare_op.10']
    $198return_value.11 = cast(value=$192compare_op.10) ['$192compare_op.10', '$198return_value.11']
    return $198return_value.11               ['$198return_value.11']
label 200:
    $200load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$200load_global.0']
    $212load_attr.2 = getattr(value=$200load_global.0, attr=sign) ['$200load_global.0', '$212load_attr.2']
    $228call.4 = call $212load_attr.2(x0, func=$212load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$212load_attr.2', '$228call.4', 'x0']
    $238load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$238load_global.5']
    $250load_attr.7 = getattr(value=$238load_global.5, attr=sign) ['$238load_global.5', '$250load_attr.7']
    $266call.9 = call $250load_attr.7(x1, func=$250load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$250load_attr.7', '$266call.9', 'x1']
    $276compare_op.10 = $228call.4 != $266call.9 ['$228call.4', '$266call.9', '$276compare_op.10']
    $282return_value.11 = cast(value=$276compare_op.10) ['$276compare_op.10', '$282return_value.11']
    return $282return_value.11               ['$282return_value.11']

2024-01-20 12:14:39,248 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1039)
           2	RESUME(arg=0, lineno=1039)
           4	LOAD_FAST(arg=0, lineno=1042)
           6	LOAD_CONST(arg=1, lineno=1042)
           8	BINARY_SUBSCR(arg=None, lineno=1042)
          18	LOAD_FAST(arg=0, lineno=1042)
          20	LOAD_CONST(arg=2, lineno=1042)
          22	BINARY_SUBSCR(arg=None, lineno=1042)
          32	COMPARE_OP(arg=4, lineno=1042)
          38	LOAD_FAST(arg=0, lineno=1042)
          40	LOAD_CONST(arg=1, lineno=1042)
          42	BINARY_SUBSCR(arg=None, lineno=1042)
          52	LOAD_FAST(arg=0, lineno=1042)
          54	LOAD_CONST(arg=3, lineno=1042)
          56	BINARY_SUBSCR(arg=None, lineno=1042)
          66	COMPARE_OP(arg=5, lineno=1042)
          72	BINARY_OP(arg=1, lineno=1042)
          76	RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow stack: []
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1039)
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow stack []
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1039)
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow stack []
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow stack []
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1042)
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=4, lineno=1042)
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1042)
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=5, lineno=1042)
2024-01-20 12:14:39,248 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 12:14:39,249 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1042)
2024-01-20 12:14:39,249 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 12:14:39,249 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 12:14:39,249 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 12:14:39,249 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:14:39,249 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 12:14:39,249 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 12:14:39,249 DEBUG numba.core.byteflow defmap: {}
2024-01-20 12:14:39,249 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:14:39,249 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:14:39,249 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 12:14:39,249 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 12:14:39,249 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 12:14:39,249 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:14:39,249 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 > $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 >= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 12:14:39,250 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1045)
           2	RESUME(arg=0, lineno=1045)
           4	LOAD_FAST(arg=0, lineno=1048)
           6	LOAD_CONST(arg=1, lineno=1048)
           8	BINARY_SUBSCR(arg=None, lineno=1048)
          18	LOAD_FAST(arg=0, lineno=1048)
          20	LOAD_CONST(arg=2, lineno=1048)
          22	BINARY_SUBSCR(arg=None, lineno=1048)
          32	COMPARE_OP(arg=0, lineno=1048)
          38	LOAD_FAST(arg=0, lineno=1048)
          40	LOAD_CONST(arg=1, lineno=1048)
          42	BINARY_SUBSCR(arg=None, lineno=1048)
          52	LOAD_FAST(arg=0, lineno=1048)
          54	LOAD_CONST(arg=3, lineno=1048)
          56	BINARY_SUBSCR(arg=None, lineno=1048)
          66	COMPARE_OP(arg=1, lineno=1048)
          72	BINARY_OP(arg=1, lineno=1048)
          76	RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow stack: []
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1045)
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow stack []
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1045)
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow stack []
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow stack []
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1048)
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=0, lineno=1048)
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1048)
2024-01-20 12:14:39,250 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 12:14:39,251 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:14:39,251 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 12:14:39,251 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=1, lineno=1048)
2024-01-20 12:14:39,251 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 12:14:39,251 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1048)
2024-01-20 12:14:39,251 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 12:14:39,251 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 12:14:39,251 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 12:14:39,251 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:14:39,251 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 12:14:39,251 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 12:14:39,251 DEBUG numba.core.byteflow defmap: {}
2024-01-20 12:14:39,251 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:14:39,251 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:14:39,251 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 12:14:39,251 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 12:14:39,251 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 12:14:39,251 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:14:39,251 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 < $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 <= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 12:14:39,505 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_combined_c9d44e7b7eae4bfc8169bc5124b10c2c.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 12:14:39,542 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 12:14:39,628 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000178B5C4B450>
2024-01-20 12:14:39,628 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000178FEB50320> server_hostname='api.openai.com' timeout=5.0
2024-01-20 12:14:39,649 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000178B77E7BD0>
2024-01-20 12:14:39,650 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 12:14:39,650 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 12:14:39,650 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 12:14:39,773 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 12:14:39,773 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 12:14:40,617 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 11:14:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'351'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'311bcd9fb75d5556cde205c1d321185e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=yDQYZyXxHp_oKORK8zExQZK.MvacKtaj3XJ2IUvNmBk-1705749279-1-AUCHIA5fth7fnmTMmA8vqQ2dzvBVmv1z4hSUz5RODgQsaNYRivGhCr9uTi9FTIXRZyRkj1bKB6eS/GeBSoRpkho=; path=/; expires=Sat, 20-Jan-24 11:44:39 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=_zxEyeFKAhvtUt._CJd6zS9AC9vp3GsTQWjLhghWFjk-1705749279410-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8486e51e5c772c3b-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 12:14:40,618 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 12:14:40,619 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 12:14:40,619 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 12:14:40,619 DEBUG httpcore.http11 response_closed.started
2024-01-20 12:14:40,619 DEBUG httpcore.http11 response_closed.complete
2024-01-20 12:14:40,619 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 12:16:31,024 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 12:16:31,026 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 12:16:31,276 INFO transcription All nescessary class variables are declared and working!
2024-01-20 12:16:40,171 INFO transcription Current recording SessionID is: dee891ff302b4fc4bd53b40f71b5d6af
2024-01-20 12:16:40,173 INFO transcription Started Microphone Thread for session dee891ff302b4fc4bd53b40f71b5d6af!
2024-01-20 12:16:40,174 INFO transcription Opening Stream for device Microsoft Sound Mapper - Input...
2024-01-20 12:16:40,174 INFO transcription Started System sounds Thread for session dee891ff302b4fc4bd53b40f71b5d6af!
2024-01-20 12:16:40,174 INFO transcription Opening Stream for device Stereo Mix (Realtek USB Audio)...
2024-01-20 12:16:40,188 INFO transcription Stream for Microphone Microsoft Sound Mapper - Input open!
2024-01-20 12:16:40,248 INFO transcription Stream for Microphone Stereo Mix (Realtek USB Audio) open!
2024-01-20 12:16:48,135 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1135)
           2	RESUME(arg=0, lineno=1135)
           4	LOAD_FAST(arg=0, lineno=1138)
           6	LOAD_CONST(arg=1, lineno=1138)
           8	BINARY_SUBSCR(arg=None, lineno=1138)
          18	STORE_FAST(arg=3, lineno=1138)
          20	LOAD_FAST(arg=1, lineno=1139)
          22	UNARY_NEGATIVE(arg=None, lineno=1139)
          24	LOAD_FAST(arg=3, lineno=1139)
          26	SWAP(arg=2, lineno=1139)
          28	COPY(arg=2, lineno=1139)
          30	COMPARE_OP(arg=1, lineno=1139)
          36	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
          38	LOAD_FAST(arg=1, lineno=1139)
          40	COMPARE_OP(arg=1, lineno=1139)
          46	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
          48	JUMP_FORWARD(arg=2, lineno=1139)
>         50	POP_TOP(arg=None, lineno=1139)
          52	JUMP_FORWARD(arg=2, lineno=1139)
>         54	LOAD_CONST(arg=1, lineno=1140)
          56	STORE_FAST(arg=3, lineno=1140)
>         58	LOAD_FAST(arg=0, lineno=1142)
          60	LOAD_CONST(arg=2, lineno=1142)
          62	BINARY_SUBSCR(arg=None, lineno=1142)
          72	STORE_FAST(arg=4, lineno=1142)
          74	LOAD_FAST(arg=1, lineno=1143)
          76	UNARY_NEGATIVE(arg=None, lineno=1143)
          78	LOAD_FAST(arg=4, lineno=1143)
          80	SWAP(arg=2, lineno=1143)
          82	COPY(arg=2, lineno=1143)
          84	COMPARE_OP(arg=1, lineno=1143)
          90	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
          92	LOAD_FAST(arg=1, lineno=1143)
          94	COMPARE_OP(arg=1, lineno=1143)
         100	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
         102	JUMP_FORWARD(arg=2, lineno=1143)
>        104	POP_TOP(arg=None, lineno=1143)
         106	JUMP_FORWARD(arg=2, lineno=1143)
>        108	LOAD_CONST(arg=1, lineno=1144)
         110	STORE_FAST(arg=4, lineno=1144)
>        112	LOAD_FAST(arg=2, lineno=1146)
         114	POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
         116	LOAD_GLOBAL(arg=1, lineno=1147)
         128	LOAD_ATTR(arg=1, lineno=1147)
         138	LOAD_FAST(arg=3, lineno=1147)
         140	PRECALL(arg=1, lineno=1147)
         144	CALL(arg=1, lineno=1147)
         154	LOAD_GLOBAL(arg=1, lineno=1147)
         166	LOAD_ATTR(arg=1, lineno=1147)
         176	LOAD_FAST(arg=4, lineno=1147)
         178	PRECALL(arg=1, lineno=1147)
         182	CALL(arg=1, lineno=1147)
         192	COMPARE_OP(arg=3, lineno=1147)
         198	RETURN_VALUE(arg=None, lineno=1147)
>        200	LOAD_GLOBAL(arg=1, lineno=1149)
         212	LOAD_ATTR(arg=2, lineno=1149)
         222	LOAD_FAST(arg=3, lineno=1149)
         224	PRECALL(arg=1, lineno=1149)
         228	CALL(arg=1, lineno=1149)
         238	LOAD_GLOBAL(arg=1, lineno=1149)
         250	LOAD_ATTR(arg=2, lineno=1149)
         260	LOAD_FAST(arg=4, lineno=1149)
         262	PRECALL(arg=1, lineno=1149)
         266	CALL(arg=1, lineno=1149)
         276	COMPARE_OP(arg=3, lineno=1149)
         282	RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 12:16:48,135 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow stack: []
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1135)
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow stack []
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1135)
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow stack []
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1138)
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow stack []
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1138)
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1138)
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow dispatch pc=18, inst=STORE_FAST(arg=3, lineno=1138)
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow stack []
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow dispatch pc=22, inst=UNARY_NEGATIVE(arg=None, lineno=1139)
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow stack ['$threshold20.3']
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow dispatch pc=24, inst=LOAD_FAST(arg=3, lineno=1139)
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow stack ['$22unary_negative.4']
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow dispatch pc=26, inst=SWAP(arg=2, lineno=1139)
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow stack ['$22unary_negative.4', '$x024.5']
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow dispatch pc=28, inst=COPY(arg=2, lineno=1139)
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4']
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow dispatch pc=30, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4', '$x024.5']
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow dispatch pc=36, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow stack ['$x024.5', '$30compare_op.6']
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow end state. edges=[Edge(pc=38, stack=('$x024.5',), blockstack=(), npush=0), Edge(pc=50, stack=('$x024.5',), blockstack=(), npush=0)]
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow pending: deque([State(pc_initial=38 nstack_initial=1), State(pc_initial=50 nstack_initial=1)])
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow stack: ['$phi38.0']
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=38 nstack_initial=1)
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow stack ['$phi38.0']
2024-01-20 12:16:48,136 DEBUG numba.core.byteflow dispatch pc=40, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow stack ['$phi38.0', '$threshold38.1']
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow dispatch pc=46, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow stack ['$40compare_op.2']
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow end state. edges=[Edge(pc=48, stack=(), blockstack=(), npush=0), Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow pending: deque([State(pc_initial=50 nstack_initial=1), State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow stack: ['$phi50.0']
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=50 nstack_initial=1)
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow dispatch pc=50, inst=POP_TOP(arg=None, lineno=1139)
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow stack ['$phi50.0']
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow dispatch pc=52, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow stack []
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow pending: deque([State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow stack: []
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=48 nstack_initial=0)
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow dispatch pc=48, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow stack []
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow end state. edges=[Edge(pc=54, stack=(), blockstack=(), npush=0)]
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0)])
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow stack: []
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=58 nstack_initial=0)
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow dispatch pc=58, inst=LOAD_FAST(arg=0, lineno=1142)
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow stack []
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow dispatch pc=60, inst=LOAD_CONST(arg=2, lineno=1142)
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow stack ['$x58.0']
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow dispatch pc=62, inst=BINARY_SUBSCR(arg=None, lineno=1142)
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow stack ['$x58.0', '$const60.1']
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow dispatch pc=72, inst=STORE_FAST(arg=4, lineno=1142)
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow stack ['$62binary_subscr.2']
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow dispatch pc=74, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow stack []
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow dispatch pc=76, inst=UNARY_NEGATIVE(arg=None, lineno=1143)
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow stack ['$threshold74.3']
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow dispatch pc=78, inst=LOAD_FAST(arg=4, lineno=1143)
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow stack ['$76unary_negative.4']
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow dispatch pc=80, inst=SWAP(arg=2, lineno=1143)
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow stack ['$76unary_negative.4', '$x178.5']
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow dispatch pc=82, inst=COPY(arg=2, lineno=1143)
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4']
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow dispatch pc=84, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4', '$x178.5']
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow dispatch pc=90, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
2024-01-20 12:16:48,137 DEBUG numba.core.byteflow stack ['$x178.5', '$84compare_op.6']
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow end state. edges=[Edge(pc=92, stack=('$x178.5',), blockstack=(), npush=0), Edge(pc=104, stack=('$x178.5',), blockstack=(), npush=0)]
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow pending: deque([State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow stack: []
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=54 nstack_initial=0)
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=1, lineno=1140)
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow stack []
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow dispatch pc=56, inst=STORE_FAST(arg=3, lineno=1140)
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow stack ['$const54.0']
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow pending: deque([State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0)])
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow stack: ['$phi92.0']
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=92 nstack_initial=1)
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow dispatch pc=92, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow stack ['$phi92.0']
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow dispatch pc=94, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow stack ['$phi92.0', '$threshold92.1']
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow dispatch pc=100, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow stack ['$94compare_op.2']
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow end state. edges=[Edge(pc=102, stack=(), blockstack=(), npush=0), Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow pending: deque([State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow stack: ['$phi104.0']
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=104 nstack_initial=1)
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow dispatch pc=104, inst=POP_TOP(arg=None, lineno=1143)
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow stack ['$phi104.0']
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow dispatch pc=106, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow stack []
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow stack: []
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=102 nstack_initial=0)
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow dispatch pc=102, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow stack []
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow end state. edges=[Edge(pc=108, stack=(), blockstack=(), npush=0)]
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0)])
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow stack: []
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=112 nstack_initial=0)
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow dispatch pc=112, inst=LOAD_FAST(arg=2, lineno=1146)
2024-01-20 12:16:48,138 DEBUG numba.core.byteflow stack []
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow dispatch pc=114, inst=POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow stack ['$zero_pos112.0']
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow end state. edges=[Edge(pc=116, stack=(), blockstack=(), npush=0), Edge(pc=200, stack=(), blockstack=(), npush=0)]
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow pending: deque([State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow stack: []
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=108 nstack_initial=0)
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow dispatch pc=108, inst=LOAD_CONST(arg=1, lineno=1144)
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow stack []
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow dispatch pc=110, inst=STORE_FAST(arg=4, lineno=1144)
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow stack ['$const108.0']
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow pending: deque([State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow stack: []
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=116 nstack_initial=0)
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow dispatch pc=116, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow stack []
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow dispatch pc=128, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow stack ['$null$116.1', '$116load_global.0']
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow dispatch pc=138, inst=LOAD_FAST(arg=3, lineno=1147)
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2']
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow dispatch pc=140, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow dispatch pc=144, inst=CALL(arg=1, lineno=1147)
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow dispatch pc=154, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow stack ['$144call.4']
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow dispatch pc=166, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$154load_global.5']
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow dispatch pc=176, inst=LOAD_FAST(arg=4, lineno=1147)
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7']
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow dispatch pc=178, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow dispatch pc=182, inst=CALL(arg=1, lineno=1147)
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow dispatch pc=192, inst=COMPARE_OP(arg=3, lineno=1147)
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow stack ['$144call.4', '$182call.9']
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow dispatch pc=198, inst=RETURN_VALUE(arg=None, lineno=1147)
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow stack ['$192compare_op.10']
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:16:48,139 DEBUG numba.core.byteflow pending: deque([State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow stack: []
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=200 nstack_initial=0)
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow dispatch pc=200, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow stack []
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow dispatch pc=212, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow stack ['$null$200.1', '$200load_global.0']
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow dispatch pc=222, inst=LOAD_FAST(arg=3, lineno=1149)
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2']
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow dispatch pc=224, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow dispatch pc=228, inst=CALL(arg=1, lineno=1149)
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow dispatch pc=238, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow stack ['$228call.4']
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow dispatch pc=250, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$238load_global.5']
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow dispatch pc=260, inst=LOAD_FAST(arg=4, lineno=1149)
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7']
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow dispatch pc=262, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow dispatch pc=266, inst=CALL(arg=1, lineno=1149)
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow dispatch pc=276, inst=COMPARE_OP(arg=3, lineno=1149)
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow stack ['$228call.4', '$266call.9']
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow dispatch pc=282, inst=RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow stack ['$276compare_op.10']
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=38 nstack_initial=1): {'$phi38.0'},
             State(pc_initial=48 nstack_initial=0): set(),
             State(pc_initial=50 nstack_initial=1): set(),
             State(pc_initial=54 nstack_initial=0): set(),
             State(pc_initial=58 nstack_initial=0): set(),
             State(pc_initial=92 nstack_initial=1): {'$phi92.0'},
             State(pc_initial=102 nstack_initial=0): set(),
             State(pc_initial=104 nstack_initial=1): set(),
             State(pc_initial=108 nstack_initial=0): set(),
             State(pc_initial=112 nstack_initial=0): set(),
             State(pc_initial=116 nstack_initial=0): set(),
             State(pc_initial=200 nstack_initial=0): set()})
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow defmap: {'$phi104.0': State(pc_initial=58 nstack_initial=0),
 '$phi38.0': State(pc_initial=0 nstack_initial=0),
 '$phi50.0': State(pc_initial=0 nstack_initial=0),
 '$phi92.0': State(pc_initial=58 nstack_initial=0)}
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 12:16:48,140 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 12:16:48,141 DEBUG numba.core.byteflow keep phismap: {'$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
 '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}}
2024-01-20 12:16:48,141 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi38.0': '$x024.5'},
             State(pc_initial=58 nstack_initial=0): {'$phi92.0': '$x178.5'}})
2024-01-20 12:16:48,141 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 12:16:48,141 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'value': '$8binary_subscr.2'}), (20, {'res': '$threshold20.3'}), (22, {'value': '$threshold20.3', 'res': '$22unary_negative.4'}), (24, {'res': '$x024.5'}), (30, {'lhs': '$22unary_negative.4', 'rhs': '$x024.5', 'res': '$30compare_op.6'}), (32, {}), (34, {}), (36, {'pred': '$30compare_op.6'})), outgoing_phis={'$phi38.0': '$x024.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={38: ('$x024.5',), 50: ('$x024.5',)})
2024-01-20 12:16:48,141 DEBUG numba.core.byteflow block_infos State(pc_initial=38 nstack_initial=1):
AdaptBlockInfo(insts=((38, {'res': '$threshold38.1'}), (40, {'lhs': '$phi38.0', 'rhs': '$threshold38.1', 'res': '$40compare_op.2'}), (42, {}), (44, {}), (46, {'pred': '$40compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={48: (), 58: ()})
2024-01-20 12:16:48,141 DEBUG numba.core.byteflow block_infos State(pc_initial=48 nstack_initial=0):
AdaptBlockInfo(insts=((48, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={54: ()})
2024-01-20 12:16:48,141 DEBUG numba.core.byteflow block_infos State(pc_initial=50 nstack_initial=1):
AdaptBlockInfo(insts=((52, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 12:16:48,141 DEBUG numba.core.byteflow block_infos State(pc_initial=54 nstack_initial=0):
AdaptBlockInfo(insts=((54, {'res': '$const54.0'}), (56, {'value': '$const54.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 12:16:48,141 DEBUG numba.core.byteflow block_infos State(pc_initial=58 nstack_initial=0):
AdaptBlockInfo(insts=((58, {'res': '$x58.0'}), (60, {'res': '$const60.1'}), (62, {'index': '$const60.1', 'target': '$x58.0', 'res': '$62binary_subscr.2'}), (64, {}), (66, {}), (68, {}), (70, {}), (72, {'value': '$62binary_subscr.2'}), (74, {'res': '$threshold74.3'}), (76, {'value': '$threshold74.3', 'res': '$76unary_negative.4'}), (78, {'res': '$x178.5'}), (84, {'lhs': '$76unary_negative.4', 'rhs': '$x178.5', 'res': '$84compare_op.6'}), (86, {}), (88, {}), (90, {'pred': '$84compare_op.6'})), outgoing_phis={'$phi92.0': '$x178.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={92: ('$x178.5',), 104: ('$x178.5',)})
2024-01-20 12:16:48,141 DEBUG numba.core.byteflow block_infos State(pc_initial=92 nstack_initial=1):
AdaptBlockInfo(insts=((92, {'res': '$threshold92.1'}), (94, {'lhs': '$phi92.0', 'rhs': '$threshold92.1', 'res': '$94compare_op.2'}), (96, {}), (98, {}), (100, {'pred': '$94compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={102: (), 112: ()})
2024-01-20 12:16:48,141 DEBUG numba.core.byteflow block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={108: ()})
2024-01-20 12:16:48,141 DEBUG numba.core.byteflow block_infos State(pc_initial=104 nstack_initial=1):
AdaptBlockInfo(insts=((106, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 12:16:48,141 DEBUG numba.core.byteflow block_infos State(pc_initial=108 nstack_initial=0):
AdaptBlockInfo(insts=((108, {'res': '$const108.0'}), (110, {'value': '$const108.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 12:16:48,141 DEBUG numba.core.byteflow block_infos State(pc_initial=112 nstack_initial=0):
AdaptBlockInfo(insts=((112, {'res': '$zero_pos112.0'}), (114, {'pred': '$zero_pos112.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={116: (), 200: ()})
2024-01-20 12:16:48,141 DEBUG numba.core.byteflow block_infos State(pc_initial=116 nstack_initial=0):
AdaptBlockInfo(insts=((116, {'idx': 0, 'res': '$116load_global.0'}), (118, {}), (120, {}), (122, {}), (124, {}), (126, {}), (128, {'item': '$116load_global.0', 'res': '$128load_attr.2'}), (130, {}), (132, {}), (134, {}), (136, {}), (138, {'res': '$x0138.3'}), (140, {}), (142, {}), (144, {'func': '$128load_attr.2', 'args': ['$x0138.3'], 'kw_names': None, 'res': '$144call.4'}), (146, {}), (148, {}), (150, {}), (152, {}), (154, {'idx': 0, 'res': '$154load_global.5'}), (156, {}), (158, {}), (160, {}), (162, {}), (164, {}), (166, {'item': '$154load_global.5', 'res': '$166load_attr.7'}), (168, {}), (170, {}), (172, {}), (174, {}), (176, {'res': '$x1176.8'}), (178, {}), (180, {}), (182, {'func': '$166load_attr.7', 'args': ['$x1176.8'], 'kw_names': None, 'res': '$182call.9'}), (184, {}), (186, {}), (188, {}), (190, {}), (192, {'lhs': '$144call.4', 'rhs': '$182call.9', 'res': '$192compare_op.10'}), (194, {}), (196, {}), (198, {'retval': '$192compare_op.10', 'castval': '$198return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:16:48,141 DEBUG numba.core.byteflow block_infos State(pc_initial=200 nstack_initial=0):
AdaptBlockInfo(insts=((200, {'idx': 0, 'res': '$200load_global.0'}), (202, {}), (204, {}), (206, {}), (208, {}), (210, {}), (212, {'item': '$200load_global.0', 'res': '$212load_attr.2'}), (214, {}), (216, {}), (218, {}), (220, {}), (222, {'res': '$x0222.3'}), (224, {}), (226, {}), (228, {'func': '$212load_attr.2', 'args': ['$x0222.3'], 'kw_names': None, 'res': '$228call.4'}), (230, {}), (232, {}), (234, {}), (236, {}), (238, {'idx': 0, 'res': '$238load_global.5'}), (240, {}), (242, {}), (244, {}), (246, {}), (248, {}), (250, {'item': '$238load_global.5', 'res': '$250load_attr.7'}), (252, {}), (254, {}), (256, {}), (258, {}), (260, {'res': '$x1260.8'}), (262, {}), (264, {}), (266, {'func': '$250load_attr.7', 'args': ['$x1260.8'], 'kw_names': None, 'res': '$266call.9'}), (268, {}), (270, {}), (272, {}), (274, {}), (276, {'lhs': '$228call.4', 'rhs': '$266call.9', 'res': '$276compare_op.10'}), (278, {}), (280, {}), (282, {'retval': '$276compare_op.10', 'castval': '$282return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:16:48,142 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const6.1 = const(int, 0)                ['$const6.1']
    x0 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$const6.1', 'x', 'x0']
    $22unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$22unary_negative.4', 'threshold']
    $30compare_op.6 = $22unary_negative.4 <= x0 ['$22unary_negative.4', '$30compare_op.6', 'x0']
    bool36 = global(bool: <class 'bool'>)    ['bool36']
    $36pred = call bool36($30compare_op.6, func=bool36, args=(Var($30compare_op.6, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$30compare_op.6', '$36pred', 'bool36']
    $phi38.0 = x0                            ['$phi38.0', 'x0']
    branch $36pred, 38, 50                   ['$36pred']
label 38:
    $40compare_op.2 = $phi38.0 <= threshold  ['$40compare_op.2', '$phi38.0', 'threshold']
    bool46 = global(bool: <class 'bool'>)    ['bool46']
    $46pred = call bool46($40compare_op.2, func=bool46, args=(Var($40compare_op.2, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$40compare_op.2', '$46pred', 'bool46']
    branch $46pred, 48, 58                   ['$46pred']
label 48:
    jump 54                                  []
label 50:
    jump 58                                  []
label 54:
    x0 = const(int, 0)                       ['x0']
    jump 58                                  []
label 58:
    $const60.1 = const(int, -1)              ['$const60.1']
    x1 = getitem(value=x, index=$const60.1, fn=<built-in function getitem>) ['$const60.1', 'x', 'x1']
    $76unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$76unary_negative.4', 'threshold']
    $84compare_op.6 = $76unary_negative.4 <= x1 ['$76unary_negative.4', '$84compare_op.6', 'x1']
    bool90 = global(bool: <class 'bool'>)    ['bool90']
    $90pred = call bool90($84compare_op.6, func=bool90, args=(Var($84compare_op.6, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$84compare_op.6', '$90pred', 'bool90']
    $phi92.0 = x1                            ['$phi92.0', 'x1']
    branch $90pred, 92, 104                  ['$90pred']
label 92:
    $94compare_op.2 = $phi92.0 <= threshold  ['$94compare_op.2', '$phi92.0', 'threshold']
    bool100 = global(bool: <class 'bool'>)   ['bool100']
    $100pred = call bool100($94compare_op.2, func=bool100, args=(Var($94compare_op.2, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$100pred', '$94compare_op.2', 'bool100']
    branch $100pred, 102, 112                ['$100pred']
label 102:
    jump 108                                 []
label 104:
    jump 112                                 []
label 108:
    x1 = const(int, 0)                       ['x1']
    jump 112                                 []
label 112:
    bool114 = global(bool: <class 'bool'>)   ['bool114']
    $114pred = call bool114(zero_pos, func=bool114, args=(Var(zero_pos, audio.py:1135),), kws=(), vararg=None, varkwarg=None, target=None) ['$114pred', 'bool114', 'zero_pos']
    branch $114pred, 116, 200                ['$114pred']
label 116:
    $116load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$116load_global.0']
    $128load_attr.2 = getattr(value=$116load_global.0, attr=signbit) ['$116load_global.0', '$128load_attr.2']
    $144call.4 = call $128load_attr.2(x0, func=$128load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$128load_attr.2', '$144call.4', 'x0']
    $154load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$154load_global.5']
    $166load_attr.7 = getattr(value=$154load_global.5, attr=signbit) ['$154load_global.5', '$166load_attr.7']
    $182call.9 = call $166load_attr.7(x1, func=$166load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$166load_attr.7', '$182call.9', 'x1']
    $192compare_op.10 = $144call.4 != $182call.9 ['$144call.4', '$182call.9', '$192compare_op.10']
    $198return_value.11 = cast(value=$192compare_op.10) ['$192compare_op.10', '$198return_value.11']
    return $198return_value.11               ['$198return_value.11']
label 200:
    $200load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$200load_global.0']
    $212load_attr.2 = getattr(value=$200load_global.0, attr=sign) ['$200load_global.0', '$212load_attr.2']
    $228call.4 = call $212load_attr.2(x0, func=$212load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$212load_attr.2', '$228call.4', 'x0']
    $238load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$238load_global.5']
    $250load_attr.7 = getattr(value=$238load_global.5, attr=sign) ['$238load_global.5', '$250load_attr.7']
    $266call.9 = call $250load_attr.7(x1, func=$250load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$250load_attr.7', '$266call.9', 'x1']
    $276compare_op.10 = $228call.4 != $266call.9 ['$228call.4', '$266call.9', '$276compare_op.10']
    $282return_value.11 = cast(value=$276compare_op.10) ['$276compare_op.10', '$282return_value.11']
    return $282return_value.11               ['$282return_value.11']

2024-01-20 12:16:48,370 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1039)
           2	RESUME(arg=0, lineno=1039)
           4	LOAD_FAST(arg=0, lineno=1042)
           6	LOAD_CONST(arg=1, lineno=1042)
           8	BINARY_SUBSCR(arg=None, lineno=1042)
          18	LOAD_FAST(arg=0, lineno=1042)
          20	LOAD_CONST(arg=2, lineno=1042)
          22	BINARY_SUBSCR(arg=None, lineno=1042)
          32	COMPARE_OP(arg=4, lineno=1042)
          38	LOAD_FAST(arg=0, lineno=1042)
          40	LOAD_CONST(arg=1, lineno=1042)
          42	BINARY_SUBSCR(arg=None, lineno=1042)
          52	LOAD_FAST(arg=0, lineno=1042)
          54	LOAD_CONST(arg=3, lineno=1042)
          56	BINARY_SUBSCR(arg=None, lineno=1042)
          66	COMPARE_OP(arg=5, lineno=1042)
          72	BINARY_OP(arg=1, lineno=1042)
          76	RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 12:16:48,370 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 12:16:48,370 DEBUG numba.core.byteflow stack: []
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1039)
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow stack []
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1039)
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow stack []
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow stack []
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1042)
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=4, lineno=1042)
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1042)
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=5, lineno=1042)
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1042)
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:16:48,371 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 12:16:48,372 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 12:16:48,372 DEBUG numba.core.byteflow defmap: {}
2024-01-20 12:16:48,372 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:16:48,372 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:16:48,372 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 12:16:48,372 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 12:16:48,372 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 12:16:48,372 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:16:48,372 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 > $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 >= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 12:16:48,373 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1045)
           2	RESUME(arg=0, lineno=1045)
           4	LOAD_FAST(arg=0, lineno=1048)
           6	LOAD_CONST(arg=1, lineno=1048)
           8	BINARY_SUBSCR(arg=None, lineno=1048)
          18	LOAD_FAST(arg=0, lineno=1048)
          20	LOAD_CONST(arg=2, lineno=1048)
          22	BINARY_SUBSCR(arg=None, lineno=1048)
          32	COMPARE_OP(arg=0, lineno=1048)
          38	LOAD_FAST(arg=0, lineno=1048)
          40	LOAD_CONST(arg=1, lineno=1048)
          42	BINARY_SUBSCR(arg=None, lineno=1048)
          52	LOAD_FAST(arg=0, lineno=1048)
          54	LOAD_CONST(arg=3, lineno=1048)
          56	BINARY_SUBSCR(arg=None, lineno=1048)
          66	COMPARE_OP(arg=1, lineno=1048)
          72	BINARY_OP(arg=1, lineno=1048)
          76	RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow stack: []
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1045)
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow stack []
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1045)
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow stack []
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow stack []
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1048)
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=0, lineno=1048)
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1048)
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:16:48,373 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 12:16:48,374 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=1, lineno=1048)
2024-01-20 12:16:48,374 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 12:16:48,374 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1048)
2024-01-20 12:16:48,374 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 12:16:48,374 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 12:16:48,374 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 12:16:48,374 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:16:48,374 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 12:16:48,374 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 12:16:48,374 DEBUG numba.core.byteflow defmap: {}
2024-01-20 12:16:48,374 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:16:48,374 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:16:48,374 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 12:16:48,374 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 12:16:48,374 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 12:16:48,374 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:16:48,374 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 < $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 <= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 12:16:48,619 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_combined_5337b182940242f2a6e0b11ddafb8229.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 12:16:48,652 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 12:16:48,745 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000201AB052790>
2024-01-20 12:16:48,745 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000201F5DC45F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 12:16:48,768 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000201AB266D10>
2024-01-20 12:16:48,768 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 12:16:48,768 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 12:16:48,769 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 12:16:48,822 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 12:16:48,822 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 12:16:49,720 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 11:16:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'420'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'397f96fc7a4f2b02475c1f7eb405d398'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=GyaRrQgwTOQHK844P68n8k6BB7TUz7_fzB.ZbOvJNq0-1705749408-1-AUhpKPOy2zVqCyfXhJj+tMlK0TdVGCQC/LF6oY+uroiCVkt+xlsoEHfQ36WpNmK9MbAFjky6iXoUzQbzw6wGOVQ=; path=/; expires=Sat, 20-Jan-24 11:46:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Si5vx3ktTdfbliRZZn.zdlRSRY8MUweLfVoz1mnUeqM-1705749408510-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8486e8455e4c9290-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 12:16:49,721 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 12:16:49,722 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 12:16:49,722 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 12:16:49,722 DEBUG httpcore.http11 response_closed.started
2024-01-20 12:16:49,722 DEBUG httpcore.http11 response_closed.complete
2024-01-20 12:16:49,722 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 12:20:13,220 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 12:20:13,222 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 12:20:13,461 INFO transcription All nescessary class variables are declared and working!
2024-01-20 12:20:15,276 INFO transcription Current recording SessionID is: 1f923b34ea824820af07e52dbf797fea
2024-01-20 12:20:15,278 INFO transcription Started Microphone Thread for session 1f923b34ea824820af07e52dbf797fea!
2024-01-20 12:20:15,279 INFO transcription Opening Stream for device Microsoft Sound Mapper - Input...
2024-01-20 12:20:15,279 INFO transcription Started System sounds Thread for session 1f923b34ea824820af07e52dbf797fea!
2024-01-20 12:20:15,279 INFO transcription Opening Stream for device Stereo Mix (Realtek USB Audio)...
2024-01-20 12:20:15,292 INFO transcription Stream for Microphone Microsoft Sound Mapper - Input open!
2024-01-20 12:20:15,350 INFO transcription Stream for Microphone Stereo Mix (Realtek USB Audio) open!
2024-01-20 12:20:30,983 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 12:20:30,985 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 12:20:31,220 INFO transcription All nescessary class variables are declared and working!
2024-01-20 12:20:32,696 INFO transcription Current recording SessionID is: 1c4d2aad252b45afb623bbecc3732a29
2024-01-20 12:20:32,698 INFO transcription Started Microphone Thread for session 1c4d2aad252b45afb623bbecc3732a29!
2024-01-20 12:20:32,698 INFO transcription Opening Stream for device Microsoft Sound Mapper - Input...
2024-01-20 12:20:32,699 INFO transcription Started System sounds Thread for session 1c4d2aad252b45afb623bbecc3732a29!
2024-01-20 12:20:32,699 INFO transcription Opening Stream for device Stereo Mix (Realtek USB Audio)...
2024-01-20 12:20:32,708 INFO transcription Stream for Microphone Microsoft Sound Mapper - Input open!
2024-01-20 12:20:32,767 INFO transcription Stream for Microphone Stereo Mix (Realtek USB Audio) open!
2024-01-20 12:20:40,698 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1135)
           2	RESUME(arg=0, lineno=1135)
           4	LOAD_FAST(arg=0, lineno=1138)
           6	LOAD_CONST(arg=1, lineno=1138)
           8	BINARY_SUBSCR(arg=None, lineno=1138)
          18	STORE_FAST(arg=3, lineno=1138)
          20	LOAD_FAST(arg=1, lineno=1139)
          22	UNARY_NEGATIVE(arg=None, lineno=1139)
          24	LOAD_FAST(arg=3, lineno=1139)
          26	SWAP(arg=2, lineno=1139)
          28	COPY(arg=2, lineno=1139)
          30	COMPARE_OP(arg=1, lineno=1139)
          36	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
          38	LOAD_FAST(arg=1, lineno=1139)
          40	COMPARE_OP(arg=1, lineno=1139)
          46	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
          48	JUMP_FORWARD(arg=2, lineno=1139)
>         50	POP_TOP(arg=None, lineno=1139)
          52	JUMP_FORWARD(arg=2, lineno=1139)
>         54	LOAD_CONST(arg=1, lineno=1140)
          56	STORE_FAST(arg=3, lineno=1140)
>         58	LOAD_FAST(arg=0, lineno=1142)
          60	LOAD_CONST(arg=2, lineno=1142)
          62	BINARY_SUBSCR(arg=None, lineno=1142)
          72	STORE_FAST(arg=4, lineno=1142)
          74	LOAD_FAST(arg=1, lineno=1143)
          76	UNARY_NEGATIVE(arg=None, lineno=1143)
          78	LOAD_FAST(arg=4, lineno=1143)
          80	SWAP(arg=2, lineno=1143)
          82	COPY(arg=2, lineno=1143)
          84	COMPARE_OP(arg=1, lineno=1143)
          90	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
          92	LOAD_FAST(arg=1, lineno=1143)
          94	COMPARE_OP(arg=1, lineno=1143)
         100	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
         102	JUMP_FORWARD(arg=2, lineno=1143)
>        104	POP_TOP(arg=None, lineno=1143)
         106	JUMP_FORWARD(arg=2, lineno=1143)
>        108	LOAD_CONST(arg=1, lineno=1144)
         110	STORE_FAST(arg=4, lineno=1144)
>        112	LOAD_FAST(arg=2, lineno=1146)
         114	POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
         116	LOAD_GLOBAL(arg=1, lineno=1147)
         128	LOAD_ATTR(arg=1, lineno=1147)
         138	LOAD_FAST(arg=3, lineno=1147)
         140	PRECALL(arg=1, lineno=1147)
         144	CALL(arg=1, lineno=1147)
         154	LOAD_GLOBAL(arg=1, lineno=1147)
         166	LOAD_ATTR(arg=1, lineno=1147)
         176	LOAD_FAST(arg=4, lineno=1147)
         178	PRECALL(arg=1, lineno=1147)
         182	CALL(arg=1, lineno=1147)
         192	COMPARE_OP(arg=3, lineno=1147)
         198	RETURN_VALUE(arg=None, lineno=1147)
>        200	LOAD_GLOBAL(arg=1, lineno=1149)
         212	LOAD_ATTR(arg=2, lineno=1149)
         222	LOAD_FAST(arg=3, lineno=1149)
         224	PRECALL(arg=1, lineno=1149)
         228	CALL(arg=1, lineno=1149)
         238	LOAD_GLOBAL(arg=1, lineno=1149)
         250	LOAD_ATTR(arg=2, lineno=1149)
         260	LOAD_FAST(arg=4, lineno=1149)
         262	PRECALL(arg=1, lineno=1149)
         266	CALL(arg=1, lineno=1149)
         276	COMPARE_OP(arg=3, lineno=1149)
         282	RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 12:20:40,698 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow stack: []
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1135)
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow stack []
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1135)
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow stack []
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1138)
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow stack []
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1138)
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1138)
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow dispatch pc=18, inst=STORE_FAST(arg=3, lineno=1138)
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow stack []
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow dispatch pc=22, inst=UNARY_NEGATIVE(arg=None, lineno=1139)
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow stack ['$threshold20.3']
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow dispatch pc=24, inst=LOAD_FAST(arg=3, lineno=1139)
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow stack ['$22unary_negative.4']
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow dispatch pc=26, inst=SWAP(arg=2, lineno=1139)
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow stack ['$22unary_negative.4', '$x024.5']
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow dispatch pc=28, inst=COPY(arg=2, lineno=1139)
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4']
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow dispatch pc=30, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4', '$x024.5']
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow dispatch pc=36, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow stack ['$x024.5', '$30compare_op.6']
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow end state. edges=[Edge(pc=38, stack=('$x024.5',), blockstack=(), npush=0), Edge(pc=50, stack=('$x024.5',), blockstack=(), npush=0)]
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow pending: deque([State(pc_initial=38 nstack_initial=1), State(pc_initial=50 nstack_initial=1)])
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow stack: ['$phi38.0']
2024-01-20 12:20:40,699 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=38 nstack_initial=1)
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow stack ['$phi38.0']
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow dispatch pc=40, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow stack ['$phi38.0', '$threshold38.1']
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow dispatch pc=46, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow stack ['$40compare_op.2']
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow end state. edges=[Edge(pc=48, stack=(), blockstack=(), npush=0), Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow pending: deque([State(pc_initial=50 nstack_initial=1), State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow stack: ['$phi50.0']
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=50 nstack_initial=1)
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow dispatch pc=50, inst=POP_TOP(arg=None, lineno=1139)
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow stack ['$phi50.0']
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow dispatch pc=52, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow stack []
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow pending: deque([State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow stack: []
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=48 nstack_initial=0)
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow dispatch pc=48, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow stack []
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow end state. edges=[Edge(pc=54, stack=(), blockstack=(), npush=0)]
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0)])
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow stack: []
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=58 nstack_initial=0)
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow dispatch pc=58, inst=LOAD_FAST(arg=0, lineno=1142)
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow stack []
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow dispatch pc=60, inst=LOAD_CONST(arg=2, lineno=1142)
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow stack ['$x58.0']
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow dispatch pc=62, inst=BINARY_SUBSCR(arg=None, lineno=1142)
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow stack ['$x58.0', '$const60.1']
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow dispatch pc=72, inst=STORE_FAST(arg=4, lineno=1142)
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow stack ['$62binary_subscr.2']
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow dispatch pc=74, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow stack []
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow dispatch pc=76, inst=UNARY_NEGATIVE(arg=None, lineno=1143)
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow stack ['$threshold74.3']
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow dispatch pc=78, inst=LOAD_FAST(arg=4, lineno=1143)
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow stack ['$76unary_negative.4']
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow dispatch pc=80, inst=SWAP(arg=2, lineno=1143)
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow stack ['$76unary_negative.4', '$x178.5']
2024-01-20 12:20:40,700 DEBUG numba.core.byteflow dispatch pc=82, inst=COPY(arg=2, lineno=1143)
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4']
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow dispatch pc=84, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4', '$x178.5']
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow dispatch pc=90, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow stack ['$x178.5', '$84compare_op.6']
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow end state. edges=[Edge(pc=92, stack=('$x178.5',), blockstack=(), npush=0), Edge(pc=104, stack=('$x178.5',), blockstack=(), npush=0)]
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow pending: deque([State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow stack: []
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=54 nstack_initial=0)
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=1, lineno=1140)
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow stack []
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow dispatch pc=56, inst=STORE_FAST(arg=3, lineno=1140)
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow stack ['$const54.0']
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow pending: deque([State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0)])
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow stack: ['$phi92.0']
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=92 nstack_initial=1)
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow dispatch pc=92, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow stack ['$phi92.0']
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow dispatch pc=94, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow stack ['$phi92.0', '$threshold92.1']
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow dispatch pc=100, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow stack ['$94compare_op.2']
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow end state. edges=[Edge(pc=102, stack=(), blockstack=(), npush=0), Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow pending: deque([State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow stack: ['$phi104.0']
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=104 nstack_initial=1)
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow dispatch pc=104, inst=POP_TOP(arg=None, lineno=1143)
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow stack ['$phi104.0']
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow dispatch pc=106, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow stack []
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow stack: []
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=102 nstack_initial=0)
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow dispatch pc=102, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow stack []
2024-01-20 12:20:40,701 DEBUG numba.core.byteflow end state. edges=[Edge(pc=108, stack=(), blockstack=(), npush=0)]
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0)])
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow stack: []
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=112 nstack_initial=0)
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow dispatch pc=112, inst=LOAD_FAST(arg=2, lineno=1146)
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow stack []
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow dispatch pc=114, inst=POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow stack ['$zero_pos112.0']
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow end state. edges=[Edge(pc=116, stack=(), blockstack=(), npush=0), Edge(pc=200, stack=(), blockstack=(), npush=0)]
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow pending: deque([State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow stack: []
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=108 nstack_initial=0)
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow dispatch pc=108, inst=LOAD_CONST(arg=1, lineno=1144)
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow stack []
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow dispatch pc=110, inst=STORE_FAST(arg=4, lineno=1144)
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow stack ['$const108.0']
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow pending: deque([State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow stack: []
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=116 nstack_initial=0)
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow dispatch pc=116, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow stack []
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow dispatch pc=128, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow stack ['$null$116.1', '$116load_global.0']
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow dispatch pc=138, inst=LOAD_FAST(arg=3, lineno=1147)
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2']
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow dispatch pc=140, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow dispatch pc=144, inst=CALL(arg=1, lineno=1147)
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow dispatch pc=154, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow stack ['$144call.4']
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow dispatch pc=166, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$154load_global.5']
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow dispatch pc=176, inst=LOAD_FAST(arg=4, lineno=1147)
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7']
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow dispatch pc=178, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow dispatch pc=182, inst=CALL(arg=1, lineno=1147)
2024-01-20 12:20:40,702 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow dispatch pc=192, inst=COMPARE_OP(arg=3, lineno=1147)
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow stack ['$144call.4', '$182call.9']
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow dispatch pc=198, inst=RETURN_VALUE(arg=None, lineno=1147)
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow stack ['$192compare_op.10']
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow pending: deque([State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow stack: []
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=200 nstack_initial=0)
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow dispatch pc=200, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow stack []
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow dispatch pc=212, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow stack ['$null$200.1', '$200load_global.0']
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow dispatch pc=222, inst=LOAD_FAST(arg=3, lineno=1149)
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2']
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow dispatch pc=224, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow dispatch pc=228, inst=CALL(arg=1, lineno=1149)
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow dispatch pc=238, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow stack ['$228call.4']
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow dispatch pc=250, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$238load_global.5']
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow dispatch pc=260, inst=LOAD_FAST(arg=4, lineno=1149)
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7']
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow dispatch pc=262, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow dispatch pc=266, inst=CALL(arg=1, lineno=1149)
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow dispatch pc=276, inst=COMPARE_OP(arg=3, lineno=1149)
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow stack ['$228call.4', '$266call.9']
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow dispatch pc=282, inst=RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow stack ['$276compare_op.10']
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 12:20:40,703 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=38 nstack_initial=1): {'$phi38.0'},
             State(pc_initial=48 nstack_initial=0): set(),
             State(pc_initial=50 nstack_initial=1): set(),
             State(pc_initial=54 nstack_initial=0): set(),
             State(pc_initial=58 nstack_initial=0): set(),
             State(pc_initial=92 nstack_initial=1): {'$phi92.0'},
             State(pc_initial=102 nstack_initial=0): set(),
             State(pc_initial=104 nstack_initial=1): set(),
             State(pc_initial=108 nstack_initial=0): set(),
             State(pc_initial=112 nstack_initial=0): set(),
             State(pc_initial=116 nstack_initial=0): set(),
             State(pc_initial=200 nstack_initial=0): set()})
2024-01-20 12:20:40,704 DEBUG numba.core.byteflow defmap: {'$phi104.0': State(pc_initial=58 nstack_initial=0),
 '$phi38.0': State(pc_initial=0 nstack_initial=0),
 '$phi50.0': State(pc_initial=0 nstack_initial=0),
 '$phi92.0': State(pc_initial=58 nstack_initial=0)}
2024-01-20 12:20:40,704 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 12:20:40,704 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 12:20:40,704 DEBUG numba.core.byteflow keep phismap: {'$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
 '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}}
2024-01-20 12:20:40,704 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi38.0': '$x024.5'},
             State(pc_initial=58 nstack_initial=0): {'$phi92.0': '$x178.5'}})
2024-01-20 12:20:40,704 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 12:20:40,704 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'value': '$8binary_subscr.2'}), (20, {'res': '$threshold20.3'}), (22, {'value': '$threshold20.3', 'res': '$22unary_negative.4'}), (24, {'res': '$x024.5'}), (30, {'lhs': '$22unary_negative.4', 'rhs': '$x024.5', 'res': '$30compare_op.6'}), (32, {}), (34, {}), (36, {'pred': '$30compare_op.6'})), outgoing_phis={'$phi38.0': '$x024.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={38: ('$x024.5',), 50: ('$x024.5',)})
2024-01-20 12:20:40,704 DEBUG numba.core.byteflow block_infos State(pc_initial=38 nstack_initial=1):
AdaptBlockInfo(insts=((38, {'res': '$threshold38.1'}), (40, {'lhs': '$phi38.0', 'rhs': '$threshold38.1', 'res': '$40compare_op.2'}), (42, {}), (44, {}), (46, {'pred': '$40compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={48: (), 58: ()})
2024-01-20 12:20:40,704 DEBUG numba.core.byteflow block_infos State(pc_initial=48 nstack_initial=0):
AdaptBlockInfo(insts=((48, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={54: ()})
2024-01-20 12:20:40,704 DEBUG numba.core.byteflow block_infos State(pc_initial=50 nstack_initial=1):
AdaptBlockInfo(insts=((52, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 12:20:40,704 DEBUG numba.core.byteflow block_infos State(pc_initial=54 nstack_initial=0):
AdaptBlockInfo(insts=((54, {'res': '$const54.0'}), (56, {'value': '$const54.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 12:20:40,704 DEBUG numba.core.byteflow block_infos State(pc_initial=58 nstack_initial=0):
AdaptBlockInfo(insts=((58, {'res': '$x58.0'}), (60, {'res': '$const60.1'}), (62, {'index': '$const60.1', 'target': '$x58.0', 'res': '$62binary_subscr.2'}), (64, {}), (66, {}), (68, {}), (70, {}), (72, {'value': '$62binary_subscr.2'}), (74, {'res': '$threshold74.3'}), (76, {'value': '$threshold74.3', 'res': '$76unary_negative.4'}), (78, {'res': '$x178.5'}), (84, {'lhs': '$76unary_negative.4', 'rhs': '$x178.5', 'res': '$84compare_op.6'}), (86, {}), (88, {}), (90, {'pred': '$84compare_op.6'})), outgoing_phis={'$phi92.0': '$x178.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={92: ('$x178.5',), 104: ('$x178.5',)})
2024-01-20 12:20:40,704 DEBUG numba.core.byteflow block_infos State(pc_initial=92 nstack_initial=1):
AdaptBlockInfo(insts=((92, {'res': '$threshold92.1'}), (94, {'lhs': '$phi92.0', 'rhs': '$threshold92.1', 'res': '$94compare_op.2'}), (96, {}), (98, {}), (100, {'pred': '$94compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={102: (), 112: ()})
2024-01-20 12:20:40,704 DEBUG numba.core.byteflow block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={108: ()})
2024-01-20 12:20:40,704 DEBUG numba.core.byteflow block_infos State(pc_initial=104 nstack_initial=1):
AdaptBlockInfo(insts=((106, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 12:20:40,704 DEBUG numba.core.byteflow block_infos State(pc_initial=108 nstack_initial=0):
AdaptBlockInfo(insts=((108, {'res': '$const108.0'}), (110, {'value': '$const108.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 12:20:40,704 DEBUG numba.core.byteflow block_infos State(pc_initial=112 nstack_initial=0):
AdaptBlockInfo(insts=((112, {'res': '$zero_pos112.0'}), (114, {'pred': '$zero_pos112.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={116: (), 200: ()})
2024-01-20 12:20:40,704 DEBUG numba.core.byteflow block_infos State(pc_initial=116 nstack_initial=0):
AdaptBlockInfo(insts=((116, {'idx': 0, 'res': '$116load_global.0'}), (118, {}), (120, {}), (122, {}), (124, {}), (126, {}), (128, {'item': '$116load_global.0', 'res': '$128load_attr.2'}), (130, {}), (132, {}), (134, {}), (136, {}), (138, {'res': '$x0138.3'}), (140, {}), (142, {}), (144, {'func': '$128load_attr.2', 'args': ['$x0138.3'], 'kw_names': None, 'res': '$144call.4'}), (146, {}), (148, {}), (150, {}), (152, {}), (154, {'idx': 0, 'res': '$154load_global.5'}), (156, {}), (158, {}), (160, {}), (162, {}), (164, {}), (166, {'item': '$154load_global.5', 'res': '$166load_attr.7'}), (168, {}), (170, {}), (172, {}), (174, {}), (176, {'res': '$x1176.8'}), (178, {}), (180, {}), (182, {'func': '$166load_attr.7', 'args': ['$x1176.8'], 'kw_names': None, 'res': '$182call.9'}), (184, {}), (186, {}), (188, {}), (190, {}), (192, {'lhs': '$144call.4', 'rhs': '$182call.9', 'res': '$192compare_op.10'}), (194, {}), (196, {}), (198, {'retval': '$192compare_op.10', 'castval': '$198return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:20:40,704 DEBUG numba.core.byteflow block_infos State(pc_initial=200 nstack_initial=0):
AdaptBlockInfo(insts=((200, {'idx': 0, 'res': '$200load_global.0'}), (202, {}), (204, {}), (206, {}), (208, {}), (210, {}), (212, {'item': '$200load_global.0', 'res': '$212load_attr.2'}), (214, {}), (216, {}), (218, {}), (220, {}), (222, {'res': '$x0222.3'}), (224, {}), (226, {}), (228, {'func': '$212load_attr.2', 'args': ['$x0222.3'], 'kw_names': None, 'res': '$228call.4'}), (230, {}), (232, {}), (234, {}), (236, {}), (238, {'idx': 0, 'res': '$238load_global.5'}), (240, {}), (242, {}), (244, {}), (246, {}), (248, {}), (250, {'item': '$238load_global.5', 'res': '$250load_attr.7'}), (252, {}), (254, {}), (256, {}), (258, {}), (260, {'res': '$x1260.8'}), (262, {}), (264, {}), (266, {'func': '$250load_attr.7', 'args': ['$x1260.8'], 'kw_names': None, 'res': '$266call.9'}), (268, {}), (270, {}), (272, {}), (274, {}), (276, {'lhs': '$228call.4', 'rhs': '$266call.9', 'res': '$276compare_op.10'}), (278, {}), (280, {}), (282, {'retval': '$276compare_op.10', 'castval': '$282return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:20:40,705 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const6.1 = const(int, 0)                ['$const6.1']
    x0 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$const6.1', 'x', 'x0']
    $22unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$22unary_negative.4', 'threshold']
    $30compare_op.6 = $22unary_negative.4 <= x0 ['$22unary_negative.4', '$30compare_op.6', 'x0']
    bool36 = global(bool: <class 'bool'>)    ['bool36']
    $36pred = call bool36($30compare_op.6, func=bool36, args=(Var($30compare_op.6, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$30compare_op.6', '$36pred', 'bool36']
    $phi38.0 = x0                            ['$phi38.0', 'x0']
    branch $36pred, 38, 50                   ['$36pred']
label 38:
    $40compare_op.2 = $phi38.0 <= threshold  ['$40compare_op.2', '$phi38.0', 'threshold']
    bool46 = global(bool: <class 'bool'>)    ['bool46']
    $46pred = call bool46($40compare_op.2, func=bool46, args=(Var($40compare_op.2, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$40compare_op.2', '$46pred', 'bool46']
    branch $46pred, 48, 58                   ['$46pred']
label 48:
    jump 54                                  []
label 50:
    jump 58                                  []
label 54:
    x0 = const(int, 0)                       ['x0']
    jump 58                                  []
label 58:
    $const60.1 = const(int, -1)              ['$const60.1']
    x1 = getitem(value=x, index=$const60.1, fn=<built-in function getitem>) ['$const60.1', 'x', 'x1']
    $76unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$76unary_negative.4', 'threshold']
    $84compare_op.6 = $76unary_negative.4 <= x1 ['$76unary_negative.4', '$84compare_op.6', 'x1']
    bool90 = global(bool: <class 'bool'>)    ['bool90']
    $90pred = call bool90($84compare_op.6, func=bool90, args=(Var($84compare_op.6, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$84compare_op.6', '$90pred', 'bool90']
    $phi92.0 = x1                            ['$phi92.0', 'x1']
    branch $90pred, 92, 104                  ['$90pred']
label 92:
    $94compare_op.2 = $phi92.0 <= threshold  ['$94compare_op.2', '$phi92.0', 'threshold']
    bool100 = global(bool: <class 'bool'>)   ['bool100']
    $100pred = call bool100($94compare_op.2, func=bool100, args=(Var($94compare_op.2, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$100pred', '$94compare_op.2', 'bool100']
    branch $100pred, 102, 112                ['$100pred']
label 102:
    jump 108                                 []
label 104:
    jump 112                                 []
label 108:
    x1 = const(int, 0)                       ['x1']
    jump 112                                 []
label 112:
    bool114 = global(bool: <class 'bool'>)   ['bool114']
    $114pred = call bool114(zero_pos, func=bool114, args=(Var(zero_pos, audio.py:1135),), kws=(), vararg=None, varkwarg=None, target=None) ['$114pred', 'bool114', 'zero_pos']
    branch $114pred, 116, 200                ['$114pred']
label 116:
    $116load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$116load_global.0']
    $128load_attr.2 = getattr(value=$116load_global.0, attr=signbit) ['$116load_global.0', '$128load_attr.2']
    $144call.4 = call $128load_attr.2(x0, func=$128load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$128load_attr.2', '$144call.4', 'x0']
    $154load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$154load_global.5']
    $166load_attr.7 = getattr(value=$154load_global.5, attr=signbit) ['$154load_global.5', '$166load_attr.7']
    $182call.9 = call $166load_attr.7(x1, func=$166load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$166load_attr.7', '$182call.9', 'x1']
    $192compare_op.10 = $144call.4 != $182call.9 ['$144call.4', '$182call.9', '$192compare_op.10']
    $198return_value.11 = cast(value=$192compare_op.10) ['$192compare_op.10', '$198return_value.11']
    return $198return_value.11               ['$198return_value.11']
label 200:
    $200load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$200load_global.0']
    $212load_attr.2 = getattr(value=$200load_global.0, attr=sign) ['$200load_global.0', '$212load_attr.2']
    $228call.4 = call $212load_attr.2(x0, func=$212load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$212load_attr.2', '$228call.4', 'x0']
    $238load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$238load_global.5']
    $250load_attr.7 = getattr(value=$238load_global.5, attr=sign) ['$238load_global.5', '$250load_attr.7']
    $266call.9 = call $250load_attr.7(x1, func=$250load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$250load_attr.7', '$266call.9', 'x1']
    $276compare_op.10 = $228call.4 != $266call.9 ['$228call.4', '$266call.9', '$276compare_op.10']
    $282return_value.11 = cast(value=$276compare_op.10) ['$276compare_op.10', '$282return_value.11']
    return $282return_value.11               ['$282return_value.11']

2024-01-20 12:20:40,942 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1039)
           2	RESUME(arg=0, lineno=1039)
           4	LOAD_FAST(arg=0, lineno=1042)
           6	LOAD_CONST(arg=1, lineno=1042)
           8	BINARY_SUBSCR(arg=None, lineno=1042)
          18	LOAD_FAST(arg=0, lineno=1042)
          20	LOAD_CONST(arg=2, lineno=1042)
          22	BINARY_SUBSCR(arg=None, lineno=1042)
          32	COMPARE_OP(arg=4, lineno=1042)
          38	LOAD_FAST(arg=0, lineno=1042)
          40	LOAD_CONST(arg=1, lineno=1042)
          42	BINARY_SUBSCR(arg=None, lineno=1042)
          52	LOAD_FAST(arg=0, lineno=1042)
          54	LOAD_CONST(arg=3, lineno=1042)
          56	BINARY_SUBSCR(arg=None, lineno=1042)
          66	COMPARE_OP(arg=5, lineno=1042)
          72	BINARY_OP(arg=1, lineno=1042)
          76	RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow stack: []
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1039)
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow stack []
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1039)
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow stack []
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow stack []
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1042)
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=4, lineno=1042)
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:20:40,942 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1042)
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=5, lineno=1042)
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1042)
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow defmap: {}
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 12:20:40,943 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:20:40,943 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 > $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 >= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 12:20:40,944 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1045)
           2	RESUME(arg=0, lineno=1045)
           4	LOAD_FAST(arg=0, lineno=1048)
           6	LOAD_CONST(arg=1, lineno=1048)
           8	BINARY_SUBSCR(arg=None, lineno=1048)
          18	LOAD_FAST(arg=0, lineno=1048)
          20	LOAD_CONST(arg=2, lineno=1048)
          22	BINARY_SUBSCR(arg=None, lineno=1048)
          32	COMPARE_OP(arg=0, lineno=1048)
          38	LOAD_FAST(arg=0, lineno=1048)
          40	LOAD_CONST(arg=1, lineno=1048)
          42	BINARY_SUBSCR(arg=None, lineno=1048)
          52	LOAD_FAST(arg=0, lineno=1048)
          54	LOAD_CONST(arg=3, lineno=1048)
          56	BINARY_SUBSCR(arg=None, lineno=1048)
          66	COMPARE_OP(arg=1, lineno=1048)
          72	BINARY_OP(arg=1, lineno=1048)
          76	RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow stack: []
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1045)
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow stack []
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1045)
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow stack []
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow stack []
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1048)
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=0, lineno=1048)
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1048)
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=1, lineno=1048)
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1048)
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 12:20:40,944 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:20:40,945 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 12:20:40,945 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 12:20:40,945 DEBUG numba.core.byteflow defmap: {}
2024-01-20 12:20:40,945 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:20:40,945 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:20:40,945 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 12:20:40,945 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 12:20:40,945 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 12:20:40,945 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:20:40,945 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 < $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 <= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 12:20:41,226 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_combined_d8eb1a0bcb2c4a459ffa7e4ba7923c32.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 12:20:41,258 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 12:20:41,349 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023A59638510>
2024-01-20 12:20:41,349 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000023A7E400320> server_hostname='api.openai.com' timeout=5.0
2024-01-20 12:20:41,370 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023A59787490>
2024-01-20 12:20:41,370 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 12:20:41,371 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 12:20:41,371 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 12:20:41,591 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 12:20:41,591 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 12:20:42,376 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 11:20:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'444'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3f912bb84bf0f3ba75f7d6adff4832ac'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=VoERwbRsv5m0n6fIU7UzAP2zY9WeOHeOSShtgy8xXfk-1705749641-1-Ac5/DDnBnEPyd3UDn2a1dZ/WxoMkvzNjAAuuPd3BWHX4W9aLHwnHqGK8GzTMF4klHYQMc0P5tDiA4dU8maPVR4s=; path=/; expires=Sat, 20-Jan-24 11:50:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=996QQtywIy1tSRYi6opjwK2QFiPxlS4xNgN_g2NwR2s-1705749641163-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8486edf31aa72c1a-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 12:20:42,378 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 12:20:42,378 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 12:20:42,379 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 12:20:42,379 DEBUG httpcore.http11 response_closed.started
2024-01-20 12:20:42,379 DEBUG httpcore.http11 response_closed.complete
2024-01-20 12:20:42,379 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 12:21:37,429 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 12:21:37,431 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 12:21:37,658 INFO transcription All nescessary class variables are declared and working!
2024-01-20 12:21:40,096 INFO transcription Current recording SessionID is: 5aea268ca97544ca9ae2b7c0a8bbcfca
2024-01-20 12:21:40,098 INFO transcription Started Microphone Thread for session 5aea268ca97544ca9ae2b7c0a8bbcfca!
2024-01-20 12:21:40,099 INFO transcription Opening Stream for device Microsoft Sound Mapper - Input...
2024-01-20 12:21:40,099 INFO transcription Started System sounds Thread for session 5aea268ca97544ca9ae2b7c0a8bbcfca!
2024-01-20 12:21:40,099 INFO transcription Opening Stream for device Stereo Mix (Realtek USB Audio)...
2024-01-20 12:21:40,111 INFO transcription Stream for Microphone Microsoft Sound Mapper - Input open!
2024-01-20 12:21:40,170 INFO transcription Stream for Microphone Stereo Mix (Realtek USB Audio) open!
2024-01-20 12:21:48,068 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1135)
           2	RESUME(arg=0, lineno=1135)
           4	LOAD_FAST(arg=0, lineno=1138)
           6	LOAD_CONST(arg=1, lineno=1138)
           8	BINARY_SUBSCR(arg=None, lineno=1138)
          18	STORE_FAST(arg=3, lineno=1138)
          20	LOAD_FAST(arg=1, lineno=1139)
          22	UNARY_NEGATIVE(arg=None, lineno=1139)
          24	LOAD_FAST(arg=3, lineno=1139)
          26	SWAP(arg=2, lineno=1139)
          28	COPY(arg=2, lineno=1139)
          30	COMPARE_OP(arg=1, lineno=1139)
          36	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
          38	LOAD_FAST(arg=1, lineno=1139)
          40	COMPARE_OP(arg=1, lineno=1139)
          46	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
          48	JUMP_FORWARD(arg=2, lineno=1139)
>         50	POP_TOP(arg=None, lineno=1139)
          52	JUMP_FORWARD(arg=2, lineno=1139)
>         54	LOAD_CONST(arg=1, lineno=1140)
          56	STORE_FAST(arg=3, lineno=1140)
>         58	LOAD_FAST(arg=0, lineno=1142)
          60	LOAD_CONST(arg=2, lineno=1142)
          62	BINARY_SUBSCR(arg=None, lineno=1142)
          72	STORE_FAST(arg=4, lineno=1142)
          74	LOAD_FAST(arg=1, lineno=1143)
          76	UNARY_NEGATIVE(arg=None, lineno=1143)
          78	LOAD_FAST(arg=4, lineno=1143)
          80	SWAP(arg=2, lineno=1143)
          82	COPY(arg=2, lineno=1143)
          84	COMPARE_OP(arg=1, lineno=1143)
          90	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
          92	LOAD_FAST(arg=1, lineno=1143)
          94	COMPARE_OP(arg=1, lineno=1143)
         100	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
         102	JUMP_FORWARD(arg=2, lineno=1143)
>        104	POP_TOP(arg=None, lineno=1143)
         106	JUMP_FORWARD(arg=2, lineno=1143)
>        108	LOAD_CONST(arg=1, lineno=1144)
         110	STORE_FAST(arg=4, lineno=1144)
>        112	LOAD_FAST(arg=2, lineno=1146)
         114	POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
         116	LOAD_GLOBAL(arg=1, lineno=1147)
         128	LOAD_ATTR(arg=1, lineno=1147)
         138	LOAD_FAST(arg=3, lineno=1147)
         140	PRECALL(arg=1, lineno=1147)
         144	CALL(arg=1, lineno=1147)
         154	LOAD_GLOBAL(arg=1, lineno=1147)
         166	LOAD_ATTR(arg=1, lineno=1147)
         176	LOAD_FAST(arg=4, lineno=1147)
         178	PRECALL(arg=1, lineno=1147)
         182	CALL(arg=1, lineno=1147)
         192	COMPARE_OP(arg=3, lineno=1147)
         198	RETURN_VALUE(arg=None, lineno=1147)
>        200	LOAD_GLOBAL(arg=1, lineno=1149)
         212	LOAD_ATTR(arg=2, lineno=1149)
         222	LOAD_FAST(arg=3, lineno=1149)
         224	PRECALL(arg=1, lineno=1149)
         228	CALL(arg=1, lineno=1149)
         238	LOAD_GLOBAL(arg=1, lineno=1149)
         250	LOAD_ATTR(arg=2, lineno=1149)
         260	LOAD_FAST(arg=4, lineno=1149)
         262	PRECALL(arg=1, lineno=1149)
         266	CALL(arg=1, lineno=1149)
         276	COMPARE_OP(arg=3, lineno=1149)
         282	RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 12:21:48,069 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 12:21:48,069 DEBUG numba.core.byteflow stack: []
2024-01-20 12:21:48,069 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 12:21:48,069 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1135)
2024-01-20 12:21:48,069 DEBUG numba.core.byteflow stack []
2024-01-20 12:21:48,069 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1135)
2024-01-20 12:21:48,069 DEBUG numba.core.byteflow stack []
2024-01-20 12:21:48,069 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1138)
2024-01-20 12:21:48,069 DEBUG numba.core.byteflow stack []
2024-01-20 12:21:48,069 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1138)
2024-01-20 12:21:48,069 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 12:21:48,069 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1138)
2024-01-20 12:21:48,069 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 12:21:48,069 DEBUG numba.core.byteflow dispatch pc=18, inst=STORE_FAST(arg=3, lineno=1138)
2024-01-20 12:21:48,069 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 12:21:48,069 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 12:21:48,069 DEBUG numba.core.byteflow stack []
2024-01-20 12:21:48,069 DEBUG numba.core.byteflow dispatch pc=22, inst=UNARY_NEGATIVE(arg=None, lineno=1139)
2024-01-20 12:21:48,069 DEBUG numba.core.byteflow stack ['$threshold20.3']
2024-01-20 12:21:48,069 DEBUG numba.core.byteflow dispatch pc=24, inst=LOAD_FAST(arg=3, lineno=1139)
2024-01-20 12:21:48,069 DEBUG numba.core.byteflow stack ['$22unary_negative.4']
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow dispatch pc=26, inst=SWAP(arg=2, lineno=1139)
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow stack ['$22unary_negative.4', '$x024.5']
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow dispatch pc=28, inst=COPY(arg=2, lineno=1139)
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4']
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow dispatch pc=30, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4', '$x024.5']
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow dispatch pc=36, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow stack ['$x024.5', '$30compare_op.6']
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow end state. edges=[Edge(pc=38, stack=('$x024.5',), blockstack=(), npush=0), Edge(pc=50, stack=('$x024.5',), blockstack=(), npush=0)]
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow pending: deque([State(pc_initial=38 nstack_initial=1), State(pc_initial=50 nstack_initial=1)])
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow stack: ['$phi38.0']
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=38 nstack_initial=1)
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow stack ['$phi38.0']
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow dispatch pc=40, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow stack ['$phi38.0', '$threshold38.1']
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow dispatch pc=46, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow stack ['$40compare_op.2']
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow end state. edges=[Edge(pc=48, stack=(), blockstack=(), npush=0), Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow pending: deque([State(pc_initial=50 nstack_initial=1), State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow stack: ['$phi50.0']
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=50 nstack_initial=1)
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow dispatch pc=50, inst=POP_TOP(arg=None, lineno=1139)
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow stack ['$phi50.0']
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow dispatch pc=52, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow stack []
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow pending: deque([State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow stack: []
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=48 nstack_initial=0)
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow dispatch pc=48, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow stack []
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow end state. edges=[Edge(pc=54, stack=(), blockstack=(), npush=0)]
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0)])
2024-01-20 12:21:48,070 DEBUG numba.core.byteflow stack: []
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=58 nstack_initial=0)
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow dispatch pc=58, inst=LOAD_FAST(arg=0, lineno=1142)
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow stack []
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow dispatch pc=60, inst=LOAD_CONST(arg=2, lineno=1142)
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow stack ['$x58.0']
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow dispatch pc=62, inst=BINARY_SUBSCR(arg=None, lineno=1142)
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow stack ['$x58.0', '$const60.1']
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow dispatch pc=72, inst=STORE_FAST(arg=4, lineno=1142)
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow stack ['$62binary_subscr.2']
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow dispatch pc=74, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow stack []
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow dispatch pc=76, inst=UNARY_NEGATIVE(arg=None, lineno=1143)
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow stack ['$threshold74.3']
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow dispatch pc=78, inst=LOAD_FAST(arg=4, lineno=1143)
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow stack ['$76unary_negative.4']
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow dispatch pc=80, inst=SWAP(arg=2, lineno=1143)
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow stack ['$76unary_negative.4', '$x178.5']
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow dispatch pc=82, inst=COPY(arg=2, lineno=1143)
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4']
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow dispatch pc=84, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4', '$x178.5']
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow dispatch pc=90, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow stack ['$x178.5', '$84compare_op.6']
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow end state. edges=[Edge(pc=92, stack=('$x178.5',), blockstack=(), npush=0), Edge(pc=104, stack=('$x178.5',), blockstack=(), npush=0)]
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow pending: deque([State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow stack: []
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=54 nstack_initial=0)
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=1, lineno=1140)
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow stack []
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow dispatch pc=56, inst=STORE_FAST(arg=3, lineno=1140)
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow stack ['$const54.0']
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow pending: deque([State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0)])
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow stack: ['$phi92.0']
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=92 nstack_initial=1)
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow dispatch pc=92, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow stack ['$phi92.0']
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow dispatch pc=94, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow stack ['$phi92.0', '$threshold92.1']
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow dispatch pc=100, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow stack ['$94compare_op.2']
2024-01-20 12:21:48,071 DEBUG numba.core.byteflow end state. edges=[Edge(pc=102, stack=(), blockstack=(), npush=0), Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow pending: deque([State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow stack: ['$phi104.0']
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=104 nstack_initial=1)
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow dispatch pc=104, inst=POP_TOP(arg=None, lineno=1143)
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow stack ['$phi104.0']
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow dispatch pc=106, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow stack []
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow stack: []
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=102 nstack_initial=0)
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow dispatch pc=102, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow stack []
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow end state. edges=[Edge(pc=108, stack=(), blockstack=(), npush=0)]
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0)])
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow stack: []
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=112 nstack_initial=0)
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow dispatch pc=112, inst=LOAD_FAST(arg=2, lineno=1146)
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow stack []
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow dispatch pc=114, inst=POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow stack ['$zero_pos112.0']
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow end state. edges=[Edge(pc=116, stack=(), blockstack=(), npush=0), Edge(pc=200, stack=(), blockstack=(), npush=0)]
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow pending: deque([State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow stack: []
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=108 nstack_initial=0)
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow dispatch pc=108, inst=LOAD_CONST(arg=1, lineno=1144)
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow stack []
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow dispatch pc=110, inst=STORE_FAST(arg=4, lineno=1144)
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow stack ['$const108.0']
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow pending: deque([State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow stack: []
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=116 nstack_initial=0)
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow dispatch pc=116, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow stack []
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow dispatch pc=128, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow stack ['$null$116.1', '$116load_global.0']
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow dispatch pc=138, inst=LOAD_FAST(arg=3, lineno=1147)
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2']
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow dispatch pc=140, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 12:21:48,072 DEBUG numba.core.byteflow dispatch pc=144, inst=CALL(arg=1, lineno=1147)
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow dispatch pc=154, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow stack ['$144call.4']
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow dispatch pc=166, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$154load_global.5']
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow dispatch pc=176, inst=LOAD_FAST(arg=4, lineno=1147)
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7']
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow dispatch pc=178, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow dispatch pc=182, inst=CALL(arg=1, lineno=1147)
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow dispatch pc=192, inst=COMPARE_OP(arg=3, lineno=1147)
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow stack ['$144call.4', '$182call.9']
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow dispatch pc=198, inst=RETURN_VALUE(arg=None, lineno=1147)
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow stack ['$192compare_op.10']
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow pending: deque([State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow stack: []
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=200 nstack_initial=0)
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow dispatch pc=200, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow stack []
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow dispatch pc=212, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow stack ['$null$200.1', '$200load_global.0']
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow dispatch pc=222, inst=LOAD_FAST(arg=3, lineno=1149)
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2']
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow dispatch pc=224, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow dispatch pc=228, inst=CALL(arg=1, lineno=1149)
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow dispatch pc=238, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow stack ['$228call.4']
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow dispatch pc=250, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$238load_global.5']
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow dispatch pc=260, inst=LOAD_FAST(arg=4, lineno=1149)
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7']
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow dispatch pc=262, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow dispatch pc=266, inst=CALL(arg=1, lineno=1149)
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow dispatch pc=276, inst=COMPARE_OP(arg=3, lineno=1149)
2024-01-20 12:21:48,073 DEBUG numba.core.byteflow stack ['$228call.4', '$266call.9']
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow dispatch pc=282, inst=RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow stack ['$276compare_op.10']
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=38 nstack_initial=1): {'$phi38.0'},
             State(pc_initial=48 nstack_initial=0): set(),
             State(pc_initial=50 nstack_initial=1): set(),
             State(pc_initial=54 nstack_initial=0): set(),
             State(pc_initial=58 nstack_initial=0): set(),
             State(pc_initial=92 nstack_initial=1): {'$phi92.0'},
             State(pc_initial=102 nstack_initial=0): set(),
             State(pc_initial=104 nstack_initial=1): set(),
             State(pc_initial=108 nstack_initial=0): set(),
             State(pc_initial=112 nstack_initial=0): set(),
             State(pc_initial=116 nstack_initial=0): set(),
             State(pc_initial=200 nstack_initial=0): set()})
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow defmap: {'$phi104.0': State(pc_initial=58 nstack_initial=0),
 '$phi38.0': State(pc_initial=0 nstack_initial=0),
 '$phi50.0': State(pc_initial=0 nstack_initial=0),
 '$phi92.0': State(pc_initial=58 nstack_initial=0)}
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow keep phismap: {'$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
 '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}}
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi38.0': '$x024.5'},
             State(pc_initial=58 nstack_initial=0): {'$phi92.0': '$x178.5'}})
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'value': '$8binary_subscr.2'}), (20, {'res': '$threshold20.3'}), (22, {'value': '$threshold20.3', 'res': '$22unary_negative.4'}), (24, {'res': '$x024.5'}), (30, {'lhs': '$22unary_negative.4', 'rhs': '$x024.5', 'res': '$30compare_op.6'}), (32, {}), (34, {}), (36, {'pred': '$30compare_op.6'})), outgoing_phis={'$phi38.0': '$x024.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={38: ('$x024.5',), 50: ('$x024.5',)})
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow block_infos State(pc_initial=38 nstack_initial=1):
AdaptBlockInfo(insts=((38, {'res': '$threshold38.1'}), (40, {'lhs': '$phi38.0', 'rhs': '$threshold38.1', 'res': '$40compare_op.2'}), (42, {}), (44, {}), (46, {'pred': '$40compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={48: (), 58: ()})
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow block_infos State(pc_initial=48 nstack_initial=0):
AdaptBlockInfo(insts=((48, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={54: ()})
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow block_infos State(pc_initial=50 nstack_initial=1):
AdaptBlockInfo(insts=((52, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow block_infos State(pc_initial=54 nstack_initial=0):
AdaptBlockInfo(insts=((54, {'res': '$const54.0'}), (56, {'value': '$const54.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow block_infos State(pc_initial=58 nstack_initial=0):
AdaptBlockInfo(insts=((58, {'res': '$x58.0'}), (60, {'res': '$const60.1'}), (62, {'index': '$const60.1', 'target': '$x58.0', 'res': '$62binary_subscr.2'}), (64, {}), (66, {}), (68, {}), (70, {}), (72, {'value': '$62binary_subscr.2'}), (74, {'res': '$threshold74.3'}), (76, {'value': '$threshold74.3', 'res': '$76unary_negative.4'}), (78, {'res': '$x178.5'}), (84, {'lhs': '$76unary_negative.4', 'rhs': '$x178.5', 'res': '$84compare_op.6'}), (86, {}), (88, {}), (90, {'pred': '$84compare_op.6'})), outgoing_phis={'$phi92.0': '$x178.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={92: ('$x178.5',), 104: ('$x178.5',)})
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow block_infos State(pc_initial=92 nstack_initial=1):
AdaptBlockInfo(insts=((92, {'res': '$threshold92.1'}), (94, {'lhs': '$phi92.0', 'rhs': '$threshold92.1', 'res': '$94compare_op.2'}), (96, {}), (98, {}), (100, {'pred': '$94compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={102: (), 112: ()})
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={108: ()})
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow block_infos State(pc_initial=104 nstack_initial=1):
AdaptBlockInfo(insts=((106, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow block_infos State(pc_initial=108 nstack_initial=0):
AdaptBlockInfo(insts=((108, {'res': '$const108.0'}), (110, {'value': '$const108.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow block_infos State(pc_initial=112 nstack_initial=0):
AdaptBlockInfo(insts=((112, {'res': '$zero_pos112.0'}), (114, {'pred': '$zero_pos112.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={116: (), 200: ()})
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow block_infos State(pc_initial=116 nstack_initial=0):
AdaptBlockInfo(insts=((116, {'idx': 0, 'res': '$116load_global.0'}), (118, {}), (120, {}), (122, {}), (124, {}), (126, {}), (128, {'item': '$116load_global.0', 'res': '$128load_attr.2'}), (130, {}), (132, {}), (134, {}), (136, {}), (138, {'res': '$x0138.3'}), (140, {}), (142, {}), (144, {'func': '$128load_attr.2', 'args': ['$x0138.3'], 'kw_names': None, 'res': '$144call.4'}), (146, {}), (148, {}), (150, {}), (152, {}), (154, {'idx': 0, 'res': '$154load_global.5'}), (156, {}), (158, {}), (160, {}), (162, {}), (164, {}), (166, {'item': '$154load_global.5', 'res': '$166load_attr.7'}), (168, {}), (170, {}), (172, {}), (174, {}), (176, {'res': '$x1176.8'}), (178, {}), (180, {}), (182, {'func': '$166load_attr.7', 'args': ['$x1176.8'], 'kw_names': None, 'res': '$182call.9'}), (184, {}), (186, {}), (188, {}), (190, {}), (192, {'lhs': '$144call.4', 'rhs': '$182call.9', 'res': '$192compare_op.10'}), (194, {}), (196, {}), (198, {'retval': '$192compare_op.10', 'castval': '$198return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:21:48,074 DEBUG numba.core.byteflow block_infos State(pc_initial=200 nstack_initial=0):
AdaptBlockInfo(insts=((200, {'idx': 0, 'res': '$200load_global.0'}), (202, {}), (204, {}), (206, {}), (208, {}), (210, {}), (212, {'item': '$200load_global.0', 'res': '$212load_attr.2'}), (214, {}), (216, {}), (218, {}), (220, {}), (222, {'res': '$x0222.3'}), (224, {}), (226, {}), (228, {'func': '$212load_attr.2', 'args': ['$x0222.3'], 'kw_names': None, 'res': '$228call.4'}), (230, {}), (232, {}), (234, {}), (236, {}), (238, {'idx': 0, 'res': '$238load_global.5'}), (240, {}), (242, {}), (244, {}), (246, {}), (248, {}), (250, {'item': '$238load_global.5', 'res': '$250load_attr.7'}), (252, {}), (254, {}), (256, {}), (258, {}), (260, {'res': '$x1260.8'}), (262, {}), (264, {}), (266, {'func': '$250load_attr.7', 'args': ['$x1260.8'], 'kw_names': None, 'res': '$266call.9'}), (268, {}), (270, {}), (272, {}), (274, {}), (276, {'lhs': '$228call.4', 'rhs': '$266call.9', 'res': '$276compare_op.10'}), (278, {}), (280, {}), (282, {'retval': '$276compare_op.10', 'castval': '$282return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:21:48,075 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const6.1 = const(int, 0)                ['$const6.1']
    x0 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$const6.1', 'x', 'x0']
    $22unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$22unary_negative.4', 'threshold']
    $30compare_op.6 = $22unary_negative.4 <= x0 ['$22unary_negative.4', '$30compare_op.6', 'x0']
    bool36 = global(bool: <class 'bool'>)    ['bool36']
    $36pred = call bool36($30compare_op.6, func=bool36, args=(Var($30compare_op.6, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$30compare_op.6', '$36pred', 'bool36']
    $phi38.0 = x0                            ['$phi38.0', 'x0']
    branch $36pred, 38, 50                   ['$36pred']
label 38:
    $40compare_op.2 = $phi38.0 <= threshold  ['$40compare_op.2', '$phi38.0', 'threshold']
    bool46 = global(bool: <class 'bool'>)    ['bool46']
    $46pred = call bool46($40compare_op.2, func=bool46, args=(Var($40compare_op.2, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$40compare_op.2', '$46pred', 'bool46']
    branch $46pred, 48, 58                   ['$46pred']
label 48:
    jump 54                                  []
label 50:
    jump 58                                  []
label 54:
    x0 = const(int, 0)                       ['x0']
    jump 58                                  []
label 58:
    $const60.1 = const(int, -1)              ['$const60.1']
    x1 = getitem(value=x, index=$const60.1, fn=<built-in function getitem>) ['$const60.1', 'x', 'x1']
    $76unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$76unary_negative.4', 'threshold']
    $84compare_op.6 = $76unary_negative.4 <= x1 ['$76unary_negative.4', '$84compare_op.6', 'x1']
    bool90 = global(bool: <class 'bool'>)    ['bool90']
    $90pred = call bool90($84compare_op.6, func=bool90, args=(Var($84compare_op.6, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$84compare_op.6', '$90pred', 'bool90']
    $phi92.0 = x1                            ['$phi92.0', 'x1']
    branch $90pred, 92, 104                  ['$90pred']
label 92:
    $94compare_op.2 = $phi92.0 <= threshold  ['$94compare_op.2', '$phi92.0', 'threshold']
    bool100 = global(bool: <class 'bool'>)   ['bool100']
    $100pred = call bool100($94compare_op.2, func=bool100, args=(Var($94compare_op.2, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$100pred', '$94compare_op.2', 'bool100']
    branch $100pred, 102, 112                ['$100pred']
label 102:
    jump 108                                 []
label 104:
    jump 112                                 []
label 108:
    x1 = const(int, 0)                       ['x1']
    jump 112                                 []
label 112:
    bool114 = global(bool: <class 'bool'>)   ['bool114']
    $114pred = call bool114(zero_pos, func=bool114, args=(Var(zero_pos, audio.py:1135),), kws=(), vararg=None, varkwarg=None, target=None) ['$114pred', 'bool114', 'zero_pos']
    branch $114pred, 116, 200                ['$114pred']
label 116:
    $116load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$116load_global.0']
    $128load_attr.2 = getattr(value=$116load_global.0, attr=signbit) ['$116load_global.0', '$128load_attr.2']
    $144call.4 = call $128load_attr.2(x0, func=$128load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$128load_attr.2', '$144call.4', 'x0']
    $154load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$154load_global.5']
    $166load_attr.7 = getattr(value=$154load_global.5, attr=signbit) ['$154load_global.5', '$166load_attr.7']
    $182call.9 = call $166load_attr.7(x1, func=$166load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$166load_attr.7', '$182call.9', 'x1']
    $192compare_op.10 = $144call.4 != $182call.9 ['$144call.4', '$182call.9', '$192compare_op.10']
    $198return_value.11 = cast(value=$192compare_op.10) ['$192compare_op.10', '$198return_value.11']
    return $198return_value.11               ['$198return_value.11']
label 200:
    $200load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$200load_global.0']
    $212load_attr.2 = getattr(value=$200load_global.0, attr=sign) ['$200load_global.0', '$212load_attr.2']
    $228call.4 = call $212load_attr.2(x0, func=$212load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$212load_attr.2', '$228call.4', 'x0']
    $238load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$238load_global.5']
    $250load_attr.7 = getattr(value=$238load_global.5, attr=sign) ['$238load_global.5', '$250load_attr.7']
    $266call.9 = call $250load_attr.7(x1, func=$250load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$250load_attr.7', '$266call.9', 'x1']
    $276compare_op.10 = $228call.4 != $266call.9 ['$228call.4', '$266call.9', '$276compare_op.10']
    $282return_value.11 = cast(value=$276compare_op.10) ['$276compare_op.10', '$282return_value.11']
    return $282return_value.11               ['$282return_value.11']

2024-01-20 12:21:48,298 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1039)
           2	RESUME(arg=0, lineno=1039)
           4	LOAD_FAST(arg=0, lineno=1042)
           6	LOAD_CONST(arg=1, lineno=1042)
           8	BINARY_SUBSCR(arg=None, lineno=1042)
          18	LOAD_FAST(arg=0, lineno=1042)
          20	LOAD_CONST(arg=2, lineno=1042)
          22	BINARY_SUBSCR(arg=None, lineno=1042)
          32	COMPARE_OP(arg=4, lineno=1042)
          38	LOAD_FAST(arg=0, lineno=1042)
          40	LOAD_CONST(arg=1, lineno=1042)
          42	BINARY_SUBSCR(arg=None, lineno=1042)
          52	LOAD_FAST(arg=0, lineno=1042)
          54	LOAD_CONST(arg=3, lineno=1042)
          56	BINARY_SUBSCR(arg=None, lineno=1042)
          66	COMPARE_OP(arg=5, lineno=1042)
          72	BINARY_OP(arg=1, lineno=1042)
          76	RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 12:21:48,298 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 12:21:48,298 DEBUG numba.core.byteflow stack: []
2024-01-20 12:21:48,298 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 12:21:48,298 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1039)
2024-01-20 12:21:48,298 DEBUG numba.core.byteflow stack []
2024-01-20 12:21:48,298 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1039)
2024-01-20 12:21:48,298 DEBUG numba.core.byteflow stack []
2024-01-20 12:21:48,298 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:21:48,298 DEBUG numba.core.byteflow stack []
2024-01-20 12:21:48,298 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 12:21:48,298 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 12:21:48,298 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:21:48,298 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 12:21:48,298 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:21:48,298 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1042)
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=4, lineno=1042)
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1042)
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=5, lineno=1042)
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1042)
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow defmap: {}
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 12:21:48,299 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 12:21:48,300 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 12:21:48,300 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:21:48,300 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 > $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 >= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 12:21:48,300 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1045)
           2	RESUME(arg=0, lineno=1045)
           4	LOAD_FAST(arg=0, lineno=1048)
           6	LOAD_CONST(arg=1, lineno=1048)
           8	BINARY_SUBSCR(arg=None, lineno=1048)
          18	LOAD_FAST(arg=0, lineno=1048)
          20	LOAD_CONST(arg=2, lineno=1048)
          22	BINARY_SUBSCR(arg=None, lineno=1048)
          32	COMPARE_OP(arg=0, lineno=1048)
          38	LOAD_FAST(arg=0, lineno=1048)
          40	LOAD_CONST(arg=1, lineno=1048)
          42	BINARY_SUBSCR(arg=None, lineno=1048)
          52	LOAD_FAST(arg=0, lineno=1048)
          54	LOAD_CONST(arg=3, lineno=1048)
          56	BINARY_SUBSCR(arg=None, lineno=1048)
          66	COMPARE_OP(arg=1, lineno=1048)
          72	BINARY_OP(arg=1, lineno=1048)
          76	RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow stack: []
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1045)
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow stack []
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1045)
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow stack []
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow stack []
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1048)
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=0, lineno=1048)
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1048)
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=1, lineno=1048)
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1048)
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 12:21:48,301 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:21:48,302 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 12:21:48,302 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 12:21:48,302 DEBUG numba.core.byteflow defmap: {}
2024-01-20 12:21:48,302 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:21:48,302 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:21:48,302 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 12:21:48,302 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 12:21:48,302 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 12:21:48,302 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:21:48,302 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 < $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 <= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 12:21:48,569 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_combined_bfbeb82e58da4c55afe2e46413cc2a72.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 12:21:48,602 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 12:21:48,683 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017CC644B450>
2024-01-20 12:21:48,683 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000017CFE96C320> server_hostname='api.openai.com' timeout=5.0
2024-01-20 12:21:48,701 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017CC7FE7910>
2024-01-20 12:21:48,702 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 12:21:48,702 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 12:21:48,702 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 12:21:48,764 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 12:21:48,764 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 12:21:49,584 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 11:21:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'389'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6685aaeb5462e13d2aad0e8ba9c9e1e3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=GybDFEPjdswtKJVUlMwHijF43.GzNLUzZCFfPm3d2ao-1705749708-1-AcGr+SGHP+CgMuOhIUHKmsOfaaj69NlNIVx4dZ30g05PiZuy7fqUPNR9VB1u7ZVJXikkgJnJLt5Cq3KjRPFMh8Q=; path=/; expires=Sat, 20-Jan-24 11:51:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Eg220VFOGBIgnryesfz8PrjWAp59Sk.FFiQTPsbTjhA-1705749708368-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8486ef97eda01987-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 12:21:49,586 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 12:21:49,586 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 12:21:49,587 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 12:21:49,587 DEBUG httpcore.http11 response_closed.started
2024-01-20 12:21:49,587 DEBUG httpcore.http11 response_closed.complete
2024-01-20 12:21:49,587 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 12:24:14,553 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 12:24:14,555 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 12:24:14,784 INFO transcription All nescessary class variables are declared and working!
2024-01-20 12:24:23,602 INFO transcription Current recording SessionID is: 0ed92f518a9b4c868413a0c67a07664c
2024-01-20 12:24:23,603 INFO transcription Started Microphone Thread for session 0ed92f518a9b4c868413a0c67a07664c!
2024-01-20 12:24:23,604 INFO transcription Opening Stream for device Microsoft Sound Mapper - Input...
2024-01-20 12:24:23,605 INFO transcription Opening Stream for device Stereo Mix (Realtek USB Audio)...
2024-01-20 12:24:23,605 INFO transcription Started System sounds Thread for session 0ed92f518a9b4c868413a0c67a07664c!
2024-01-20 12:24:23,617 INFO transcription Stream for Microphone Microsoft Sound Mapper - Input open!
2024-01-20 12:24:23,675 INFO transcription Stream for Microphone Stereo Mix (Realtek USB Audio) open!
2024-01-20 12:24:31,594 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1135)
           2	RESUME(arg=0, lineno=1135)
           4	LOAD_FAST(arg=0, lineno=1138)
           6	LOAD_CONST(arg=1, lineno=1138)
           8	BINARY_SUBSCR(arg=None, lineno=1138)
          18	STORE_FAST(arg=3, lineno=1138)
          20	LOAD_FAST(arg=1, lineno=1139)
          22	UNARY_NEGATIVE(arg=None, lineno=1139)
          24	LOAD_FAST(arg=3, lineno=1139)
          26	SWAP(arg=2, lineno=1139)
          28	COPY(arg=2, lineno=1139)
          30	COMPARE_OP(arg=1, lineno=1139)
          36	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
          38	LOAD_FAST(arg=1, lineno=1139)
          40	COMPARE_OP(arg=1, lineno=1139)
          46	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
          48	JUMP_FORWARD(arg=2, lineno=1139)
>         50	POP_TOP(arg=None, lineno=1139)
          52	JUMP_FORWARD(arg=2, lineno=1139)
>         54	LOAD_CONST(arg=1, lineno=1140)
          56	STORE_FAST(arg=3, lineno=1140)
>         58	LOAD_FAST(arg=0, lineno=1142)
          60	LOAD_CONST(arg=2, lineno=1142)
          62	BINARY_SUBSCR(arg=None, lineno=1142)
          72	STORE_FAST(arg=4, lineno=1142)
          74	LOAD_FAST(arg=1, lineno=1143)
          76	UNARY_NEGATIVE(arg=None, lineno=1143)
          78	LOAD_FAST(arg=4, lineno=1143)
          80	SWAP(arg=2, lineno=1143)
          82	COPY(arg=2, lineno=1143)
          84	COMPARE_OP(arg=1, lineno=1143)
          90	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
          92	LOAD_FAST(arg=1, lineno=1143)
          94	COMPARE_OP(arg=1, lineno=1143)
         100	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
         102	JUMP_FORWARD(arg=2, lineno=1143)
>        104	POP_TOP(arg=None, lineno=1143)
         106	JUMP_FORWARD(arg=2, lineno=1143)
>        108	LOAD_CONST(arg=1, lineno=1144)
         110	STORE_FAST(arg=4, lineno=1144)
>        112	LOAD_FAST(arg=2, lineno=1146)
         114	POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
         116	LOAD_GLOBAL(arg=1, lineno=1147)
         128	LOAD_ATTR(arg=1, lineno=1147)
         138	LOAD_FAST(arg=3, lineno=1147)
         140	PRECALL(arg=1, lineno=1147)
         144	CALL(arg=1, lineno=1147)
         154	LOAD_GLOBAL(arg=1, lineno=1147)
         166	LOAD_ATTR(arg=1, lineno=1147)
         176	LOAD_FAST(arg=4, lineno=1147)
         178	PRECALL(arg=1, lineno=1147)
         182	CALL(arg=1, lineno=1147)
         192	COMPARE_OP(arg=3, lineno=1147)
         198	RETURN_VALUE(arg=None, lineno=1147)
>        200	LOAD_GLOBAL(arg=1, lineno=1149)
         212	LOAD_ATTR(arg=2, lineno=1149)
         222	LOAD_FAST(arg=3, lineno=1149)
         224	PRECALL(arg=1, lineno=1149)
         228	CALL(arg=1, lineno=1149)
         238	LOAD_GLOBAL(arg=1, lineno=1149)
         250	LOAD_ATTR(arg=2, lineno=1149)
         260	LOAD_FAST(arg=4, lineno=1149)
         262	PRECALL(arg=1, lineno=1149)
         266	CALL(arg=1, lineno=1149)
         276	COMPARE_OP(arg=3, lineno=1149)
         282	RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 12:24:31,594 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 12:24:31,594 DEBUG numba.core.byteflow stack: []
2024-01-20 12:24:31,594 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1135)
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow stack []
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1135)
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow stack []
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1138)
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow stack []
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1138)
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1138)
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow dispatch pc=18, inst=STORE_FAST(arg=3, lineno=1138)
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow stack []
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow dispatch pc=22, inst=UNARY_NEGATIVE(arg=None, lineno=1139)
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow stack ['$threshold20.3']
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow dispatch pc=24, inst=LOAD_FAST(arg=3, lineno=1139)
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow stack ['$22unary_negative.4']
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow dispatch pc=26, inst=SWAP(arg=2, lineno=1139)
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow stack ['$22unary_negative.4', '$x024.5']
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow dispatch pc=28, inst=COPY(arg=2, lineno=1139)
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4']
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow dispatch pc=30, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4', '$x024.5']
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow dispatch pc=36, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow stack ['$x024.5', '$30compare_op.6']
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow end state. edges=[Edge(pc=38, stack=('$x024.5',), blockstack=(), npush=0), Edge(pc=50, stack=('$x024.5',), blockstack=(), npush=0)]
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow pending: deque([State(pc_initial=38 nstack_initial=1), State(pc_initial=50 nstack_initial=1)])
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow stack: ['$phi38.0']
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=38 nstack_initial=1)
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow stack ['$phi38.0']
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow dispatch pc=40, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow stack ['$phi38.0', '$threshold38.1']
2024-01-20 12:24:31,595 DEBUG numba.core.byteflow dispatch pc=46, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow stack ['$40compare_op.2']
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow end state. edges=[Edge(pc=48, stack=(), blockstack=(), npush=0), Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow pending: deque([State(pc_initial=50 nstack_initial=1), State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow stack: ['$phi50.0']
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=50 nstack_initial=1)
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow dispatch pc=50, inst=POP_TOP(arg=None, lineno=1139)
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow stack ['$phi50.0']
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow dispatch pc=52, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow stack []
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow pending: deque([State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow stack: []
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=48 nstack_initial=0)
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow dispatch pc=48, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow stack []
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow end state. edges=[Edge(pc=54, stack=(), blockstack=(), npush=0)]
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0)])
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow stack: []
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=58 nstack_initial=0)
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow dispatch pc=58, inst=LOAD_FAST(arg=0, lineno=1142)
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow stack []
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow dispatch pc=60, inst=LOAD_CONST(arg=2, lineno=1142)
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow stack ['$x58.0']
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow dispatch pc=62, inst=BINARY_SUBSCR(arg=None, lineno=1142)
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow stack ['$x58.0', '$const60.1']
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow dispatch pc=72, inst=STORE_FAST(arg=4, lineno=1142)
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow stack ['$62binary_subscr.2']
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow dispatch pc=74, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow stack []
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow dispatch pc=76, inst=UNARY_NEGATIVE(arg=None, lineno=1143)
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow stack ['$threshold74.3']
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow dispatch pc=78, inst=LOAD_FAST(arg=4, lineno=1143)
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow stack ['$76unary_negative.4']
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow dispatch pc=80, inst=SWAP(arg=2, lineno=1143)
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow stack ['$76unary_negative.4', '$x178.5']
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow dispatch pc=82, inst=COPY(arg=2, lineno=1143)
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4']
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow dispatch pc=84, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4', '$x178.5']
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow dispatch pc=90, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow stack ['$x178.5', '$84compare_op.6']
2024-01-20 12:24:31,596 DEBUG numba.core.byteflow end state. edges=[Edge(pc=92, stack=('$x178.5',), blockstack=(), npush=0), Edge(pc=104, stack=('$x178.5',), blockstack=(), npush=0)]
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow pending: deque([State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow stack: []
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=54 nstack_initial=0)
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=1, lineno=1140)
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow stack []
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow dispatch pc=56, inst=STORE_FAST(arg=3, lineno=1140)
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow stack ['$const54.0']
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow pending: deque([State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0)])
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow stack: ['$phi92.0']
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=92 nstack_initial=1)
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow dispatch pc=92, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow stack ['$phi92.0']
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow dispatch pc=94, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow stack ['$phi92.0', '$threshold92.1']
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow dispatch pc=100, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow stack ['$94compare_op.2']
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow end state. edges=[Edge(pc=102, stack=(), blockstack=(), npush=0), Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow pending: deque([State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow stack: ['$phi104.0']
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=104 nstack_initial=1)
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow dispatch pc=104, inst=POP_TOP(arg=None, lineno=1143)
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow stack ['$phi104.0']
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow dispatch pc=106, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow stack []
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow stack: []
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=102 nstack_initial=0)
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow dispatch pc=102, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow stack []
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow end state. edges=[Edge(pc=108, stack=(), blockstack=(), npush=0)]
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0)])
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow stack: []
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=112 nstack_initial=0)
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow dispatch pc=112, inst=LOAD_FAST(arg=2, lineno=1146)
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow stack []
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow dispatch pc=114, inst=POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow stack ['$zero_pos112.0']
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow end state. edges=[Edge(pc=116, stack=(), blockstack=(), npush=0), Edge(pc=200, stack=(), blockstack=(), npush=0)]
2024-01-20 12:24:31,597 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow pending: deque([State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow stack: []
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=108 nstack_initial=0)
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow dispatch pc=108, inst=LOAD_CONST(arg=1, lineno=1144)
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow stack []
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow dispatch pc=110, inst=STORE_FAST(arg=4, lineno=1144)
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow stack ['$const108.0']
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow pending: deque([State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow stack: []
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=116 nstack_initial=0)
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow dispatch pc=116, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow stack []
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow dispatch pc=128, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow stack ['$null$116.1', '$116load_global.0']
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow dispatch pc=138, inst=LOAD_FAST(arg=3, lineno=1147)
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2']
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow dispatch pc=140, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow dispatch pc=144, inst=CALL(arg=1, lineno=1147)
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow dispatch pc=154, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow stack ['$144call.4']
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow dispatch pc=166, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$154load_global.5']
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow dispatch pc=176, inst=LOAD_FAST(arg=4, lineno=1147)
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7']
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow dispatch pc=178, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow dispatch pc=182, inst=CALL(arg=1, lineno=1147)
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow dispatch pc=192, inst=COMPARE_OP(arg=3, lineno=1147)
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow stack ['$144call.4', '$182call.9']
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow dispatch pc=198, inst=RETURN_VALUE(arg=None, lineno=1147)
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow stack ['$192compare_op.10']
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow pending: deque([State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:24:31,598 DEBUG numba.core.byteflow stack: []
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=200 nstack_initial=0)
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow dispatch pc=200, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow stack []
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow dispatch pc=212, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow stack ['$null$200.1', '$200load_global.0']
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow dispatch pc=222, inst=LOAD_FAST(arg=3, lineno=1149)
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2']
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow dispatch pc=224, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow dispatch pc=228, inst=CALL(arg=1, lineno=1149)
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow dispatch pc=238, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow stack ['$228call.4']
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow dispatch pc=250, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$238load_global.5']
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow dispatch pc=260, inst=LOAD_FAST(arg=4, lineno=1149)
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7']
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow dispatch pc=262, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow dispatch pc=266, inst=CALL(arg=1, lineno=1149)
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow dispatch pc=276, inst=COMPARE_OP(arg=3, lineno=1149)
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow stack ['$228call.4', '$266call.9']
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow dispatch pc=282, inst=RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow stack ['$276compare_op.10']
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=38 nstack_initial=1): {'$phi38.0'},
             State(pc_initial=48 nstack_initial=0): set(),
             State(pc_initial=50 nstack_initial=1): set(),
             State(pc_initial=54 nstack_initial=0): set(),
             State(pc_initial=58 nstack_initial=0): set(),
             State(pc_initial=92 nstack_initial=1): {'$phi92.0'},
             State(pc_initial=102 nstack_initial=0): set(),
             State(pc_initial=104 nstack_initial=1): set(),
             State(pc_initial=108 nstack_initial=0): set(),
             State(pc_initial=112 nstack_initial=0): set(),
             State(pc_initial=116 nstack_initial=0): set(),
             State(pc_initial=200 nstack_initial=0): set()})
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow defmap: {'$phi104.0': State(pc_initial=58 nstack_initial=0),
 '$phi38.0': State(pc_initial=0 nstack_initial=0),
 '$phi50.0': State(pc_initial=0 nstack_initial=0),
 '$phi92.0': State(pc_initial=58 nstack_initial=0)}
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 12:24:31,599 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 12:24:31,600 DEBUG numba.core.byteflow keep phismap: {'$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
 '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}}
2024-01-20 12:24:31,600 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi38.0': '$x024.5'},
             State(pc_initial=58 nstack_initial=0): {'$phi92.0': '$x178.5'}})
2024-01-20 12:24:31,600 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 12:24:31,600 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'value': '$8binary_subscr.2'}), (20, {'res': '$threshold20.3'}), (22, {'value': '$threshold20.3', 'res': '$22unary_negative.4'}), (24, {'res': '$x024.5'}), (30, {'lhs': '$22unary_negative.4', 'rhs': '$x024.5', 'res': '$30compare_op.6'}), (32, {}), (34, {}), (36, {'pred': '$30compare_op.6'})), outgoing_phis={'$phi38.0': '$x024.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={38: ('$x024.5',), 50: ('$x024.5',)})
2024-01-20 12:24:31,600 DEBUG numba.core.byteflow block_infos State(pc_initial=38 nstack_initial=1):
AdaptBlockInfo(insts=((38, {'res': '$threshold38.1'}), (40, {'lhs': '$phi38.0', 'rhs': '$threshold38.1', 'res': '$40compare_op.2'}), (42, {}), (44, {}), (46, {'pred': '$40compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={48: (), 58: ()})
2024-01-20 12:24:31,600 DEBUG numba.core.byteflow block_infos State(pc_initial=48 nstack_initial=0):
AdaptBlockInfo(insts=((48, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={54: ()})
2024-01-20 12:24:31,600 DEBUG numba.core.byteflow block_infos State(pc_initial=50 nstack_initial=1):
AdaptBlockInfo(insts=((52, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 12:24:31,600 DEBUG numba.core.byteflow block_infos State(pc_initial=54 nstack_initial=0):
AdaptBlockInfo(insts=((54, {'res': '$const54.0'}), (56, {'value': '$const54.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 12:24:31,600 DEBUG numba.core.byteflow block_infos State(pc_initial=58 nstack_initial=0):
AdaptBlockInfo(insts=((58, {'res': '$x58.0'}), (60, {'res': '$const60.1'}), (62, {'index': '$const60.1', 'target': '$x58.0', 'res': '$62binary_subscr.2'}), (64, {}), (66, {}), (68, {}), (70, {}), (72, {'value': '$62binary_subscr.2'}), (74, {'res': '$threshold74.3'}), (76, {'value': '$threshold74.3', 'res': '$76unary_negative.4'}), (78, {'res': '$x178.5'}), (84, {'lhs': '$76unary_negative.4', 'rhs': '$x178.5', 'res': '$84compare_op.6'}), (86, {}), (88, {}), (90, {'pred': '$84compare_op.6'})), outgoing_phis={'$phi92.0': '$x178.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={92: ('$x178.5',), 104: ('$x178.5',)})
2024-01-20 12:24:31,600 DEBUG numba.core.byteflow block_infos State(pc_initial=92 nstack_initial=1):
AdaptBlockInfo(insts=((92, {'res': '$threshold92.1'}), (94, {'lhs': '$phi92.0', 'rhs': '$threshold92.1', 'res': '$94compare_op.2'}), (96, {}), (98, {}), (100, {'pred': '$94compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={102: (), 112: ()})
2024-01-20 12:24:31,600 DEBUG numba.core.byteflow block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={108: ()})
2024-01-20 12:24:31,600 DEBUG numba.core.byteflow block_infos State(pc_initial=104 nstack_initial=1):
AdaptBlockInfo(insts=((106, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 12:24:31,600 DEBUG numba.core.byteflow block_infos State(pc_initial=108 nstack_initial=0):
AdaptBlockInfo(insts=((108, {'res': '$const108.0'}), (110, {'value': '$const108.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 12:24:31,600 DEBUG numba.core.byteflow block_infos State(pc_initial=112 nstack_initial=0):
AdaptBlockInfo(insts=((112, {'res': '$zero_pos112.0'}), (114, {'pred': '$zero_pos112.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={116: (), 200: ()})
2024-01-20 12:24:31,600 DEBUG numba.core.byteflow block_infos State(pc_initial=116 nstack_initial=0):
AdaptBlockInfo(insts=((116, {'idx': 0, 'res': '$116load_global.0'}), (118, {}), (120, {}), (122, {}), (124, {}), (126, {}), (128, {'item': '$116load_global.0', 'res': '$128load_attr.2'}), (130, {}), (132, {}), (134, {}), (136, {}), (138, {'res': '$x0138.3'}), (140, {}), (142, {}), (144, {'func': '$128load_attr.2', 'args': ['$x0138.3'], 'kw_names': None, 'res': '$144call.4'}), (146, {}), (148, {}), (150, {}), (152, {}), (154, {'idx': 0, 'res': '$154load_global.5'}), (156, {}), (158, {}), (160, {}), (162, {}), (164, {}), (166, {'item': '$154load_global.5', 'res': '$166load_attr.7'}), (168, {}), (170, {}), (172, {}), (174, {}), (176, {'res': '$x1176.8'}), (178, {}), (180, {}), (182, {'func': '$166load_attr.7', 'args': ['$x1176.8'], 'kw_names': None, 'res': '$182call.9'}), (184, {}), (186, {}), (188, {}), (190, {}), (192, {'lhs': '$144call.4', 'rhs': '$182call.9', 'res': '$192compare_op.10'}), (194, {}), (196, {}), (198, {'retval': '$192compare_op.10', 'castval': '$198return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:24:31,600 DEBUG numba.core.byteflow block_infos State(pc_initial=200 nstack_initial=0):
AdaptBlockInfo(insts=((200, {'idx': 0, 'res': '$200load_global.0'}), (202, {}), (204, {}), (206, {}), (208, {}), (210, {}), (212, {'item': '$200load_global.0', 'res': '$212load_attr.2'}), (214, {}), (216, {}), (218, {}), (220, {}), (222, {'res': '$x0222.3'}), (224, {}), (226, {}), (228, {'func': '$212load_attr.2', 'args': ['$x0222.3'], 'kw_names': None, 'res': '$228call.4'}), (230, {}), (232, {}), (234, {}), (236, {}), (238, {'idx': 0, 'res': '$238load_global.5'}), (240, {}), (242, {}), (244, {}), (246, {}), (248, {}), (250, {'item': '$238load_global.5', 'res': '$250load_attr.7'}), (252, {}), (254, {}), (256, {}), (258, {}), (260, {'res': '$x1260.8'}), (262, {}), (264, {}), (266, {'func': '$250load_attr.7', 'args': ['$x1260.8'], 'kw_names': None, 'res': '$266call.9'}), (268, {}), (270, {}), (272, {}), (274, {}), (276, {'lhs': '$228call.4', 'rhs': '$266call.9', 'res': '$276compare_op.10'}), (278, {}), (280, {}), (282, {'retval': '$276compare_op.10', 'castval': '$282return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:24:31,601 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const6.1 = const(int, 0)                ['$const6.1']
    x0 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$const6.1', 'x', 'x0']
    $22unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$22unary_negative.4', 'threshold']
    $30compare_op.6 = $22unary_negative.4 <= x0 ['$22unary_negative.4', '$30compare_op.6', 'x0']
    bool36 = global(bool: <class 'bool'>)    ['bool36']
    $36pred = call bool36($30compare_op.6, func=bool36, args=(Var($30compare_op.6, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$30compare_op.6', '$36pred', 'bool36']
    $phi38.0 = x0                            ['$phi38.0', 'x0']
    branch $36pred, 38, 50                   ['$36pred']
label 38:
    $40compare_op.2 = $phi38.0 <= threshold  ['$40compare_op.2', '$phi38.0', 'threshold']
    bool46 = global(bool: <class 'bool'>)    ['bool46']
    $46pred = call bool46($40compare_op.2, func=bool46, args=(Var($40compare_op.2, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$40compare_op.2', '$46pred', 'bool46']
    branch $46pred, 48, 58                   ['$46pred']
label 48:
    jump 54                                  []
label 50:
    jump 58                                  []
label 54:
    x0 = const(int, 0)                       ['x0']
    jump 58                                  []
label 58:
    $const60.1 = const(int, -1)              ['$const60.1']
    x1 = getitem(value=x, index=$const60.1, fn=<built-in function getitem>) ['$const60.1', 'x', 'x1']
    $76unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$76unary_negative.4', 'threshold']
    $84compare_op.6 = $76unary_negative.4 <= x1 ['$76unary_negative.4', '$84compare_op.6', 'x1']
    bool90 = global(bool: <class 'bool'>)    ['bool90']
    $90pred = call bool90($84compare_op.6, func=bool90, args=(Var($84compare_op.6, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$84compare_op.6', '$90pred', 'bool90']
    $phi92.0 = x1                            ['$phi92.0', 'x1']
    branch $90pred, 92, 104                  ['$90pred']
label 92:
    $94compare_op.2 = $phi92.0 <= threshold  ['$94compare_op.2', '$phi92.0', 'threshold']
    bool100 = global(bool: <class 'bool'>)   ['bool100']
    $100pred = call bool100($94compare_op.2, func=bool100, args=(Var($94compare_op.2, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$100pred', '$94compare_op.2', 'bool100']
    branch $100pred, 102, 112                ['$100pred']
label 102:
    jump 108                                 []
label 104:
    jump 112                                 []
label 108:
    x1 = const(int, 0)                       ['x1']
    jump 112                                 []
label 112:
    bool114 = global(bool: <class 'bool'>)   ['bool114']
    $114pred = call bool114(zero_pos, func=bool114, args=(Var(zero_pos, audio.py:1135),), kws=(), vararg=None, varkwarg=None, target=None) ['$114pred', 'bool114', 'zero_pos']
    branch $114pred, 116, 200                ['$114pred']
label 116:
    $116load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$116load_global.0']
    $128load_attr.2 = getattr(value=$116load_global.0, attr=signbit) ['$116load_global.0', '$128load_attr.2']
    $144call.4 = call $128load_attr.2(x0, func=$128load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$128load_attr.2', '$144call.4', 'x0']
    $154load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$154load_global.5']
    $166load_attr.7 = getattr(value=$154load_global.5, attr=signbit) ['$154load_global.5', '$166load_attr.7']
    $182call.9 = call $166load_attr.7(x1, func=$166load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$166load_attr.7', '$182call.9', 'x1']
    $192compare_op.10 = $144call.4 != $182call.9 ['$144call.4', '$182call.9', '$192compare_op.10']
    $198return_value.11 = cast(value=$192compare_op.10) ['$192compare_op.10', '$198return_value.11']
    return $198return_value.11               ['$198return_value.11']
label 200:
    $200load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$200load_global.0']
    $212load_attr.2 = getattr(value=$200load_global.0, attr=sign) ['$200load_global.0', '$212load_attr.2']
    $228call.4 = call $212load_attr.2(x0, func=$212load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$212load_attr.2', '$228call.4', 'x0']
    $238load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$238load_global.5']
    $250load_attr.7 = getattr(value=$238load_global.5, attr=sign) ['$238load_global.5', '$250load_attr.7']
    $266call.9 = call $250load_attr.7(x1, func=$250load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$250load_attr.7', '$266call.9', 'x1']
    $276compare_op.10 = $228call.4 != $266call.9 ['$228call.4', '$266call.9', '$276compare_op.10']
    $282return_value.11 = cast(value=$276compare_op.10) ['$276compare_op.10', '$282return_value.11']
    return $282return_value.11               ['$282return_value.11']

2024-01-20 12:24:31,828 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1039)
           2	RESUME(arg=0, lineno=1039)
           4	LOAD_FAST(arg=0, lineno=1042)
           6	LOAD_CONST(arg=1, lineno=1042)
           8	BINARY_SUBSCR(arg=None, lineno=1042)
          18	LOAD_FAST(arg=0, lineno=1042)
          20	LOAD_CONST(arg=2, lineno=1042)
          22	BINARY_SUBSCR(arg=None, lineno=1042)
          32	COMPARE_OP(arg=4, lineno=1042)
          38	LOAD_FAST(arg=0, lineno=1042)
          40	LOAD_CONST(arg=1, lineno=1042)
          42	BINARY_SUBSCR(arg=None, lineno=1042)
          52	LOAD_FAST(arg=0, lineno=1042)
          54	LOAD_CONST(arg=3, lineno=1042)
          56	BINARY_SUBSCR(arg=None, lineno=1042)
          66	COMPARE_OP(arg=5, lineno=1042)
          72	BINARY_OP(arg=1, lineno=1042)
          76	RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow stack: []
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1039)
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow stack []
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1039)
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow stack []
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow stack []
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1042)
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=4, lineno=1042)
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 12:24:31,828 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1042)
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=5, lineno=1042)
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1042)
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow defmap: {}
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 12:24:31,829 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:24:31,830 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 > $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 >= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 12:24:31,830 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1045)
           2	RESUME(arg=0, lineno=1045)
           4	LOAD_FAST(arg=0, lineno=1048)
           6	LOAD_CONST(arg=1, lineno=1048)
           8	BINARY_SUBSCR(arg=None, lineno=1048)
          18	LOAD_FAST(arg=0, lineno=1048)
          20	LOAD_CONST(arg=2, lineno=1048)
          22	BINARY_SUBSCR(arg=None, lineno=1048)
          32	COMPARE_OP(arg=0, lineno=1048)
          38	LOAD_FAST(arg=0, lineno=1048)
          40	LOAD_CONST(arg=1, lineno=1048)
          42	BINARY_SUBSCR(arg=None, lineno=1048)
          52	LOAD_FAST(arg=0, lineno=1048)
          54	LOAD_CONST(arg=3, lineno=1048)
          56	BINARY_SUBSCR(arg=None, lineno=1048)
          66	COMPARE_OP(arg=1, lineno=1048)
          72	BINARY_OP(arg=1, lineno=1048)
          76	RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 12:24:31,830 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 12:24:31,830 DEBUG numba.core.byteflow stack: []
2024-01-20 12:24:31,830 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 12:24:31,830 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1045)
2024-01-20 12:24:31,830 DEBUG numba.core.byteflow stack []
2024-01-20 12:24:31,830 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1045)
2024-01-20 12:24:31,830 DEBUG numba.core.byteflow stack []
2024-01-20 12:24:31,830 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:24:31,830 DEBUG numba.core.byteflow stack []
2024-01-20 12:24:31,830 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 12:24:31,830 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 12:24:31,830 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:24:31,830 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 12:24:31,830 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:24:31,830 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 12:24:31,830 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1048)
2024-01-20 12:24:31,830 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=0, lineno=1048)
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1048)
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=1, lineno=1048)
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1048)
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow defmap: {}
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 12:24:31,831 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:24:31,832 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 < $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 <= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 12:24:32,074 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_combined_11a87077db8b44438b43439b57705556.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 12:24:32,105 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 12:24:32,180 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021E2A71F350>
2024-01-20 12:24:32,180 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021E75F445F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 12:24:32,202 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021E2A747290>
2024-01-20 12:24:32,202 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 12:24:32,203 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 12:24:32,203 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 12:24:32,261 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 12:24:32,261 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 12:24:33,127 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 11:24:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'342'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1bba206b1b28b29e7b5f3bb759d1980d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=IAHTQJsFnBpqSFPsL5b_HNayhk364gEaX9fzo9qMomo-1705749871-1-ARFZ/cML4vydC4HDZYOaNjCcYUSzDaHhe2wMzRooQhKXxRhSBu6XTi6k7bymHKhjsb4ex94kgyIj18NZ6nNk6rI=; path=/; expires=Sat, 20-Jan-24 11:54:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=cmRF83R.EIE8iHUWVYnye.FSn6cVq7IPUVdB7CPb9j0-1705749871909-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8486f395c80f1e59-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 12:24:33,129 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 12:24:33,129 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 12:24:33,129 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 12:24:33,129 DEBUG httpcore.http11 response_closed.started
2024-01-20 12:24:33,129 DEBUG httpcore.http11 response_closed.complete
2024-01-20 12:24:33,130 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 12:25:33,141 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 12:25:33,143 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 12:25:33,387 INFO transcription All nescessary class variables are declared and working!
2024-01-20 12:25:34,826 INFO transcription Current recording SessionID is: 82564efd9b424abca3e23575025ec0d4
2024-01-20 12:25:34,827 INFO transcription Started Microphone Thread for session 82564efd9b424abca3e23575025ec0d4!
2024-01-20 12:25:34,828 INFO transcription Opening Stream for device Microsoft Sound Mapper - Input...
2024-01-20 12:25:34,829 INFO transcription Started System sounds Thread for session 82564efd9b424abca3e23575025ec0d4!
2024-01-20 12:25:34,829 INFO transcription Opening Stream for device Stereo Mix (Realtek USB Audio)...
2024-01-20 12:25:34,841 INFO transcription Stream for Microphone Microsoft Sound Mapper - Input open!
2024-01-20 12:25:34,899 INFO transcription Stream for Microphone Stereo Mix (Realtek USB Audio) open!
2024-01-20 12:25:40,812 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1135)
           2	RESUME(arg=0, lineno=1135)
           4	LOAD_FAST(arg=0, lineno=1138)
           6	LOAD_CONST(arg=1, lineno=1138)
           8	BINARY_SUBSCR(arg=None, lineno=1138)
          18	STORE_FAST(arg=3, lineno=1138)
          20	LOAD_FAST(arg=1, lineno=1139)
          22	UNARY_NEGATIVE(arg=None, lineno=1139)
          24	LOAD_FAST(arg=3, lineno=1139)
          26	SWAP(arg=2, lineno=1139)
          28	COPY(arg=2, lineno=1139)
          30	COMPARE_OP(arg=1, lineno=1139)
          36	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
          38	LOAD_FAST(arg=1, lineno=1139)
          40	COMPARE_OP(arg=1, lineno=1139)
          46	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
          48	JUMP_FORWARD(arg=2, lineno=1139)
>         50	POP_TOP(arg=None, lineno=1139)
          52	JUMP_FORWARD(arg=2, lineno=1139)
>         54	LOAD_CONST(arg=1, lineno=1140)
          56	STORE_FAST(arg=3, lineno=1140)
>         58	LOAD_FAST(arg=0, lineno=1142)
          60	LOAD_CONST(arg=2, lineno=1142)
          62	BINARY_SUBSCR(arg=None, lineno=1142)
          72	STORE_FAST(arg=4, lineno=1142)
          74	LOAD_FAST(arg=1, lineno=1143)
          76	UNARY_NEGATIVE(arg=None, lineno=1143)
          78	LOAD_FAST(arg=4, lineno=1143)
          80	SWAP(arg=2, lineno=1143)
          82	COPY(arg=2, lineno=1143)
          84	COMPARE_OP(arg=1, lineno=1143)
          90	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
          92	LOAD_FAST(arg=1, lineno=1143)
          94	COMPARE_OP(arg=1, lineno=1143)
         100	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
         102	JUMP_FORWARD(arg=2, lineno=1143)
>        104	POP_TOP(arg=None, lineno=1143)
         106	JUMP_FORWARD(arg=2, lineno=1143)
>        108	LOAD_CONST(arg=1, lineno=1144)
         110	STORE_FAST(arg=4, lineno=1144)
>        112	LOAD_FAST(arg=2, lineno=1146)
         114	POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
         116	LOAD_GLOBAL(arg=1, lineno=1147)
         128	LOAD_ATTR(arg=1, lineno=1147)
         138	LOAD_FAST(arg=3, lineno=1147)
         140	PRECALL(arg=1, lineno=1147)
         144	CALL(arg=1, lineno=1147)
         154	LOAD_GLOBAL(arg=1, lineno=1147)
         166	LOAD_ATTR(arg=1, lineno=1147)
         176	LOAD_FAST(arg=4, lineno=1147)
         178	PRECALL(arg=1, lineno=1147)
         182	CALL(arg=1, lineno=1147)
         192	COMPARE_OP(arg=3, lineno=1147)
         198	RETURN_VALUE(arg=None, lineno=1147)
>        200	LOAD_GLOBAL(arg=1, lineno=1149)
         212	LOAD_ATTR(arg=2, lineno=1149)
         222	LOAD_FAST(arg=3, lineno=1149)
         224	PRECALL(arg=1, lineno=1149)
         228	CALL(arg=1, lineno=1149)
         238	LOAD_GLOBAL(arg=1, lineno=1149)
         250	LOAD_ATTR(arg=2, lineno=1149)
         260	LOAD_FAST(arg=4, lineno=1149)
         262	PRECALL(arg=1, lineno=1149)
         266	CALL(arg=1, lineno=1149)
         276	COMPARE_OP(arg=3, lineno=1149)
         282	RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow stack: []
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1135)
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow stack []
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1135)
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow stack []
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1138)
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow stack []
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1138)
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1138)
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow dispatch pc=18, inst=STORE_FAST(arg=3, lineno=1138)
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow stack []
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow dispatch pc=22, inst=UNARY_NEGATIVE(arg=None, lineno=1139)
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow stack ['$threshold20.3']
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow dispatch pc=24, inst=LOAD_FAST(arg=3, lineno=1139)
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow stack ['$22unary_negative.4']
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow dispatch pc=26, inst=SWAP(arg=2, lineno=1139)
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow stack ['$22unary_negative.4', '$x024.5']
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow dispatch pc=28, inst=COPY(arg=2, lineno=1139)
2024-01-20 12:25:40,813 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4']
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow dispatch pc=30, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4', '$x024.5']
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow dispatch pc=36, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow stack ['$x024.5', '$30compare_op.6']
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow end state. edges=[Edge(pc=38, stack=('$x024.5',), blockstack=(), npush=0), Edge(pc=50, stack=('$x024.5',), blockstack=(), npush=0)]
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow pending: deque([State(pc_initial=38 nstack_initial=1), State(pc_initial=50 nstack_initial=1)])
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow stack: ['$phi38.0']
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=38 nstack_initial=1)
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow stack ['$phi38.0']
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow dispatch pc=40, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow stack ['$phi38.0', '$threshold38.1']
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow dispatch pc=46, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow stack ['$40compare_op.2']
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow end state. edges=[Edge(pc=48, stack=(), blockstack=(), npush=0), Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow pending: deque([State(pc_initial=50 nstack_initial=1), State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow stack: ['$phi50.0']
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=50 nstack_initial=1)
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow dispatch pc=50, inst=POP_TOP(arg=None, lineno=1139)
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow stack ['$phi50.0']
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow dispatch pc=52, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow stack []
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow pending: deque([State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow stack: []
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=48 nstack_initial=0)
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow dispatch pc=48, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow stack []
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow end state. edges=[Edge(pc=54, stack=(), blockstack=(), npush=0)]
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0)])
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow stack: []
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=58 nstack_initial=0)
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow dispatch pc=58, inst=LOAD_FAST(arg=0, lineno=1142)
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow stack []
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow dispatch pc=60, inst=LOAD_CONST(arg=2, lineno=1142)
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow stack ['$x58.0']
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow dispatch pc=62, inst=BINARY_SUBSCR(arg=None, lineno=1142)
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow stack ['$x58.0', '$const60.1']
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow dispatch pc=72, inst=STORE_FAST(arg=4, lineno=1142)
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow stack ['$62binary_subscr.2']
2024-01-20 12:25:40,814 DEBUG numba.core.byteflow dispatch pc=74, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow stack []
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow dispatch pc=76, inst=UNARY_NEGATIVE(arg=None, lineno=1143)
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow stack ['$threshold74.3']
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow dispatch pc=78, inst=LOAD_FAST(arg=4, lineno=1143)
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow stack ['$76unary_negative.4']
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow dispatch pc=80, inst=SWAP(arg=2, lineno=1143)
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow stack ['$76unary_negative.4', '$x178.5']
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow dispatch pc=82, inst=COPY(arg=2, lineno=1143)
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4']
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow dispatch pc=84, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4', '$x178.5']
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow dispatch pc=90, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow stack ['$x178.5', '$84compare_op.6']
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow end state. edges=[Edge(pc=92, stack=('$x178.5',), blockstack=(), npush=0), Edge(pc=104, stack=('$x178.5',), blockstack=(), npush=0)]
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow pending: deque([State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow stack: []
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=54 nstack_initial=0)
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=1, lineno=1140)
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow stack []
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow dispatch pc=56, inst=STORE_FAST(arg=3, lineno=1140)
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow stack ['$const54.0']
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow pending: deque([State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0)])
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow stack: ['$phi92.0']
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=92 nstack_initial=1)
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow dispatch pc=92, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow stack ['$phi92.0']
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow dispatch pc=94, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow stack ['$phi92.0', '$threshold92.1']
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow dispatch pc=100, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow stack ['$94compare_op.2']
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow end state. edges=[Edge(pc=102, stack=(), blockstack=(), npush=0), Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow pending: deque([State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow stack: ['$phi104.0']
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=104 nstack_initial=1)
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow dispatch pc=104, inst=POP_TOP(arg=None, lineno=1143)
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow stack ['$phi104.0']
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow dispatch pc=106, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow stack []
2024-01-20 12:25:40,815 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow stack: []
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=102 nstack_initial=0)
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow dispatch pc=102, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow stack []
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow end state. edges=[Edge(pc=108, stack=(), blockstack=(), npush=0)]
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0)])
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow stack: []
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=112 nstack_initial=0)
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow dispatch pc=112, inst=LOAD_FAST(arg=2, lineno=1146)
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow stack []
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow dispatch pc=114, inst=POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow stack ['$zero_pos112.0']
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow end state. edges=[Edge(pc=116, stack=(), blockstack=(), npush=0), Edge(pc=200, stack=(), blockstack=(), npush=0)]
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow pending: deque([State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow stack: []
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=108 nstack_initial=0)
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow dispatch pc=108, inst=LOAD_CONST(arg=1, lineno=1144)
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow stack []
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow dispatch pc=110, inst=STORE_FAST(arg=4, lineno=1144)
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow stack ['$const108.0']
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow pending: deque([State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow stack: []
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=116 nstack_initial=0)
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow dispatch pc=116, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow stack []
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow dispatch pc=128, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow stack ['$null$116.1', '$116load_global.0']
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow dispatch pc=138, inst=LOAD_FAST(arg=3, lineno=1147)
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2']
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow dispatch pc=140, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow dispatch pc=144, inst=CALL(arg=1, lineno=1147)
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow dispatch pc=154, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow stack ['$144call.4']
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow dispatch pc=166, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$154load_global.5']
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow dispatch pc=176, inst=LOAD_FAST(arg=4, lineno=1147)
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7']
2024-01-20 12:25:40,816 DEBUG numba.core.byteflow dispatch pc=178, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow dispatch pc=182, inst=CALL(arg=1, lineno=1147)
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow dispatch pc=192, inst=COMPARE_OP(arg=3, lineno=1147)
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow stack ['$144call.4', '$182call.9']
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow dispatch pc=198, inst=RETURN_VALUE(arg=None, lineno=1147)
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow stack ['$192compare_op.10']
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow pending: deque([State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow stack: []
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=200 nstack_initial=0)
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow dispatch pc=200, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow stack []
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow dispatch pc=212, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow stack ['$null$200.1', '$200load_global.0']
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow dispatch pc=222, inst=LOAD_FAST(arg=3, lineno=1149)
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2']
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow dispatch pc=224, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow dispatch pc=228, inst=CALL(arg=1, lineno=1149)
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow dispatch pc=238, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow stack ['$228call.4']
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow dispatch pc=250, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$238load_global.5']
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow dispatch pc=260, inst=LOAD_FAST(arg=4, lineno=1149)
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7']
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow dispatch pc=262, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow dispatch pc=266, inst=CALL(arg=1, lineno=1149)
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow dispatch pc=276, inst=COMPARE_OP(arg=3, lineno=1149)
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow stack ['$228call.4', '$266call.9']
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow dispatch pc=282, inst=RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow stack ['$276compare_op.10']
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0)])
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 12:25:40,817 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=38 nstack_initial=1): {'$phi38.0'},
             State(pc_initial=48 nstack_initial=0): set(),
             State(pc_initial=50 nstack_initial=1): set(),
             State(pc_initial=54 nstack_initial=0): set(),
             State(pc_initial=58 nstack_initial=0): set(),
             State(pc_initial=92 nstack_initial=1): {'$phi92.0'},
             State(pc_initial=102 nstack_initial=0): set(),
             State(pc_initial=104 nstack_initial=1): set(),
             State(pc_initial=108 nstack_initial=0): set(),
             State(pc_initial=112 nstack_initial=0): set(),
             State(pc_initial=116 nstack_initial=0): set(),
             State(pc_initial=200 nstack_initial=0): set()})
2024-01-20 12:25:40,818 DEBUG numba.core.byteflow defmap: {'$phi104.0': State(pc_initial=58 nstack_initial=0),
 '$phi38.0': State(pc_initial=0 nstack_initial=0),
 '$phi50.0': State(pc_initial=0 nstack_initial=0),
 '$phi92.0': State(pc_initial=58 nstack_initial=0)}
2024-01-20 12:25:40,818 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 12:25:40,818 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 12:25:40,818 DEBUG numba.core.byteflow keep phismap: {'$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
 '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}}
2024-01-20 12:25:40,818 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi38.0': '$x024.5'},
             State(pc_initial=58 nstack_initial=0): {'$phi92.0': '$x178.5'}})
2024-01-20 12:25:40,818 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 12:25:40,818 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'value': '$8binary_subscr.2'}), (20, {'res': '$threshold20.3'}), (22, {'value': '$threshold20.3', 'res': '$22unary_negative.4'}), (24, {'res': '$x024.5'}), (30, {'lhs': '$22unary_negative.4', 'rhs': '$x024.5', 'res': '$30compare_op.6'}), (32, {}), (34, {}), (36, {'pred': '$30compare_op.6'})), outgoing_phis={'$phi38.0': '$x024.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={38: ('$x024.5',), 50: ('$x024.5',)})
2024-01-20 12:25:40,818 DEBUG numba.core.byteflow block_infos State(pc_initial=38 nstack_initial=1):
AdaptBlockInfo(insts=((38, {'res': '$threshold38.1'}), (40, {'lhs': '$phi38.0', 'rhs': '$threshold38.1', 'res': '$40compare_op.2'}), (42, {}), (44, {}), (46, {'pred': '$40compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={48: (), 58: ()})
2024-01-20 12:25:40,818 DEBUG numba.core.byteflow block_infos State(pc_initial=48 nstack_initial=0):
AdaptBlockInfo(insts=((48, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={54: ()})
2024-01-20 12:25:40,818 DEBUG numba.core.byteflow block_infos State(pc_initial=50 nstack_initial=1):
AdaptBlockInfo(insts=((52, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 12:25:40,818 DEBUG numba.core.byteflow block_infos State(pc_initial=54 nstack_initial=0):
AdaptBlockInfo(insts=((54, {'res': '$const54.0'}), (56, {'value': '$const54.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 12:25:40,818 DEBUG numba.core.byteflow block_infos State(pc_initial=58 nstack_initial=0):
AdaptBlockInfo(insts=((58, {'res': '$x58.0'}), (60, {'res': '$const60.1'}), (62, {'index': '$const60.1', 'target': '$x58.0', 'res': '$62binary_subscr.2'}), (64, {}), (66, {}), (68, {}), (70, {}), (72, {'value': '$62binary_subscr.2'}), (74, {'res': '$threshold74.3'}), (76, {'value': '$threshold74.3', 'res': '$76unary_negative.4'}), (78, {'res': '$x178.5'}), (84, {'lhs': '$76unary_negative.4', 'rhs': '$x178.5', 'res': '$84compare_op.6'}), (86, {}), (88, {}), (90, {'pred': '$84compare_op.6'})), outgoing_phis={'$phi92.0': '$x178.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={92: ('$x178.5',), 104: ('$x178.5',)})
2024-01-20 12:25:40,818 DEBUG numba.core.byteflow block_infos State(pc_initial=92 nstack_initial=1):
AdaptBlockInfo(insts=((92, {'res': '$threshold92.1'}), (94, {'lhs': '$phi92.0', 'rhs': '$threshold92.1', 'res': '$94compare_op.2'}), (96, {}), (98, {}), (100, {'pred': '$94compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={102: (), 112: ()})
2024-01-20 12:25:40,818 DEBUG numba.core.byteflow block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={108: ()})
2024-01-20 12:25:40,818 DEBUG numba.core.byteflow block_infos State(pc_initial=104 nstack_initial=1):
AdaptBlockInfo(insts=((106, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 12:25:40,818 DEBUG numba.core.byteflow block_infos State(pc_initial=108 nstack_initial=0):
AdaptBlockInfo(insts=((108, {'res': '$const108.0'}), (110, {'value': '$const108.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 12:25:40,818 DEBUG numba.core.byteflow block_infos State(pc_initial=112 nstack_initial=0):
AdaptBlockInfo(insts=((112, {'res': '$zero_pos112.0'}), (114, {'pred': '$zero_pos112.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={116: (), 200: ()})
2024-01-20 12:25:40,818 DEBUG numba.core.byteflow block_infos State(pc_initial=116 nstack_initial=0):
AdaptBlockInfo(insts=((116, {'idx': 0, 'res': '$116load_global.0'}), (118, {}), (120, {}), (122, {}), (124, {}), (126, {}), (128, {'item': '$116load_global.0', 'res': '$128load_attr.2'}), (130, {}), (132, {}), (134, {}), (136, {}), (138, {'res': '$x0138.3'}), (140, {}), (142, {}), (144, {'func': '$128load_attr.2', 'args': ['$x0138.3'], 'kw_names': None, 'res': '$144call.4'}), (146, {}), (148, {}), (150, {}), (152, {}), (154, {'idx': 0, 'res': '$154load_global.5'}), (156, {}), (158, {}), (160, {}), (162, {}), (164, {}), (166, {'item': '$154load_global.5', 'res': '$166load_attr.7'}), (168, {}), (170, {}), (172, {}), (174, {}), (176, {'res': '$x1176.8'}), (178, {}), (180, {}), (182, {'func': '$166load_attr.7', 'args': ['$x1176.8'], 'kw_names': None, 'res': '$182call.9'}), (184, {}), (186, {}), (188, {}), (190, {}), (192, {'lhs': '$144call.4', 'rhs': '$182call.9', 'res': '$192compare_op.10'}), (194, {}), (196, {}), (198, {'retval': '$192compare_op.10', 'castval': '$198return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:25:40,818 DEBUG numba.core.byteflow block_infos State(pc_initial=200 nstack_initial=0):
AdaptBlockInfo(insts=((200, {'idx': 0, 'res': '$200load_global.0'}), (202, {}), (204, {}), (206, {}), (208, {}), (210, {}), (212, {'item': '$200load_global.0', 'res': '$212load_attr.2'}), (214, {}), (216, {}), (218, {}), (220, {}), (222, {'res': '$x0222.3'}), (224, {}), (226, {}), (228, {'func': '$212load_attr.2', 'args': ['$x0222.3'], 'kw_names': None, 'res': '$228call.4'}), (230, {}), (232, {}), (234, {}), (236, {}), (238, {'idx': 0, 'res': '$238load_global.5'}), (240, {}), (242, {}), (244, {}), (246, {}), (248, {}), (250, {'item': '$238load_global.5', 'res': '$250load_attr.7'}), (252, {}), (254, {}), (256, {}), (258, {}), (260, {'res': '$x1260.8'}), (262, {}), (264, {}), (266, {'func': '$250load_attr.7', 'args': ['$x1260.8'], 'kw_names': None, 'res': '$266call.9'}), (268, {}), (270, {}), (272, {}), (274, {}), (276, {'lhs': '$228call.4', 'rhs': '$266call.9', 'res': '$276compare_op.10'}), (278, {}), (280, {}), (282, {'retval': '$276compare_op.10', 'castval': '$282return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:25:40,819 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const6.1 = const(int, 0)                ['$const6.1']
    x0 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$const6.1', 'x', 'x0']
    $22unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$22unary_negative.4', 'threshold']
    $30compare_op.6 = $22unary_negative.4 <= x0 ['$22unary_negative.4', '$30compare_op.6', 'x0']
    bool36 = global(bool: <class 'bool'>)    ['bool36']
    $36pred = call bool36($30compare_op.6, func=bool36, args=(Var($30compare_op.6, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$30compare_op.6', '$36pred', 'bool36']
    $phi38.0 = x0                            ['$phi38.0', 'x0']
    branch $36pred, 38, 50                   ['$36pred']
label 38:
    $40compare_op.2 = $phi38.0 <= threshold  ['$40compare_op.2', '$phi38.0', 'threshold']
    bool46 = global(bool: <class 'bool'>)    ['bool46']
    $46pred = call bool46($40compare_op.2, func=bool46, args=(Var($40compare_op.2, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$40compare_op.2', '$46pred', 'bool46']
    branch $46pred, 48, 58                   ['$46pred']
label 48:
    jump 54                                  []
label 50:
    jump 58                                  []
label 54:
    x0 = const(int, 0)                       ['x0']
    jump 58                                  []
label 58:
    $const60.1 = const(int, -1)              ['$const60.1']
    x1 = getitem(value=x, index=$const60.1, fn=<built-in function getitem>) ['$const60.1', 'x', 'x1']
    $76unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$76unary_negative.4', 'threshold']
    $84compare_op.6 = $76unary_negative.4 <= x1 ['$76unary_negative.4', '$84compare_op.6', 'x1']
    bool90 = global(bool: <class 'bool'>)    ['bool90']
    $90pred = call bool90($84compare_op.6, func=bool90, args=(Var($84compare_op.6, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$84compare_op.6', '$90pred', 'bool90']
    $phi92.0 = x1                            ['$phi92.0', 'x1']
    branch $90pred, 92, 104                  ['$90pred']
label 92:
    $94compare_op.2 = $phi92.0 <= threshold  ['$94compare_op.2', '$phi92.0', 'threshold']
    bool100 = global(bool: <class 'bool'>)   ['bool100']
    $100pred = call bool100($94compare_op.2, func=bool100, args=(Var($94compare_op.2, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$100pred', '$94compare_op.2', 'bool100']
    branch $100pred, 102, 112                ['$100pred']
label 102:
    jump 108                                 []
label 104:
    jump 112                                 []
label 108:
    x1 = const(int, 0)                       ['x1']
    jump 112                                 []
label 112:
    bool114 = global(bool: <class 'bool'>)   ['bool114']
    $114pred = call bool114(zero_pos, func=bool114, args=(Var(zero_pos, audio.py:1135),), kws=(), vararg=None, varkwarg=None, target=None) ['$114pred', 'bool114', 'zero_pos']
    branch $114pred, 116, 200                ['$114pred']
label 116:
    $116load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$116load_global.0']
    $128load_attr.2 = getattr(value=$116load_global.0, attr=signbit) ['$116load_global.0', '$128load_attr.2']
    $144call.4 = call $128load_attr.2(x0, func=$128load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$128load_attr.2', '$144call.4', 'x0']
    $154load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$154load_global.5']
    $166load_attr.7 = getattr(value=$154load_global.5, attr=signbit) ['$154load_global.5', '$166load_attr.7']
    $182call.9 = call $166load_attr.7(x1, func=$166load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$166load_attr.7', '$182call.9', 'x1']
    $192compare_op.10 = $144call.4 != $182call.9 ['$144call.4', '$182call.9', '$192compare_op.10']
    $198return_value.11 = cast(value=$192compare_op.10) ['$192compare_op.10', '$198return_value.11']
    return $198return_value.11               ['$198return_value.11']
label 200:
    $200load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$200load_global.0']
    $212load_attr.2 = getattr(value=$200load_global.0, attr=sign) ['$200load_global.0', '$212load_attr.2']
    $228call.4 = call $212load_attr.2(x0, func=$212load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$212load_attr.2', '$228call.4', 'x0']
    $238load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$238load_global.5']
    $250load_attr.7 = getattr(value=$238load_global.5, attr=sign) ['$238load_global.5', '$250load_attr.7']
    $266call.9 = call $250load_attr.7(x1, func=$250load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$250load_attr.7', '$266call.9', 'x1']
    $276compare_op.10 = $228call.4 != $266call.9 ['$228call.4', '$266call.9', '$276compare_op.10']
    $282return_value.11 = cast(value=$276compare_op.10) ['$276compare_op.10', '$282return_value.11']
    return $282return_value.11               ['$282return_value.11']

2024-01-20 12:25:41,046 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1039)
           2	RESUME(arg=0, lineno=1039)
           4	LOAD_FAST(arg=0, lineno=1042)
           6	LOAD_CONST(arg=1, lineno=1042)
           8	BINARY_SUBSCR(arg=None, lineno=1042)
          18	LOAD_FAST(arg=0, lineno=1042)
          20	LOAD_CONST(arg=2, lineno=1042)
          22	BINARY_SUBSCR(arg=None, lineno=1042)
          32	COMPARE_OP(arg=4, lineno=1042)
          38	LOAD_FAST(arg=0, lineno=1042)
          40	LOAD_CONST(arg=1, lineno=1042)
          42	BINARY_SUBSCR(arg=None, lineno=1042)
          52	LOAD_FAST(arg=0, lineno=1042)
          54	LOAD_CONST(arg=3, lineno=1042)
          56	BINARY_SUBSCR(arg=None, lineno=1042)
          66	COMPARE_OP(arg=5, lineno=1042)
          72	BINARY_OP(arg=1, lineno=1042)
          76	RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 12:25:41,046 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 12:25:41,046 DEBUG numba.core.byteflow stack: []
2024-01-20 12:25:41,046 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 12:25:41,046 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1039)
2024-01-20 12:25:41,046 DEBUG numba.core.byteflow stack []
2024-01-20 12:25:41,046 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1039)
2024-01-20 12:25:41,046 DEBUG numba.core.byteflow stack []
2024-01-20 12:25:41,046 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:25:41,046 DEBUG numba.core.byteflow stack []
2024-01-20 12:25:41,046 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 12:25:41,046 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 12:25:41,046 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1042)
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=4, lineno=1042)
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1042)
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=5, lineno=1042)
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1042)
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow defmap: {}
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 12:25:41,047 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:25:41,048 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 > $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 >= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 12:25:41,048 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1045)
           2	RESUME(arg=0, lineno=1045)
           4	LOAD_FAST(arg=0, lineno=1048)
           6	LOAD_CONST(arg=1, lineno=1048)
           8	BINARY_SUBSCR(arg=None, lineno=1048)
          18	LOAD_FAST(arg=0, lineno=1048)
          20	LOAD_CONST(arg=2, lineno=1048)
          22	BINARY_SUBSCR(arg=None, lineno=1048)
          32	COMPARE_OP(arg=0, lineno=1048)
          38	LOAD_FAST(arg=0, lineno=1048)
          40	LOAD_CONST(arg=1, lineno=1048)
          42	BINARY_SUBSCR(arg=None, lineno=1048)
          52	LOAD_FAST(arg=0, lineno=1048)
          54	LOAD_CONST(arg=3, lineno=1048)
          56	BINARY_SUBSCR(arg=None, lineno=1048)
          66	COMPARE_OP(arg=1, lineno=1048)
          72	BINARY_OP(arg=1, lineno=1048)
          76	RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 12:25:41,048 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 12:25:41,048 DEBUG numba.core.byteflow stack: []
2024-01-20 12:25:41,048 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1045)
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow stack []
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1045)
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow stack []
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow stack []
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1048)
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=0, lineno=1048)
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1048)
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=1, lineno=1048)
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1048)
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow defmap: {}
2024-01-20 12:25:41,049 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:25:41,050 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 12:25:41,050 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 12:25:41,050 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 12:25:41,050 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 12:25:41,050 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 12:25:41,050 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 < $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 <= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 12:25:41,300 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_combined_f9a6b63aa7b54de49eaa563dbf5dd518.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 12:25:41,331 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 12:25:41,428 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002590A484B90>
2024-01-20 12:25:41,428 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000002597EE945F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 12:25:41,445 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002593E0F7CD0>
2024-01-20 12:25:41,445 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 12:25:41,446 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 12:25:41,446 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 12:25:41,496 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 12:25:41,496 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 12:25:42,211 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 11:25:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'309'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a0a137a44ebd23b44d918f597bb9117d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=TuhmrV1ld1DrAArnBPL2ZlrbXITFBCWVJ9Fq0rcB1cg-1705749940-1-AflUdccWetsKdXHbZXB5liSluRm6hkEGX0/LEoKBGtUGicIWtXZV5qtbMpFtgLlJGsbq03IJJF+/natR4MBUxlk=; path=/; expires=Sat, 20-Jan-24 11:55:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=QGdDURfa25GuYCbyzRSyHCSyo7pgY2LfNgfURIjpmKA-1705749940992-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8486f546883f2bd6-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 12:25:42,213 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 12:25:42,213 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 12:25:42,214 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 12:25:42,214 DEBUG httpcore.http11 response_closed.started
2024-01-20 12:25:42,214 DEBUG httpcore.http11 response_closed.complete
2024-01-20 12:25:42,214 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 13:15:17,682 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 13:15:17,683 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 13:15:17,915 INFO transcription All nescessary class variables are declared and working!
2024-01-20 13:15:29,750 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\DATA\\videoplayback (1)\\videoplayback (1).mp3'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 13:15:29,779 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 13:15:29,870 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019AC75B5890>
2024-01-20 13:15:29,871 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000019AC75AC710> server_hostname='api.openai.com' timeout=5.0
2024-01-20 13:15:29,885 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019AC81B6D10>
2024-01-20 13:15:29,885 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 13:15:29,886 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 13:15:29,886 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 13:15:54,046 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 13:15:54,046 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 13:15:58,072 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 12:15:56 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'611'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8f7894f404f7dd20f7ce7005fc70f0a5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Dp6kDPp690_S3jLhkq1ZCGsYrGexTfdrAsADi61yxSU-1705752956-1-ASfY1MqPqgyr3XH40a/LnfyOiqWC9OOPT1jWVFmvwYWNzbZ6Z5XUO/n/5pos9HUvfjkgLXF7fcuAT5h31/Cnf2w=; path=/; expires=Sat, 20-Jan-24 12:45:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=iKAI_SQx62bjaWH1zS0tyo_CdkbNhWOZhcqjWeY71IY-1705752956795-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84873e3beb173a9e-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 13:15:58,075 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 13:15:58,075 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 13:15:58,076 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 13:15:58,076 DEBUG httpcore.http11 response_closed.started
2024-01-20 13:15:58,076 DEBUG httpcore.http11 response_closed.complete
2024-01-20 13:15:58,076 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 13:15:58,077 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 13:15:58,079 DEBUG openai._base_client Not retrying
2024-01-20 13:15:58,079 DEBUG openai._base_client Re-raising status error
2024-01-20 13:33:42,075 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 13:33:42,077 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 13:33:42,311 INFO transcription All nescessary class variables are declared and working!
2024-01-20 13:34:38,243 INFO transcription Current recording SessionID is: e244757be9db449b8ab16e700a056488
2024-01-20 13:34:38,244 INFO transcription Started Microphone Thread for session e244757be9db449b8ab16e700a056488!
2024-01-20 13:34:38,245 INFO transcription Opening Stream for device Microsoft Sound Mapper - Input...
2024-01-20 13:34:38,245 INFO transcription Started System sounds Thread for session e244757be9db449b8ab16e700a056488!
2024-01-20 13:34:38,246 INFO transcription Opening Stream for device Stereo Mix (Realtek USB Audio)...
2024-01-20 13:34:38,257 INFO transcription Stream for Microphone Microsoft Sound Mapper - Input open!
2024-01-20 13:34:38,318 INFO transcription Stream for Microphone Stereo Mix (Realtek USB Audio) open!
2024-01-20 13:34:46,262 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1135)
           2	RESUME(arg=0, lineno=1135)
           4	LOAD_FAST(arg=0, lineno=1138)
           6	LOAD_CONST(arg=1, lineno=1138)
           8	BINARY_SUBSCR(arg=None, lineno=1138)
          18	STORE_FAST(arg=3, lineno=1138)
          20	LOAD_FAST(arg=1, lineno=1139)
          22	UNARY_NEGATIVE(arg=None, lineno=1139)
          24	LOAD_FAST(arg=3, lineno=1139)
          26	SWAP(arg=2, lineno=1139)
          28	COPY(arg=2, lineno=1139)
          30	COMPARE_OP(arg=1, lineno=1139)
          36	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
          38	LOAD_FAST(arg=1, lineno=1139)
          40	COMPARE_OP(arg=1, lineno=1139)
          46	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
          48	JUMP_FORWARD(arg=2, lineno=1139)
>         50	POP_TOP(arg=None, lineno=1139)
          52	JUMP_FORWARD(arg=2, lineno=1139)
>         54	LOAD_CONST(arg=1, lineno=1140)
          56	STORE_FAST(arg=3, lineno=1140)
>         58	LOAD_FAST(arg=0, lineno=1142)
          60	LOAD_CONST(arg=2, lineno=1142)
          62	BINARY_SUBSCR(arg=None, lineno=1142)
          72	STORE_FAST(arg=4, lineno=1142)
          74	LOAD_FAST(arg=1, lineno=1143)
          76	UNARY_NEGATIVE(arg=None, lineno=1143)
          78	LOAD_FAST(arg=4, lineno=1143)
          80	SWAP(arg=2, lineno=1143)
          82	COPY(arg=2, lineno=1143)
          84	COMPARE_OP(arg=1, lineno=1143)
          90	POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
          92	LOAD_FAST(arg=1, lineno=1143)
          94	COMPARE_OP(arg=1, lineno=1143)
         100	POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
         102	JUMP_FORWARD(arg=2, lineno=1143)
>        104	POP_TOP(arg=None, lineno=1143)
         106	JUMP_FORWARD(arg=2, lineno=1143)
>        108	LOAD_CONST(arg=1, lineno=1144)
         110	STORE_FAST(arg=4, lineno=1144)
>        112	LOAD_FAST(arg=2, lineno=1146)
         114	POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
         116	LOAD_GLOBAL(arg=1, lineno=1147)
         128	LOAD_ATTR(arg=1, lineno=1147)
         138	LOAD_FAST(arg=3, lineno=1147)
         140	PRECALL(arg=1, lineno=1147)
         144	CALL(arg=1, lineno=1147)
         154	LOAD_GLOBAL(arg=1, lineno=1147)
         166	LOAD_ATTR(arg=1, lineno=1147)
         176	LOAD_FAST(arg=4, lineno=1147)
         178	PRECALL(arg=1, lineno=1147)
         182	CALL(arg=1, lineno=1147)
         192	COMPARE_OP(arg=3, lineno=1147)
         198	RETURN_VALUE(arg=None, lineno=1147)
>        200	LOAD_GLOBAL(arg=1, lineno=1149)
         212	LOAD_ATTR(arg=2, lineno=1149)
         222	LOAD_FAST(arg=3, lineno=1149)
         224	PRECALL(arg=1, lineno=1149)
         228	CALL(arg=1, lineno=1149)
         238	LOAD_GLOBAL(arg=1, lineno=1149)
         250	LOAD_ATTR(arg=2, lineno=1149)
         260	LOAD_FAST(arg=4, lineno=1149)
         262	PRECALL(arg=1, lineno=1149)
         266	CALL(arg=1, lineno=1149)
         276	COMPARE_OP(arg=3, lineno=1149)
         282	RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 13:34:46,262 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 13:34:46,262 DEBUG numba.core.byteflow stack: []
2024-01-20 13:34:46,262 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 13:34:46,262 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1135)
2024-01-20 13:34:46,262 DEBUG numba.core.byteflow stack []
2024-01-20 13:34:46,262 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1135)
2024-01-20 13:34:46,262 DEBUG numba.core.byteflow stack []
2024-01-20 13:34:46,262 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1138)
2024-01-20 13:34:46,262 DEBUG numba.core.byteflow stack []
2024-01-20 13:34:46,262 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1138)
2024-01-20 13:34:46,262 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 13:34:46,262 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1138)
2024-01-20 13:34:46,262 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 13:34:46,262 DEBUG numba.core.byteflow dispatch pc=18, inst=STORE_FAST(arg=3, lineno=1138)
2024-01-20 13:34:46,262 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 13:34:46,262 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 13:34:46,262 DEBUG numba.core.byteflow stack []
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow dispatch pc=22, inst=UNARY_NEGATIVE(arg=None, lineno=1139)
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow stack ['$threshold20.3']
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow dispatch pc=24, inst=LOAD_FAST(arg=3, lineno=1139)
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow stack ['$22unary_negative.4']
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow dispatch pc=26, inst=SWAP(arg=2, lineno=1139)
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow stack ['$22unary_negative.4', '$x024.5']
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow dispatch pc=28, inst=COPY(arg=2, lineno=1139)
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4']
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow dispatch pc=30, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow stack ['$x024.5', '$22unary_negative.4', '$x024.5']
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow dispatch pc=36, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1139)
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow stack ['$x024.5', '$30compare_op.6']
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow end state. edges=[Edge(pc=38, stack=('$x024.5',), blockstack=(), npush=0), Edge(pc=50, stack=('$x024.5',), blockstack=(), npush=0)]
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow pending: deque([State(pc_initial=38 nstack_initial=1), State(pc_initial=50 nstack_initial=1)])
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow stack: ['$phi38.0']
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=38 nstack_initial=1)
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=1, lineno=1139)
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow stack ['$phi38.0']
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow dispatch pc=40, inst=COMPARE_OP(arg=1, lineno=1139)
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow stack ['$phi38.0', '$threshold38.1']
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow dispatch pc=46, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1139)
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow stack ['$40compare_op.2']
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow end state. edges=[Edge(pc=48, stack=(), blockstack=(), npush=0), Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow pending: deque([State(pc_initial=50 nstack_initial=1), State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow stack: ['$phi50.0']
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=50 nstack_initial=1)
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow dispatch pc=50, inst=POP_TOP(arg=None, lineno=1139)
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow stack ['$phi50.0']
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow dispatch pc=52, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow stack []
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow pending: deque([State(pc_initial=48 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0)])
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow stack: []
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=48 nstack_initial=0)
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow dispatch pc=48, inst=JUMP_FORWARD(arg=2, lineno=1139)
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow stack []
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow end state. edges=[Edge(pc=54, stack=(), blockstack=(), npush=0)]
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0)])
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow stack: []
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=58 nstack_initial=0)
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow dispatch pc=58, inst=LOAD_FAST(arg=0, lineno=1142)
2024-01-20 13:34:46,263 DEBUG numba.core.byteflow stack []
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow dispatch pc=60, inst=LOAD_CONST(arg=2, lineno=1142)
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow stack ['$x58.0']
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow dispatch pc=62, inst=BINARY_SUBSCR(arg=None, lineno=1142)
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow stack ['$x58.0', '$const60.1']
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow dispatch pc=72, inst=STORE_FAST(arg=4, lineno=1142)
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow stack ['$62binary_subscr.2']
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow dispatch pc=74, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow stack []
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow dispatch pc=76, inst=UNARY_NEGATIVE(arg=None, lineno=1143)
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow stack ['$threshold74.3']
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow dispatch pc=78, inst=LOAD_FAST(arg=4, lineno=1143)
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow stack ['$76unary_negative.4']
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow dispatch pc=80, inst=SWAP(arg=2, lineno=1143)
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow stack ['$76unary_negative.4', '$x178.5']
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow dispatch pc=82, inst=COPY(arg=2, lineno=1143)
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4']
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow dispatch pc=84, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow stack ['$x178.5', '$76unary_negative.4', '$x178.5']
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow dispatch pc=90, inst=POP_JUMP_FORWARD_IF_FALSE(arg=6, lineno=1143)
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow stack ['$x178.5', '$84compare_op.6']
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow end state. edges=[Edge(pc=92, stack=('$x178.5',), blockstack=(), npush=0), Edge(pc=104, stack=('$x178.5',), blockstack=(), npush=0)]
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow pending: deque([State(pc_initial=54 nstack_initial=0), State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1)])
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow stack: []
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=54 nstack_initial=0)
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=1, lineno=1140)
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow stack []
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow dispatch pc=56, inst=STORE_FAST(arg=3, lineno=1140)
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow stack ['$const54.0']
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow end state. edges=[Edge(pc=58, stack=(), blockstack=(), npush=0)]
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow pending: deque([State(pc_initial=92 nstack_initial=1), State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0)])
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow stack: ['$phi92.0']
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=92 nstack_initial=1)
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow dispatch pc=92, inst=LOAD_FAST(arg=1, lineno=1143)
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow stack ['$phi92.0']
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow dispatch pc=94, inst=COMPARE_OP(arg=1, lineno=1143)
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow stack ['$phi92.0', '$threshold92.1']
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow dispatch pc=100, inst=POP_JUMP_FORWARD_IF_FALSE(arg=5, lineno=1143)
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow stack ['$94compare_op.2']
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow end state. edges=[Edge(pc=102, stack=(), blockstack=(), npush=0), Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow pending: deque([State(pc_initial=104 nstack_initial=1), State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow stack: ['$phi104.0']
2024-01-20 13:34:46,264 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=104 nstack_initial=1)
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow dispatch pc=104, inst=POP_TOP(arg=None, lineno=1143)
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow stack ['$phi104.0']
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow dispatch pc=106, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow stack []
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow pending: deque([State(pc_initial=58 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow stack: []
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=102 nstack_initial=0)
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow dispatch pc=102, inst=JUMP_FORWARD(arg=2, lineno=1143)
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow stack []
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow end state. edges=[Edge(pc=108, stack=(), blockstack=(), npush=0)]
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0)])
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow stack: []
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=112 nstack_initial=0)
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow dispatch pc=112, inst=LOAD_FAST(arg=2, lineno=1146)
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow stack []
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow dispatch pc=114, inst=POP_JUMP_FORWARD_IF_FALSE(arg=42, lineno=1146)
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow stack ['$zero_pos112.0']
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow end state. edges=[Edge(pc=116, stack=(), blockstack=(), npush=0), Edge(pc=200, stack=(), blockstack=(), npush=0)]
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0), State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow pending: deque([State(pc_initial=108 nstack_initial=0), State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0)])
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow stack: []
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=108 nstack_initial=0)
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow dispatch pc=108, inst=LOAD_CONST(arg=1, lineno=1144)
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow stack []
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow dispatch pc=110, inst=STORE_FAST(arg=4, lineno=1144)
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow stack ['$const108.0']
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow end state. edges=[Edge(pc=112, stack=(), blockstack=(), npush=0)]
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow pending: deque([State(pc_initial=116 nstack_initial=0), State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow stack: []
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=116 nstack_initial=0)
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow dispatch pc=116, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow stack []
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow dispatch pc=128, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow stack ['$null$116.1', '$116load_global.0']
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow dispatch pc=138, inst=LOAD_FAST(arg=3, lineno=1147)
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2']
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow dispatch pc=140, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow dispatch pc=144, inst=CALL(arg=1, lineno=1147)
2024-01-20 13:34:46,265 DEBUG numba.core.byteflow stack ['$null$116.1', '$128load_attr.2', '$x0138.3']
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow dispatch pc=154, inst=LOAD_GLOBAL(arg=1, lineno=1147)
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow stack ['$144call.4']
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow dispatch pc=166, inst=LOAD_ATTR(arg=1, lineno=1147)
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$154load_global.5']
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow dispatch pc=176, inst=LOAD_FAST(arg=4, lineno=1147)
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7']
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow dispatch pc=178, inst=PRECALL(arg=1, lineno=1147)
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow dispatch pc=182, inst=CALL(arg=1, lineno=1147)
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow stack ['$144call.4', '$null$154.6', '$166load_attr.7', '$x1176.8']
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow dispatch pc=192, inst=COMPARE_OP(arg=3, lineno=1147)
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow stack ['$144call.4', '$182call.9']
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow dispatch pc=198, inst=RETURN_VALUE(arg=None, lineno=1147)
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow stack ['$192compare_op.10']
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow pending: deque([State(pc_initial=200 nstack_initial=0), State(pc_initial=112 nstack_initial=0)])
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow stack: []
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=200 nstack_initial=0)
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow dispatch pc=200, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow stack []
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow dispatch pc=212, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow stack ['$null$200.1', '$200load_global.0']
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow dispatch pc=222, inst=LOAD_FAST(arg=3, lineno=1149)
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2']
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow dispatch pc=224, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow dispatch pc=228, inst=CALL(arg=1, lineno=1149)
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow stack ['$null$200.1', '$212load_attr.2', '$x0222.3']
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow dispatch pc=238, inst=LOAD_GLOBAL(arg=1, lineno=1149)
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow stack ['$228call.4']
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow dispatch pc=250, inst=LOAD_ATTR(arg=2, lineno=1149)
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$238load_global.5']
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow dispatch pc=260, inst=LOAD_FAST(arg=4, lineno=1149)
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7']
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow dispatch pc=262, inst=PRECALL(arg=1, lineno=1149)
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow dispatch pc=266, inst=CALL(arg=1, lineno=1149)
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow stack ['$228call.4', '$null$238.6', '$250load_attr.7', '$x1260.8']
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow dispatch pc=276, inst=COMPARE_OP(arg=3, lineno=1149)
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow stack ['$228call.4', '$266call.9']
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow dispatch pc=282, inst=RETURN_VALUE(arg=None, lineno=1149)
2024-01-20 13:34:46,266 DEBUG numba.core.byteflow stack ['$276compare_op.10']
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow pending: deque([State(pc_initial=112 nstack_initial=0)])
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=38 nstack_initial=1): {'$phi38.0'},
             State(pc_initial=48 nstack_initial=0): set(),
             State(pc_initial=50 nstack_initial=1): set(),
             State(pc_initial=54 nstack_initial=0): set(),
             State(pc_initial=58 nstack_initial=0): set(),
             State(pc_initial=92 nstack_initial=1): {'$phi92.0'},
             State(pc_initial=102 nstack_initial=0): set(),
             State(pc_initial=104 nstack_initial=1): set(),
             State(pc_initial=108 nstack_initial=0): set(),
             State(pc_initial=112 nstack_initial=0): set(),
             State(pc_initial=116 nstack_initial=0): set(),
             State(pc_initial=200 nstack_initial=0): set()})
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow defmap: {'$phi104.0': State(pc_initial=58 nstack_initial=0),
 '$phi38.0': State(pc_initial=0 nstack_initial=0),
 '$phi50.0': State(pc_initial=0 nstack_initial=0),
 '$phi92.0': State(pc_initial=58 nstack_initial=0)}
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>,
            {'$phi104.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))},
             '$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi50.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
             '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}})
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow keep phismap: {'$phi38.0': {('$x024.5', State(pc_initial=0 nstack_initial=0))},
 '$phi92.0': {('$x178.5', State(pc_initial=58 nstack_initial=0))}}
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi38.0': '$x024.5'},
             State(pc_initial=58 nstack_initial=0): {'$phi92.0': '$x178.5'}})
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'value': '$8binary_subscr.2'}), (20, {'res': '$threshold20.3'}), (22, {'value': '$threshold20.3', 'res': '$22unary_negative.4'}), (24, {'res': '$x024.5'}), (30, {'lhs': '$22unary_negative.4', 'rhs': '$x024.5', 'res': '$30compare_op.6'}), (32, {}), (34, {}), (36, {'pred': '$30compare_op.6'})), outgoing_phis={'$phi38.0': '$x024.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={38: ('$x024.5',), 50: ('$x024.5',)})
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow block_infos State(pc_initial=38 nstack_initial=1):
AdaptBlockInfo(insts=((38, {'res': '$threshold38.1'}), (40, {'lhs': '$phi38.0', 'rhs': '$threshold38.1', 'res': '$40compare_op.2'}), (42, {}), (44, {}), (46, {'pred': '$40compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={48: (), 58: ()})
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow block_infos State(pc_initial=48 nstack_initial=0):
AdaptBlockInfo(insts=((48, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={54: ()})
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow block_infos State(pc_initial=50 nstack_initial=1):
AdaptBlockInfo(insts=((52, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow block_infos State(pc_initial=54 nstack_initial=0):
AdaptBlockInfo(insts=((54, {'res': '$const54.0'}), (56, {'value': '$const54.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={58: ()})
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow block_infos State(pc_initial=58 nstack_initial=0):
AdaptBlockInfo(insts=((58, {'res': '$x58.0'}), (60, {'res': '$const60.1'}), (62, {'index': '$const60.1', 'target': '$x58.0', 'res': '$62binary_subscr.2'}), (64, {}), (66, {}), (68, {}), (70, {}), (72, {'value': '$62binary_subscr.2'}), (74, {'res': '$threshold74.3'}), (76, {'value': '$threshold74.3', 'res': '$76unary_negative.4'}), (78, {'res': '$x178.5'}), (84, {'lhs': '$76unary_negative.4', 'rhs': '$x178.5', 'res': '$84compare_op.6'}), (86, {}), (88, {}), (90, {'pred': '$84compare_op.6'})), outgoing_phis={'$phi92.0': '$x178.5'}, blockstack=(), active_try_block=None, outgoing_edgepushed={92: ('$x178.5',), 104: ('$x178.5',)})
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow block_infos State(pc_initial=92 nstack_initial=1):
AdaptBlockInfo(insts=((92, {'res': '$threshold92.1'}), (94, {'lhs': '$phi92.0', 'rhs': '$threshold92.1', 'res': '$94compare_op.2'}), (96, {}), (98, {}), (100, {'pred': '$94compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={102: (), 112: ()})
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={108: ()})
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow block_infos State(pc_initial=104 nstack_initial=1):
AdaptBlockInfo(insts=((106, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow block_infos State(pc_initial=108 nstack_initial=0):
AdaptBlockInfo(insts=((108, {'res': '$const108.0'}), (110, {'value': '$const108.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={112: ()})
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow block_infos State(pc_initial=112 nstack_initial=0):
AdaptBlockInfo(insts=((112, {'res': '$zero_pos112.0'}), (114, {'pred': '$zero_pos112.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={116: (), 200: ()})
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow block_infos State(pc_initial=116 nstack_initial=0):
AdaptBlockInfo(insts=((116, {'idx': 0, 'res': '$116load_global.0'}), (118, {}), (120, {}), (122, {}), (124, {}), (126, {}), (128, {'item': '$116load_global.0', 'res': '$128load_attr.2'}), (130, {}), (132, {}), (134, {}), (136, {}), (138, {'res': '$x0138.3'}), (140, {}), (142, {}), (144, {'func': '$128load_attr.2', 'args': ['$x0138.3'], 'kw_names': None, 'res': '$144call.4'}), (146, {}), (148, {}), (150, {}), (152, {}), (154, {'idx': 0, 'res': '$154load_global.5'}), (156, {}), (158, {}), (160, {}), (162, {}), (164, {}), (166, {'item': '$154load_global.5', 'res': '$166load_attr.7'}), (168, {}), (170, {}), (172, {}), (174, {}), (176, {'res': '$x1176.8'}), (178, {}), (180, {}), (182, {'func': '$166load_attr.7', 'args': ['$x1176.8'], 'kw_names': None, 'res': '$182call.9'}), (184, {}), (186, {}), (188, {}), (190, {}), (192, {'lhs': '$144call.4', 'rhs': '$182call.9', 'res': '$192compare_op.10'}), (194, {}), (196, {}), (198, {'retval': '$192compare_op.10', 'castval': '$198return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 13:34:46,267 DEBUG numba.core.byteflow block_infos State(pc_initial=200 nstack_initial=0):
AdaptBlockInfo(insts=((200, {'idx': 0, 'res': '$200load_global.0'}), (202, {}), (204, {}), (206, {}), (208, {}), (210, {}), (212, {'item': '$200load_global.0', 'res': '$212load_attr.2'}), (214, {}), (216, {}), (218, {}), (220, {}), (222, {'res': '$x0222.3'}), (224, {}), (226, {}), (228, {'func': '$212load_attr.2', 'args': ['$x0222.3'], 'kw_names': None, 'res': '$228call.4'}), (230, {}), (232, {}), (234, {}), (236, {}), (238, {'idx': 0, 'res': '$238load_global.5'}), (240, {}), (242, {}), (244, {}), (246, {}), (248, {}), (250, {'item': '$238load_global.5', 'res': '$250load_attr.7'}), (252, {}), (254, {}), (256, {}), (258, {}), (260, {'res': '$x1260.8'}), (262, {}), (264, {}), (266, {'func': '$250load_attr.7', 'args': ['$x1260.8'], 'kw_names': None, 'res': '$266call.9'}), (268, {}), (270, {}), (272, {}), (274, {}), (276, {'lhs': '$228call.4', 'rhs': '$266call.9', 'res': '$276compare_op.10'}), (278, {}), (280, {}), (282, {'retval': '$276compare_op.10', 'castval': '$282return_value.11'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 13:34:46,268 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const6.1 = const(int, 0)                ['$const6.1']
    x0 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$const6.1', 'x', 'x0']
    $22unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$22unary_negative.4', 'threshold']
    $30compare_op.6 = $22unary_negative.4 <= x0 ['$22unary_negative.4', '$30compare_op.6', 'x0']
    bool36 = global(bool: <class 'bool'>)    ['bool36']
    $36pred = call bool36($30compare_op.6, func=bool36, args=(Var($30compare_op.6, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$30compare_op.6', '$36pred', 'bool36']
    $phi38.0 = x0                            ['$phi38.0', 'x0']
    branch $36pred, 38, 50                   ['$36pred']
label 38:
    $40compare_op.2 = $phi38.0 <= threshold  ['$40compare_op.2', '$phi38.0', 'threshold']
    bool46 = global(bool: <class 'bool'>)    ['bool46']
    $46pred = call bool46($40compare_op.2, func=bool46, args=(Var($40compare_op.2, audio.py:1139),), kws=(), vararg=None, varkwarg=None, target=None) ['$40compare_op.2', '$46pred', 'bool46']
    branch $46pred, 48, 58                   ['$46pred']
label 48:
    jump 54                                  []
label 50:
    jump 58                                  []
label 54:
    x0 = const(int, 0)                       ['x0']
    jump 58                                  []
label 58:
    $const60.1 = const(int, -1)              ['$const60.1']
    x1 = getitem(value=x, index=$const60.1, fn=<built-in function getitem>) ['$const60.1', 'x', 'x1']
    $76unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$76unary_negative.4', 'threshold']
    $84compare_op.6 = $76unary_negative.4 <= x1 ['$76unary_negative.4', '$84compare_op.6', 'x1']
    bool90 = global(bool: <class 'bool'>)    ['bool90']
    $90pred = call bool90($84compare_op.6, func=bool90, args=(Var($84compare_op.6, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$84compare_op.6', '$90pred', 'bool90']
    $phi92.0 = x1                            ['$phi92.0', 'x1']
    branch $90pred, 92, 104                  ['$90pred']
label 92:
    $94compare_op.2 = $phi92.0 <= threshold  ['$94compare_op.2', '$phi92.0', 'threshold']
    bool100 = global(bool: <class 'bool'>)   ['bool100']
    $100pred = call bool100($94compare_op.2, func=bool100, args=(Var($94compare_op.2, audio.py:1143),), kws=(), vararg=None, varkwarg=None, target=None) ['$100pred', '$94compare_op.2', 'bool100']
    branch $100pred, 102, 112                ['$100pred']
label 102:
    jump 108                                 []
label 104:
    jump 112                                 []
label 108:
    x1 = const(int, 0)                       ['x1']
    jump 112                                 []
label 112:
    bool114 = global(bool: <class 'bool'>)   ['bool114']
    $114pred = call bool114(zero_pos, func=bool114, args=(Var(zero_pos, audio.py:1135),), kws=(), vararg=None, varkwarg=None, target=None) ['$114pred', 'bool114', 'zero_pos']
    branch $114pred, 116, 200                ['$114pred']
label 116:
    $116load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$116load_global.0']
    $128load_attr.2 = getattr(value=$116load_global.0, attr=signbit) ['$116load_global.0', '$128load_attr.2']
    $144call.4 = call $128load_attr.2(x0, func=$128load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$128load_attr.2', '$144call.4', 'x0']
    $154load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$154load_global.5']
    $166load_attr.7 = getattr(value=$154load_global.5, attr=signbit) ['$154load_global.5', '$166load_attr.7']
    $182call.9 = call $166load_attr.7(x1, func=$166load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$166load_attr.7', '$182call.9', 'x1']
    $192compare_op.10 = $144call.4 != $182call.9 ['$144call.4', '$182call.9', '$192compare_op.10']
    $198return_value.11 = cast(value=$192compare_op.10) ['$192compare_op.10', '$198return_value.11']
    return $198return_value.11               ['$198return_value.11']
label 200:
    $200load_global.0 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$200load_global.0']
    $212load_attr.2 = getattr(value=$200load_global.0, attr=sign) ['$200load_global.0', '$212load_attr.2']
    $228call.4 = call $212load_attr.2(x0, func=$212load_attr.2, args=[Var(x0, audio.py:1138)], kws=(), vararg=None, varkwarg=None, target=None) ['$212load_attr.2', '$228call.4', 'x0']
    $238load_global.5 = global(np: <module 'numpy' from 'd:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\numpy\\__init__.py'>) ['$238load_global.5']
    $250load_attr.7 = getattr(value=$238load_global.5, attr=sign) ['$238load_global.5', '$250load_attr.7']
    $266call.9 = call $250load_attr.7(x1, func=$250load_attr.7, args=[Var(x1, audio.py:1142)], kws=(), vararg=None, varkwarg=None, target=None) ['$250load_attr.7', '$266call.9', 'x1']
    $276compare_op.10 = $228call.4 != $266call.9 ['$228call.4', '$266call.9', '$276compare_op.10']
    $282return_value.11 = cast(value=$276compare_op.10) ['$276compare_op.10', '$282return_value.11']
    return $282return_value.11               ['$282return_value.11']

2024-01-20 13:34:46,502 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1039)
           2	RESUME(arg=0, lineno=1039)
           4	LOAD_FAST(arg=0, lineno=1042)
           6	LOAD_CONST(arg=1, lineno=1042)
           8	BINARY_SUBSCR(arg=None, lineno=1042)
          18	LOAD_FAST(arg=0, lineno=1042)
          20	LOAD_CONST(arg=2, lineno=1042)
          22	BINARY_SUBSCR(arg=None, lineno=1042)
          32	COMPARE_OP(arg=4, lineno=1042)
          38	LOAD_FAST(arg=0, lineno=1042)
          40	LOAD_CONST(arg=1, lineno=1042)
          42	BINARY_SUBSCR(arg=None, lineno=1042)
          52	LOAD_FAST(arg=0, lineno=1042)
          54	LOAD_CONST(arg=3, lineno=1042)
          56	BINARY_SUBSCR(arg=None, lineno=1042)
          66	COMPARE_OP(arg=5, lineno=1042)
          72	BINARY_OP(arg=1, lineno=1042)
          76	RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow stack: []
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1039)
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow stack []
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1039)
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow stack []
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow stack []
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1042)
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=4, lineno=1042)
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1042)
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1042)
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1042)
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1042)
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=5, lineno=1042)
2024-01-20 13:34:46,503 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 13:34:46,504 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1042)
2024-01-20 13:34:46,504 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 13:34:46,504 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1042)
2024-01-20 13:34:46,504 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 13:34:46,504 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 13:34:46,504 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 13:34:46,504 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 13:34:46,504 DEBUG numba.core.byteflow defmap: {}
2024-01-20 13:34:46,504 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 13:34:46,504 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 13:34:46,504 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 13:34:46,504 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 13:34:46,504 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 13:34:46,504 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 13:34:46,504 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 > $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 >= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 13:34:46,505 DEBUG numba.core.byteflow bytecode dump:
>          0	NOP(arg=None, lineno=1045)
           2	RESUME(arg=0, lineno=1045)
           4	LOAD_FAST(arg=0, lineno=1048)
           6	LOAD_CONST(arg=1, lineno=1048)
           8	BINARY_SUBSCR(arg=None, lineno=1048)
          18	LOAD_FAST(arg=0, lineno=1048)
          20	LOAD_CONST(arg=2, lineno=1048)
          22	BINARY_SUBSCR(arg=None, lineno=1048)
          32	COMPARE_OP(arg=0, lineno=1048)
          38	LOAD_FAST(arg=0, lineno=1048)
          40	LOAD_CONST(arg=1, lineno=1048)
          42	BINARY_SUBSCR(arg=None, lineno=1048)
          52	LOAD_FAST(arg=0, lineno=1048)
          54	LOAD_CONST(arg=3, lineno=1048)
          56	BINARY_SUBSCR(arg=None, lineno=1048)
          66	COMPARE_OP(arg=1, lineno=1048)
          72	BINARY_OP(arg=1, lineno=1048)
          76	RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow pending: deque([State(pc_initial=0 nstack_initial=0)])
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow stack: []
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow state.pc_initial: State(pc_initial=0 nstack_initial=0)
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow dispatch pc=0, inst=NOP(arg=None, lineno=1045)
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow stack []
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow dispatch pc=2, inst=RESUME(arg=0, lineno=1045)
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow stack []
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow dispatch pc=4, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow stack []
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow dispatch pc=6, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow stack ['$x4.0']
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow dispatch pc=8, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow stack ['$x4.0', '$const6.1']
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow dispatch pc=18, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow stack ['$8binary_subscr.2']
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow dispatch pc=20, inst=LOAD_CONST(arg=2, lineno=1048)
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3']
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow dispatch pc=22, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$x18.3', '$const20.4']
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow dispatch pc=32, inst=COMPARE_OP(arg=0, lineno=1048)
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow stack ['$8binary_subscr.2', '$22binary_subscr.5']
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow dispatch pc=38, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow stack ['$32compare_op.6']
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow dispatch pc=40, inst=LOAD_CONST(arg=1, lineno=1048)
2024-01-20 13:34:46,505 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7']
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow dispatch pc=42, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$x38.7', '$const40.8']
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow dispatch pc=52, inst=LOAD_FAST(arg=0, lineno=1048)
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9']
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow dispatch pc=54, inst=LOAD_CONST(arg=3, lineno=1048)
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10']
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow dispatch pc=56, inst=BINARY_SUBSCR(arg=None, lineno=1048)
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$x52.10', '$const54.11']
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow dispatch pc=66, inst=COMPARE_OP(arg=1, lineno=1048)
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$42binary_subscr.9', '$56binary_subscr.12']
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow dispatch pc=72, inst=BINARY_OP(arg=1, lineno=1048)
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow stack ['$32compare_op.6', '$66compare_op.13']
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow dispatch pc=76, inst=RETURN_VALUE(arg=None, lineno=1048)
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow stack ['$binop_and_72.14']
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow end state. edges=[]
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow -------------------------Prune PHIs-------------------------
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow defmap: {}
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow phismap: defaultdict(<class 'set'>, {})
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow changing phismap: defaultdict(<class 'set'>, {})
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow keep phismap: {}
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow new_out: defaultdict(<class 'dict'>, {})
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow ----------------------DONE Prune PHIs-----------------------
2024-01-20 13:34:46,506 DEBUG numba.core.byteflow block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {}), (4, {'res': '$x4.0'}), (6, {'res': '$const6.1'}), (8, {'index': '$const6.1', 'target': '$x4.0', 'res': '$8binary_subscr.2'}), (10, {}), (12, {}), (14, {}), (16, {}), (18, {'res': '$x18.3'}), (20, {'res': '$const20.4'}), (22, {'index': '$const20.4', 'target': '$x18.3', 'res': '$22binary_subscr.5'}), (24, {}), (26, {}), (28, {}), (30, {}), (32, {'lhs': '$8binary_subscr.2', 'rhs': '$22binary_subscr.5', 'res': '$32compare_op.6'}), (34, {}), (36, {}), (38, {'res': '$x38.7'}), (40, {'res': '$const40.8'}), (42, {'index': '$const40.8', 'target': '$x38.7', 'res': '$42binary_subscr.9'}), (44, {}), (46, {}), (48, {}), (50, {}), (52, {'res': '$x52.10'}), (54, {'res': '$const54.11'}), (56, {'index': '$const54.11', 'target': '$x52.10', 'res': '$56binary_subscr.12'}), (58, {}), (60, {}), (62, {}), (64, {}), (66, {'lhs': '$42binary_subscr.9', 'rhs': '$56binary_subscr.12', 'res': '$66compare_op.13'}), (68, {}), (70, {}), (72, {'op': '&', 'lhs': '$32compare_op.6', 'rhs': '$66compare_op.13', 'res': '$binop_and_72.14'}), (74, {}), (76, {'retval': '$binop_and_72.14', 'castval': '$76return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2024-01-20 13:34:46,506 DEBUG numba.core.interpreter label 0:
    x = arg(0, name=x)                       ['x']
    $const6.1 = const(int, 0)                ['$const6.1']
    $8binary_subscr.2 = getitem(value=x, index=$const6.1, fn=<built-in function getitem>) ['$8binary_subscr.2', '$const6.1', 'x']
    $const20.4 = const(int, -1)              ['$const20.4']
    $22binary_subscr.5 = getitem(value=x, index=$const20.4, fn=<built-in function getitem>) ['$22binary_subscr.5', '$const20.4', 'x']
    $32compare_op.6 = $8binary_subscr.2 < $22binary_subscr.5 ['$22binary_subscr.5', '$32compare_op.6', '$8binary_subscr.2']
    $const40.8 = const(int, 0)               ['$const40.8']
    $42binary_subscr.9 = getitem(value=x, index=$const40.8, fn=<built-in function getitem>) ['$42binary_subscr.9', '$const40.8', 'x']
    $const54.11 = const(int, 1)              ['$const54.11']
    $56binary_subscr.12 = getitem(value=x, index=$const54.11, fn=<built-in function getitem>) ['$56binary_subscr.12', '$const54.11', 'x']
    $66compare_op.13 = $42binary_subscr.9 <= $56binary_subscr.12 ['$42binary_subscr.9', '$56binary_subscr.12', '$66compare_op.13']
    $binop_and_72.14 = $32compare_op.6 & $66compare_op.13 ['$32compare_op.6', '$66compare_op.13', '$binop_and_72.14']
    $76return_value.15 = cast(value=$binop_and_72.14) ['$76return_value.15', '$binop_and_72.14']
    return $76return_value.15                ['$76return_value.15']

2024-01-20 13:34:46,784 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_combined_b287f3943e744e199901d5df1a15d805.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 13:34:46,815 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 13:34:46,906 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020AC49D0510>
2024-01-20 13:34:46,906 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020AFFBC45F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 13:34:46,926 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020AC4A72B10>
2024-01-20 13:34:46,927 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 13:34:46,927 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 13:34:46,927 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 13:34:47,038 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 13:34:47,038 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 13:34:48,316 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 12:34:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'444'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b75d6b39b44cdeaf4d0b4bc46d0f690b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=WMgw.LTf6UMCt8PH5x6qeNV2t6F7J25qbWS.1uKDhWQ-1705754087-1-AUDsuq7sTTALcaZPkO+FwA9yXKn4jqRyzsQ35Vv+Q9xt4fix3a9+/0AKMWFycOLJ6vkWhaQv0WwFO7BuanzQWX0=; path=/; expires=Sat, 20-Jan-24 13:04:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=o.jh_NuVIMQKMjoDITpFbYpul.lvOfgAEQYzzULemgU-1705754087017-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84875a7b4b943a3e-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 13:34:48,317 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 13:34:48,318 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 13:34:48,318 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 13:34:48,318 DEBUG httpcore.http11 response_closed.started
2024-01-20 13:34:48,318 DEBUG httpcore.http11 response_closed.complete
2024-01-20 13:34:48,319 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 13:35:00,888 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_b5e98fbe-cad8-4391-a356-f99febf07020.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 13:35:00,890 DEBUG httpcore.connection close.started
2024-01-20 13:35:00,891 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_33ee436f-1b5b-4e8a-835e-fc34293beaae.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 13:35:00,891 DEBUG httpcore.connection close.complete
2024-01-20 13:35:00,892 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 13:35:00,893 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 13:35:01,922 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020AC4A863D0>
2024-01-20 13:35:01,922 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020AC4A9FE50>
2024-01-20 13:35:01,922 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020AFFBC45F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 13:35:01,922 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020AFFBC45F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 13:35:01,943 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020AC9530F90>
2024-01-20 13:35:01,943 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 13:35:01,944 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 13:35:01,944 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 13:35:01,952 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020AC4A9F850>
2024-01-20 13:35:01,952 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 13:35:01,952 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 13:35:01,952 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 13:35:04,499 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 13:35:04,499 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 13:35:16,156 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 12:35:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'9988'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'efc2d937b2572347def193a10205a655'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84875ad91b4139ec-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 13:35:16,156 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 13:35:16,157 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 13:35:16,157 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 13:35:16,157 DEBUG httpcore.http11 response_closed.started
2024-01-20 13:35:16,157 DEBUG httpcore.http11 response_closed.complete
2024-01-20 13:35:16,157 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 13:35:27,457 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 13:35:27,457 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 13:35:30,293 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 12:35:28 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'586'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'be973981028fab1149d85905a4aec2de'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84875ad92e742c33-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 13:35:30,293 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 13:35:30,294 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 13:35:30,294 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 13:35:30,294 DEBUG httpcore.http11 response_closed.started
2024-01-20 13:35:30,294 DEBUG httpcore.http11 response_closed.complete
2024-01-20 13:35:30,294 DEBUG httpcore.connection close.started
2024-01-20 13:35:30,294 DEBUG httpcore.connection close.complete
2024-01-20 13:35:30,294 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 13:35:30,294 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 13:35:30,296 DEBUG openai._base_client Not retrying
2024-01-20 13:35:30,296 DEBUG openai._base_client Re-raising status error
2024-01-20 13:35:30,296 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 13:40:06,577 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 13:40:06,578 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 13:40:06,824 INFO transcription All nescessary class variables are declared and working!
2024-01-20 13:40:11,410 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_48e86462-e406-460f-bd74-cc1584578f8e.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 13:40:11,413 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_26101366-bbfd-47b2-9f1f-32137c88929c.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 13:40:11,455 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 13:40:11,456 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 13:40:11,540 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021A7F5FCA50>
2024-01-20 13:40:11,540 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021A7EA145F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 13:40:11,558 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021A2057B810>
2024-01-20 13:40:11,558 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021A7EA145F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 13:40:11,559 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021A205809D0>
2024-01-20 13:40:11,560 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 13:40:11,560 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 13:40:11,560 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 13:40:11,578 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021A20583810>
2024-01-20 13:40:11,579 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 13:40:11,579 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 13:40:11,579 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 13:40:13,026 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 13:40:13,026 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 13:40:23,568 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 12:40:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'9161'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'664c317ced49b7840d4248a464a1076e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=TDNhV1YFA3AO6g_QynHvxLrUnAa80z3NQ9V.6VU.azE-1705754422-1-AVF7ElGP17fNeEzTWGH0ovVmapCYDDVnCcHlTEPUZVBZNuXR2CG/+SpKZSzeXYzfyMkz7mluPBAuZdaJQBxq83c=; path=/; expires=Sat, 20-Jan-24 13:10:22 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=lOHXyFGLKL3AdyYXQ1a0UJj_IriUexAuZ_17Tk4L0c4-1705754422262-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848762683c89995d-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 13:40:23,569 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 13:40:23,570 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 13:40:23,570 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 13:40:23,570 DEBUG httpcore.http11 response_closed.started
2024-01-20 13:40:23,570 DEBUG httpcore.http11 response_closed.complete
2024-01-20 13:40:23,570 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 13:40:36,893 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 13:40:36,893 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 13:40:39,606 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 12:40:38 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'564'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5af96da34d237ad7acfbbcb228e0d397'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=6ChhMmR_IjMnVeymIGexWXJ9IRpLdtRhqp6Xjt0g1uI-1705754438-1-AUZ59H49LCLFMfAVqw3wCR0M6q6AhWCmdfPInF4tx7c9O/WVgmAMDHNDl7Mo5YUROjHIgi7cPJiHSAhhXgyHbQA=; path=/; expires=Sat, 20-Jan-24 13:10:38 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=DeG43eiqnPkYrxUxY1n9UAbZCyJlxjvTlskMrFHI8FU-1705754438301-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848762685f116997-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 13:40:39,607 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 13:40:39,607 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 13:40:39,607 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 13:40:39,608 DEBUG httpcore.http11 response_closed.started
2024-01-20 13:40:39,608 DEBUG httpcore.http11 response_closed.complete
2024-01-20 13:40:39,608 DEBUG httpcore.connection close.started
2024-01-20 13:40:39,608 DEBUG httpcore.connection close.complete
2024-01-20 13:40:39,608 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 13:40:39,608 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 13:40:39,610 DEBUG openai._base_client Not retrying
2024-01-20 13:40:39,610 DEBUG openai._base_client Re-raising status error
2024-01-20 13:40:39,610 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 13:49:43,002 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 13:49:43,004 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 13:49:43,238 INFO transcription All nescessary class variables are declared and working!
2024-01-20 13:49:48,491 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_473c6fcb-6f0b-4a6d-a308-61036f67e006.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 13:49:48,494 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_f4f8b9bf-dabc-4de9-8851-75c4eb77399b.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 13:49:48,533 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 13:49:48,534 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 13:49:48,619 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000299C18AD150>
2024-01-20 13:49:48,619 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000299BA3345F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 13:49:48,633 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000299C18AB750>
2024-01-20 13:49:48,633 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000299BA3345F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 13:49:48,641 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000299C18ACAD0>
2024-01-20 13:49:48,642 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 13:49:48,642 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 13:49:48,642 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 13:49:48,647 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000299C18ACF10>
2024-01-20 13:49:48,647 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 13:49:48,647 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 13:49:48,648 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 13:49:50,049 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 13:49:50,049 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 13:50:00,716 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 12:49:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'9123'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'7aec97042fefb5216a168039c10b7893'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=LUJxHplO3p7i8keewFvPL1b9_u1mwUU.166h5O_JkbI-1705754999-1-ASnSaLjtHE7CRMiJInEDrIb27t3YEZ2fQQUOf7E3Np3TVVN32Qe1JLEZKqoG23jvJkXcdHAAYefCc5xghSVuCQE=; path=/; expires=Sat, 20-Jan-24 13:19:59 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=N__JsX5jq9wmllMqYbQWy.MqVAa2Avvrr5iOXmXuLJ0-1705754999399-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487707edbbf65d7-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 13:50:00,717 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 13:50:00,718 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 13:50:00,718 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 13:50:00,718 DEBUG httpcore.http11 response_closed.started
2024-01-20 13:50:00,718 DEBUG httpcore.http11 response_closed.complete
2024-01-20 13:50:00,718 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 13:50:12,963 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 13:50:12,963 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 13:50:16,742 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 12:50:15 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'681'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5d1d4886d8649b070546f52f73756d82'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=4CkqiqW49vmKodvZCxCuIjftzc0zNSvjP6G17TrWmrk-1705755015-1-AfbQ5gtLBBBX+lsWegPhWL6bM6l+1QG49ppX8wdrG8r3K3FACYaEXSZYsGi6ttEY9DtLFJb+4Ehy3ctoP25eelU=; path=/; expires=Sat, 20-Jan-24 13:20:15 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=SRtWM8aTaRNQNWbpA0puwP.fwHodoWnGFdICGmvh4NQ-1705755015425-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487707efd3a4d28-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 13:50:16,742 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 13:50:16,742 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 13:50:16,743 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 13:50:16,743 DEBUG httpcore.http11 response_closed.started
2024-01-20 13:50:16,743 DEBUG httpcore.http11 response_closed.complete
2024-01-20 13:50:16,743 DEBUG httpcore.connection close.started
2024-01-20 13:50:16,743 DEBUG httpcore.connection close.complete
2024-01-20 13:50:16,743 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 13:50:16,743 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 13:50:16,745 DEBUG openai._base_client Not retrying
2024-01-20 13:50:16,745 DEBUG openai._base_client Re-raising status error
2024-01-20 13:50:16,745 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 13:50:16,758 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 13:50:16,764 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 13:50:16,765 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 13:50:16,766 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 13:50:16,766 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 13:50:16,766 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 13:50:16,766 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 13:50:16,766 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 13:50:16,803 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000299BAB63D90>
2024-01-20 13:50:16,803 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000299BA3345F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 13:50:16,817 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000299C192AAD0>
2024-01-20 13:50:16,818 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 13:50:16,818 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 13:50:16,818 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 13:50:16,818 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 13:50:16,818 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 13:50:26,732 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 12:50:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'9684'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9124'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'5.256s'), (b'x-request-id', b'0cf1930325aa8054286ab67c176d70c2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487712eae884d28-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 13:50:26,732 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 13:50:26,732 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 13:50:26,733 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 13:50:26,733 DEBUG httpcore.http11 response_closed.started
2024-01-20 13:50:26,733 DEBUG httpcore.http11 response_closed.complete
2024-01-20 13:50:26,733 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 13:50:36,289 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 12:50:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'19193'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'8285'), (b'x-ratelimit-reset-requests', b'17.23s'), (b'x-ratelimit-reset-tokens', b'10.288s'), (b'x-request-id', b'3b147bfe450a0519456f9c78ae6357ef'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487712ef9309048-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 13:50:36,290 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 13:50:36,290 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 13:50:36,290 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 13:50:36,290 DEBUG httpcore.http11 response_closed.started
2024-01-20 13:50:36,290 DEBUG httpcore.http11 response_closed.complete
2024-01-20 13:50:36,291 DEBUG httpcore.connection close.started
2024-01-20 13:50:36,291 DEBUG httpcore.connection close.complete
2024-01-20 13:50:36,291 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 13:51:34,458 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_3f5db7ed-95aa-42da-a496-88b8179b86c0.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 13:51:34,460 DEBUG httpcore.connection close.started
2024-01-20 13:51:34,460 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_26b52dcf-bf5b-4fb0-b8f2-49282ff8921d.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 13:51:34,461 DEBUG httpcore.connection close.complete
2024-01-20 13:51:34,462 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 13:51:34,462 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 13:51:34,532 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000299BAEEB2D0>
2024-01-20 13:51:34,532 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000299BA3345F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 13:51:34,533 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000299BAEE9ED0>
2024-01-20 13:51:34,533 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000299BA3345F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 13:51:34,555 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000299BAEEAF50>
2024-01-20 13:51:34,556 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 13:51:34,556 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 13:51:34,556 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 13:51:34,556 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000299C192D250>
2024-01-20 13:51:34,556 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 13:51:34,556 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 13:51:34,557 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 13:51:37,227 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 13:51:37,227 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 13:51:44,377 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\DATA\\test\\test.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 13:51:44,378 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 13:51:44,458 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000299BAF01450>
2024-01-20 13:51:44,458 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000299BA3345F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 13:51:44,478 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000299C192B490>
2024-01-20 13:51:44,478 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 13:51:44,478 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 13:51:44,478 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 13:51:44,686 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 13:51:44,686 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 13:51:45,885 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 12:51:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'470'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'10dae92abd54d2a3df58f877e28fdc8f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84877352dddb5c98-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 13:51:45,886 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 13:51:45,886 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 13:51:45,886 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 13:51:45,886 DEBUG httpcore.http11 response_closed.started
2024-01-20 13:51:45,886 DEBUG httpcore.http11 response_closed.complete
2024-01-20 13:51:45,886 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 13:51:45,897 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \nVersuchen wir es einfach nochmal. Test, Test, Test, Test, Test. Juckt ja jetzt kein, ähm, joa.'}], 'model': 'gpt-4'}}
2024-01-20 13:51:45,898 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 13:51:45,903 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \nVersuchen wir es einfach nochmal. Test, Test, Test, Test, Test. Juckt ja jetzt kein, ähm, joa.'}], 'model': 'gpt-4'}}
2024-01-20 13:51:45,903 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 13:51:45,904 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 13:51:45,904 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 13:51:45,905 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 13:51:45,905 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 13:51:45,925 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000299C1951F10>
2024-01-20 13:51:45,925 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000299BA3345F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 13:51:45,943 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000299C192B010>
2024-01-20 13:51:45,944 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 13:51:45,944 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 13:51:45,944 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 13:51:45,944 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 13:51:45,944 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 13:51:46,926 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 12:51:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'8781'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'67d8aa16c3ed9ff0da57ef96170aaf47'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84877314d96c5be1-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 13:51:46,927 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 13:51:46,927 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 13:51:46,928 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 13:51:46,928 DEBUG httpcore.http11 response_closed.started
2024-01-20 13:51:46,928 DEBUG httpcore.http11 response_closed.complete
2024-01-20 13:51:46,928 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 13:51:48,958 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 12:51:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'2864'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9856'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'864ms'), (b'x-request-id', b'701794c3e6f74794fc9dd24807680b12'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487735bbf895c98-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 13:51:48,958 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 13:51:48,958 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 13:51:48,959 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 13:51:48,959 DEBUG httpcore.http11 response_closed.started
2024-01-20 13:51:48,959 DEBUG httpcore.http11 response_closed.complete
2024-01-20 13:51:48,959 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 13:51:53,119 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 12:51:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'6988'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'9747'), (b'x-ratelimit-reset-requests', b'17.246s'), (b'x-ratelimit-reset-tokens', b'1.514s'), (b'x-request-id', b'53746dc7eaa1c2ead2ba7a3f48c4cacc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487735bf8496915-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 13:51:53,120 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 13:51:53,120 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 13:51:53,120 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 13:51:53,120 DEBUG httpcore.http11 response_closed.started
2024-01-20 13:51:53,121 DEBUG httpcore.http11 response_closed.complete
2024-01-20 13:51:53,121 DEBUG httpcore.connection close.started
2024-01-20 13:51:53,121 DEBUG httpcore.connection close.complete
2024-01-20 13:51:53,121 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 13:51:58,914 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 13:51:58,914 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 13:52:01,522 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 12:52:00 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'608'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'94762114aca6a87714859d600533aaec'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84877314db461965-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 13:52:01,522 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 13:52:01,522 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 13:52:01,522 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 13:52:01,523 DEBUG httpcore.http11 response_closed.started
2024-01-20 13:52:01,523 DEBUG httpcore.http11 response_closed.complete
2024-01-20 13:52:01,523 DEBUG httpcore.connection close.started
2024-01-20 13:52:01,523 DEBUG httpcore.connection close.complete
2024-01-20 13:52:01,523 DEBUG httpcore.connection close.started
2024-01-20 13:52:01,523 DEBUG httpcore.connection close.complete
2024-01-20 13:52:01,523 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 13:52:01,523 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 13:52:01,524 DEBUG openai._base_client Not retrying
2024-01-20 13:52:01,524 DEBUG openai._base_client Re-raising status error
2024-01-20 13:52:01,524 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 13:52:01,536 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 13:52:01,537 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 13:52:01,538 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 13:52:01,542 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 13:52:01,543 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 13:52:01,544 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 13:52:01,544 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 13:52:01,544 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 13:52:01,565 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000299C1963C90>
2024-01-20 13:52:01,566 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000299BA3345F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 13:52:01,588 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000299C1962AD0>
2024-01-20 13:52:01,589 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 13:52:01,589 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 13:52:01,589 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 13:52:01,589 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 13:52:01,589 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 13:52:12,424 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 12:52:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'10678'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'9124'), (b'x-ratelimit-reset-requests', b'10.272s'), (b'x-ratelimit-reset-tokens', b'5.256s'), (b'x-request-id', b'53a23014a7e5e43492b1dcf46c7d8408'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848773bd8fe41965-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 13:52:12,424 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 13:52:12,424 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 13:52:12,426 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 13:52:12,426 DEBUG httpcore.http11 response_closed.started
2024-01-20 13:52:12,426 DEBUG httpcore.http11 response_closed.complete
2024-01-20 13:52:12,426 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 13:52:20,947 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 12:52:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'19157'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'8282'), (b'x-ratelimit-reset-requests', b'18.879s'), (b'x-ratelimit-reset-tokens', b'10.304s'), (b'x-request-id', b'1b85888f0bdd99d8d553733f5899091a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848773bdcb1e4da8-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 13:52:20,948 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 13:52:20,948 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 13:52:20,948 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 13:52:20,948 DEBUG httpcore.http11 response_closed.started
2024-01-20 13:52:20,948 DEBUG httpcore.http11 response_closed.complete
2024-01-20 13:52:20,948 DEBUG httpcore.connection close.started
2024-01-20 13:52:20,949 DEBUG httpcore.connection close.complete
2024-01-20 13:52:20,949 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 14:14:29,278 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 14:14:29,279 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 14:14:29,520 INFO transcription All nescessary class variables are declared and working!
2024-01-20 14:14:46,165 DEBUG pydub.converter subprocess.call(['ffmpeg', '-y', '-f', 'mp3', '-i', 'C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\DATA\\videoplayback (1)\\videoplayback (1).mp3', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
2024-01-20 14:14:51,401 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_c8b6238c-26be-48f1-ab38-bbf1e2106713.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:14:51,404 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_006531c7-57f0-4ba6-9e74-72a5716481d2.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:14:51,406 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_96bdc177-315b-4509-afd0-8dd404b8bdc9.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:14:51,408 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_876f6252-43b1-4792-a1d1-dbd1e15dbe6a.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:14:51,410 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_9a867a7e-e69b-45e6-ac90-da9f72ab422a.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:14:51,413 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_dcf440b7-8c3a-4db0-9779-7a4d90d50018.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:14:51,415 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_b37882d3-3e8f-489e-8e89-e50b44e78402.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:14:51,417 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_8f971cda-f6a9-41f5-baa4-34d511a12d6b.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:14:51,419 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_7169f2b6-733e-4b7a-a2d7-41a7fada74e8.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:14:51,422 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_9016ac1e-3ae1-4591-986b-64a2a31aef90.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:14:51,424 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_c5901cdc-9bed-4461-b2d5-b0f519f62262.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:14:51,427 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_fc82c113-50ba-46ea-b7a2-9d5dfa298569.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:14:51,429 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_5944f2b2-e9c0-4b27-8d9f-9c7e58005fe2.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:14:51,662 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:14:51,665 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:14:51,666 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:14:51,668 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:14:51,677 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:14:51,678 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:14:51,679 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:14:51,679 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:14:51,682 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:14:51,685 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:14:51,685 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:14:51,686 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:14:51,687 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:14:51,755 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F64506810>
2024-01-20 14:14:51,755 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F64506510>
2024-01-20 14:14:51,755 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F64505E90>
2024-01-20 14:14:51,755 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F64506490>
2024-01-20 14:14:51,755 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000013F5FAA9A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:14:51,755 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000013F5FAA9A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:14:51,755 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000013F5FAA9A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:14:51,755 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000013F5FAA9A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:14:51,759 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F645063D0>
2024-01-20 14:14:51,759 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F64453090>
2024-01-20 14:14:51,759 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000013F5FAA9A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:14:51,759 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F645075D0>
2024-01-20 14:14:51,759 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000013F5FAA9A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:14:51,759 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000013F5FAA9A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:14:51,761 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F64507950>
2024-01-20 14:14:51,761 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F64451C50>
2024-01-20 14:14:51,761 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000013F5FAA9A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:14:51,761 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F64505ED0>
2024-01-20 14:14:51,761 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000013F5FAA9A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:14:51,761 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000013F5FAA9A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:14:51,763 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F64506590>
2024-01-20 14:14:51,763 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000013F5FAA9A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:14:51,777 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F00121390>
2024-01-20 14:14:51,777 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F645079D0>
2024-01-20 14:14:51,777 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:14:51,777 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:14:51,777 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F64506A90>
2024-01-20 14:14:51,778 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F64506210>
2024-01-20 14:14:51,778 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F606BEF90>
2024-01-20 14:14:51,778 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F64506050>
2024-01-20 14:14:51,778 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:14:51,778 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:14:51,778 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:14:51,778 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:14:51,778 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000013F5FAA9A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:14:51,779 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000013F5FAA9A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:14:51,779 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:14:51,779 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:14:51,779 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:14:51,779 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:14:51,780 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:14:51,780 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:14:51,781 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F00122750>
2024-01-20 14:14:51,781 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:14:51,782 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F00123390>
2024-01-20 14:14:51,782 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:14:51,782 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F00123DD0>
2024-01-20 14:14:51,782 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F001238D0>
2024-01-20 14:14:51,782 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F00123310>
2024-01-20 14:14:51,783 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:14:51,783 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:14:51,783 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:14:51,783 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F00123250>
2024-01-20 14:14:51,783 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:14:51,783 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:14:51,783 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F64507710>
2024-01-20 14:14:51,783 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:14:51,783 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:14:51,784 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:14:51,784 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:14:51,784 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:14:51,784 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:14:51,784 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:14:51,785 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:14:51,785 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:14:51,785 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:14:51,786 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:14:51,786 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:14:51,786 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:14:51,787 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:14:51,796 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F0013B290>
2024-01-20 14:14:51,796 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:14:51,797 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:14:51,797 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:14:51,799 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013F0013B990>
2024-01-20 14:14:51,799 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:14:51,799 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:14:51,799 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:14:58,495 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:14:58,495 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:14:59,915 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sat, 20 Jan 2024 13:14:58 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'179'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'191'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ef51de012d7be57a38c2d041ef7331bd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=_vKqOeKqmo1WPgctf_v3JGux7hhWN_owSYzgwrCNnyE-1705756498-1-AXec1Ilq6m499riPOzWZFPuxUUo0XYAF34jGO2+M6OnIhMWWrCNoDb/Fe4VQmaWxGaGMfe5jYrQCrIaICtHUOSY=; path=/; expires=Sat, 20-Jan-24 13:44:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=q2akR6aUhytG6r194kQIXKqsiwlfVmB0gT2WecxWJZ8-1705756498570-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848795314df0bbdf-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:14:59,917 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 400 Bad Request"
2024-01-20 14:14:59,917 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:14:59,917 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:14:59,917 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:14:59,917 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:14:59,918 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "400 Bad Request"
2024-01-20 14:14:59,918 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2024-01-20 14:14:59,919 DEBUG openai._base_client Not retrying
2024-01-20 14:14:59,919 DEBUG openai._base_client Re-raising status error
2024-01-20 14:14:59,920 ERROR transcription Error transcribing file part 12: Error code: 400 - {'error': {'message': 'The audio file could not be decoded or its format is not supported.', 'type': 'invalid_request_error', 'param': None, 'code': None}}
2024-01-20 14:16:17,627 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:16:17,627 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:16:17,655 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:16:17,655 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:16:17,866 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:16:17,866 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:16:17,915 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:16:17,915 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:16:18,451 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:16:18,451 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:16:18,584 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:16:18,584 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:16:18,813 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:16:18,813 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:16:18,838 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:16:18,838 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:16:19,025 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:16:19,025 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:16:19,440 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:16:19,440 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:16:19,580 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:16:19,580 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:16:20,134 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:16:20,135 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:16:20,872 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:16:19 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'632'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'47'), (b'x-ratelimit-reset-requests', b'3.576s'), (b'x-request-id', b'9867f95d542597c3420907a9e28956ab'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=1D7k6_eejB8CkRoFuB5gC_sEfG_PmSp.HG9xN.lAeUU-1705756579-1-AYvi6iUrPAm/VdcnL6fhWNOG+ZU3y20Z7DQAeAw7WcG0hRhQqHK3XoOlOK2NOChbqHTY3Y7kDDfKjUFlE/QUNq4=; path=/; expires=Sat, 20-Jan-24 13:46:19 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=yVies56khGLfXFn9oHpQUZvzaikuCkeFKPemIF09ErU-1705756579526-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848795315f269112-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:16:20,872 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:16:20,873 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:16:20,873 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:16:20,873 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:16:20,873 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:16:20,873 DEBUG httpcore.connection close.started
2024-01-20 14:16:20,873 DEBUG httpcore.connection close.complete
2024-01-20 14:16:20,873 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:16:20,873 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:16:20,874 DEBUG openai._base_client Not retrying
2024-01-20 14:16:20,874 DEBUG openai._base_client Re-raising status error
2024-01-20 14:16:20,874 ERROR transcription Error transcribing file part 10: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:16:21,272 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:16:19 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'620'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'26458ee2f3d9b541e2d48ee7375b8b5c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=UD398n2VtdwtKNWrb5Am72qogPF5DVrxvi6_1h8WpGY-1705756579-1-ARQ87QL9oM0SwU0OUOSqbQmnjRvHky4u1jhjUxGmBZTjsbkaE4z6x3QkGcQg7yzw1GvUrl1n2+QRbiE8qA9KPwI=; path=/; expires=Sat, 20-Jan-24 13:46:19 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=fNp8BuVGj7kDDxEsvBcJNwiGpLUzgXle6iTSSaiMVCY-1705756579926-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848795316ada3657-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:16:21,273 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:16:21,273 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:16:21,273 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:16:21,273 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:16:21,274 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:16:21,274 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:16:21,274 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:16:21,274 DEBUG openai._base_client Not retrying
2024-01-20 14:16:21,275 DEBUG openai._base_client Re-raising status error
2024-01-20 14:16:21,275 ERROR transcription Error transcribing file part 6: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:16:21,586 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:16:20 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'646'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'48'), (b'x-ratelimit-reset-requests', b'2.39s'), (b'x-request-id', b'7d0b8850ef8f5ebc2aa064acbbe73ab0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=zuyYFo2_P8J3d5mz.zbF6_XIdDhFh9A7W.4LfrmZZeo-1705756580-1-AZPzOeP1PjycGFL4t4KQvfO+OI5eDjKNarE14S0jvzeE+RoooOahfDg4NTjsWnnXzFwjON8uCmyrOgCgju+/wzQ=; path=/; expires=Sat, 20-Jan-24 13:46:20 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=KdJv24uuFCjddzWK8s_Ej7CT4JddlFp6ANMH6C550yc-1705756580239-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848795318f7a3605-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:16:21,587 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:16:21,587 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:16:21,587 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:16:21,588 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:16:21,588 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:16:21,588 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:16:21,588 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:16:21,588 DEBUG openai._base_client Not retrying
2024-01-20 14:16:21,589 DEBUG openai._base_client Re-raising status error
2024-01-20 14:16:21,589 ERROR transcription Error transcribing file part 7: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:16:21,610 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:16:20 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'615'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'45'), (b'x-ratelimit-reset-requests', b'5.667s'), (b'x-request-id', b'9124859ef77cf979e60c911e7712fb03'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=c5t9Gs_6G9hsXy66e8dMXLHd3D2ZYz_hIVFN.w2nM5I-1705756580-1-AXVKA9QtTiSKGT2JPgi4bMqsVIxNfelem439niZT5S8z/wRy2/mX2/bvL8e3ZEPMUP6tAXdyXSb3BSGvSJOKv44=; path=/; expires=Sat, 20-Jan-24 13:46:20 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=oo6t1H0cv90c7s4vwKIavwZ_QP7uusFbCpMIBSEImOs-1705756580264-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848795314cc74d50-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:16:21,611 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:16:21,611 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:16:21,611 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:16:21,611 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:16:21,612 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:16:21,612 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:16:21,612 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:16:21,612 DEBUG openai._base_client Not retrying
2024-01-20 14:16:21,612 DEBUG openai._base_client Re-raising status error
2024-01-20 14:16:21,613 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:16:21,734 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:16:20 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'799'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'46'), (b'x-ratelimit-reset-requests', b'4.664s'), (b'x-request-id', b'ae237231b85906874441b5115154df91'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=LnQK5mUzifId6iM1RPETuZeN4GyoEPH37olW7uI.tD4-1705756580-1-AQwbE5A2/004TRK+xqMCAmGhk6yb8uldGTWrS92Q7ONhJtUGp+PPS7oGJl6/DmuPdxs7BD8UM1q9SPcbI/9Mdjk=; path=/; expires=Sat, 20-Jan-24 13:46:20 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=5FiZHU_qU5EO.q6.53U1uUkMdQqyVXynqApCplfigk0-1705756580388-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487953158122c5e-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:16:21,734 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:16:21,735 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:16:21,735 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:16:21,735 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:16:21,735 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:16:21,735 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:16:21,735 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:16:21,736 DEBUG openai._base_client Not retrying
2024-01-20 14:16:21,736 DEBUG openai._base_client Re-raising status error
2024-01-20 14:16:21,736 ERROR transcription Error transcribing file part 5: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:16:22,025 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:16:20 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'684'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'43'), (b'x-ratelimit-reset-requests', b'7.873s'), (b'x-request-id', b'e94df21f6e0076d3c0c66ddd5aaa75a3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=4J1zhLjiZfRbPuoMh7Ez6gTXGPsvLIKD59QOHZ_gzAQ-1705756580-1-Ae94/TF2Iz6cB6XOKCXRP9CmS4inLDfIGRD3xx384LS5pbc7YwdlT2S/acYmlMzu/7ZTT1eRNeLC8/KtyIflvfs=; path=/; expires=Sat, 20-Jan-24 13:46:20 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=jI6R7sUcc7UOY3HdhCLT8.eFYWId.5ZtXNELho7bFo0-1705756580678-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848795315aef2c33-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:16:22,026 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:16:22,026 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:16:22,027 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:16:22,027 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:16:22,027 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:16:22,027 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:16:22,027 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:16:22,028 DEBUG openai._base_client Not retrying
2024-01-20 14:16:22,028 DEBUG openai._base_client Re-raising status error
2024-01-20 14:16:22,028 ERROR transcription Error transcribing file part 8: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:16:22,035 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:16:20 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'697'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'44'), (b'x-ratelimit-reset-requests', b'6.692s'), (b'x-request-id', b'f1ce55503c5345e7c7acda4da44c8b0d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=LsjSMexgKB9Es3zYEPJw_6VKDfa.rjYCC5c.CWURpdQ-1705756580-1-AagO8LG1SbMDIOgBhceXSCepq/0J1KkqVUAmg1xxC3TwFAn4e1wU8ow4Tp9OV1aaSylPrVa6pLMHGRkGVZFRv+0=; path=/; expires=Sat, 20-Jan-24 13:46:20 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=QctuOIiqrR3E0HdCt1EkaDuxpf9UBYaG1HcJv_xkS3s-1705756580688-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848795316d039bfb-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:16:22,036 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:16:22,036 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:16:22,036 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:16:22,036 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:16:22,036 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:16:22,036 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:16:22,036 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:16:22,037 DEBUG openai._base_client Not retrying
2024-01-20 14:16:22,037 DEBUG openai._base_client Re-raising status error
2024-01-20 14:16:22,037 ERROR transcription Error transcribing file part 3: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:16:22,297 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:16:20 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'699'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'42'), (b'x-ratelimit-reset-requests', b'8.809s'), (b'x-request-id', b'a11b60a7579cc389faba1eb2f43a119f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=s3P9Fx3bPHbXQjqEcGe3ziTvhbVJZq9jeINHlCFpYrs-1705756580-1-AXwtUwxLKZZXR7WIDClbllbPn879NbbSF5sm6bszxDx+KFa+CtVx+tJyOcRUhChgxiLrf9vnqwhy5+klESAbXPM=; path=/; expires=Sat, 20-Jan-24 13:46:20 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=H79mq0mxAeHJ_tTQfbhmK.j2qvz2JsAmpv5WdsYS7Vo-1705756580951-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848795315e9e4d9d-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:16:22,298 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:16:22,298 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:16:22,298 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:16:22,298 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:16:22,298 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:16:22,298 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:16:22,299 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:16:22,299 DEBUG openai._base_client Not retrying
2024-01-20 14:16:22,299 DEBUG openai._base_client Re-raising status error
2024-01-20 14:16:22,300 ERROR transcription Error transcribing file part 4: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:16:22,450 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:16:21 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'578'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'41'), (b'x-ratelimit-reset-requests', b'9.603s'), (b'x-request-id', b'9c9b7c4d160ac0a86ee63faad2147df2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=C9lyvxgOVOYcZncGglGDuzQZmdQZfyoXF8.f8rwpNiY-1705756581-1-AVHMqiu4+tp9gsdMxr/ihkFdYKZZ2xubMdiyrwGSb7wJtwLe/MYn3Td91BMfqDOw8Yp8Er5Nq/cMM4bZaERPDsU=; path=/; expires=Sat, 20-Jan-24 13:46:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=iWmSGUIXrkXAIXPcjwgG8TKx5K1sLsDAnZw1eHGnUm0-1705756581104-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848795316e1b03f4-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:16:22,451 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:16:22,451 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:16:22,451 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:16:22,451 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:16:22,451 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:16:22,452 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:16:22,452 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:16:22,452 DEBUG openai._base_client Not retrying
2024-01-20 14:16:22,452 DEBUG openai._base_client Re-raising status error
2024-01-20 14:16:22,453 ERROR transcription Error transcribing file part 11: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:16:22,530 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:16:21 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'700'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'40'), (b'x-ratelimit-reset-requests', b'11.618s'), (b'x-request-id', b'261c000e082462133aaec71ff32978ff'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=H7c_66HYT3zDWyGNjINkMfNW.1bDPmcJ00biJcxu3ww-1705756581-1-Ac9RqiTq6VaQpuoTGB9uOyFcJB8Vm9BYT0s8Agi85i2MTGd15CqvvXvcCYOg0DrZJIeI/qIO+sC7zq47VBmUzAA=; path=/; expires=Sat, 20-Jan-24 13:46:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=ktfy5AdF.VLkwTx3hd8eSoOeVXWXFytkJj0GI6T1rV0-1705756581183-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84879531685a6aba-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:16:22,531 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:16:22,531 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:16:22,532 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:16:22,532 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:16:22,532 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:16:22,532 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:16:22,532 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:16:22,533 DEBUG openai._base_client Not retrying
2024-01-20 14:16:22,533 DEBUG openai._base_client Re-raising status error
2024-01-20 14:16:22,533 ERROR transcription Error transcribing file part 9: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:16:23,153 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:16:21 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'806'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'41'), (b'x-ratelimit-reset-requests', b'10.585s'), (b'x-request-id', b'fde04b360cc96ad1682d01180383e27e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=SdxF4XYuA0N4FvJSg8vCGJJdN0adyipYdqf1ZbMgdh0-1705756581-1-AUSGZZjNY1didX556GHI1NntwHCHj4WrGrWZ/0OTuyrX21HpRHbW3LLKy+XqpzT11/Vn5Boj0t7+6hrWiDNSZ0Y=; path=/; expires=Sat, 20-Jan-24 13:46:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=IXNRpufIXpTrukz9Zc7TKXbiGNvpeP.4YYbFtQgoJrU-1705756581806-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84879531886790d6-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:16:23,154 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:16:23,154 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:16:23,154 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:16:23,154 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:16:23,154 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:16:23,154 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:16:23,154 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:16:23,155 DEBUG openai._base_client Not retrying
2024-01-20 14:16:23,155 DEBUG openai._base_client Re-raising status error
2024-01-20 14:16:23,155 ERROR transcription Error transcribing file part 2: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:16:23,288 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:16:21 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'671'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'40'), (b'x-ratelimit-reset-requests', b'11.991s'), (b'x-request-id', b'd8867152faf7877bd6f5b6b6c32d93c6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=u1IsSH8mYyJlDM2lyYDp7HKD0DIKKhCykUIcACdGCuo-1705756581-1-AWtnw3Q22R8eMmjiRrFI6NelOADjJ6RRyBWlX9JU1Pa+Ls7RQC5SSvxXun02gUh7Zh4P6XtypLOk+vwzJAgKH3U=; path=/; expires=Sat, 20-Jan-24 13:46:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=txD0uZi6WEfgPmltOJZk.p0QjeqyAJFsJXmr4YwUYJk-1705756581942-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84879531ad95900c-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:16:23,288 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:16:23,289 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:16:23,289 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:16:23,289 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:16:23,289 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:16:23,289 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:16:23,289 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:16:23,290 DEBUG openai._base_client Not retrying
2024-01-20 14:16:23,290 DEBUG openai._base_client Re-raising status error
2024-01-20 14:16:23,290 ERROR transcription Error transcribing file part 1: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:16:23,314 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \n'}], 'model': 'gpt-4'}}
2024-01-20 14:16:23,339 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \n'}], 'model': 'gpt-4'}}
2024-01-20 14:16:23,341 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:16:23,342 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:16:23,342 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:16:23,342 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:16:23,342 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:16:23,343 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:16:23,343 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:16:23,343 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:16:23,343 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:16:23,343 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:16:25,711 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 13:16:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'2154'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'9792'), (b'x-ratelimit-reset-requests', b'17.262s'), (b'x-ratelimit-reset-tokens', b'1.242s'), (b'x-request-id', b'b5f52f7b1ee145993bc7091e2f125385'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487976d9d623657-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:16:25,711 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 14:16:25,712 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:16:25,712 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:16:25,712 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:16:25,712 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:16:25,712 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 14:16:26,773 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 13:16:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'3239'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9910'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'540ms'), (b'x-request-id', b'879ad65b6936d986bb083401f8126006'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487976d9cfc6aba-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:16:26,774 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 14:16:26,774 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:16:26,774 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:16:26,774 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:16:26,774 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:16:26,775 DEBUG httpcore.connection close.started
2024-01-20 14:16:26,775 DEBUG httpcore.connection close.complete
2024-01-20 14:16:26,775 DEBUG httpcore.connection close.started
2024-01-20 14:16:26,775 DEBUG httpcore.connection close.complete
2024-01-20 14:16:26,775 DEBUG httpcore.connection close.started
2024-01-20 14:16:26,775 DEBUG httpcore.connection close.complete
2024-01-20 14:16:26,775 DEBUG httpcore.connection close.started
2024-01-20 14:16:26,776 DEBUG httpcore.connection close.complete
2024-01-20 14:16:26,776 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 14:16:59,202 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 14:16:59,204 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 14:16:59,432 INFO transcription All nescessary class variables are declared and working!
2024-01-20 14:17:05,556 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_4d4b61f3-5827-457a-b380-2ebbd195433a.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:17:05,559 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_f7d94dd6-a10d-47e3-9439-642d04048e03.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:17:05,599 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:17:05,599 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:17:05,690 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D1E8A63B50>
2024-01-20 14:17:05,690 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D1E7B95AC0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:17:05,706 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D1E8A27E10>
2024-01-20 14:17:05,706 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D1E7B95AC0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:17:05,715 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D1E8A4FD90>
2024-01-20 14:17:05,715 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:17:05,716 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:17:05,716 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:17:05,724 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D1E8A4C250>
2024-01-20 14:17:05,724 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:17:05,724 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:17:05,725 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:17:06,342 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:17:06,342 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:17:17,007 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 13:17:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'9140'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'52fe500a2cb30378559b53d527bfe7a2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=yTt7KHZ1nQUq.vDRMHfsqXUqatmimv9pTIvuyta2qMY-1705756635-1-AfHfZt0g6QzcBAJP3xzsERsU+VY21Kw8EhOhqnJIuLkuCVxIEwTfFrOL+QkiieWof8iZr82ZNoVRWii4aFMAAvU=; path=/; expires=Sat, 20-Jan-24 13:47:15 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=LAQSRTy8Sw4hdOJnADh6tAfwrzO0QG2ikdNTpQuV2F0-1705756635659-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487987668d9925b-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:17:17,008 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 14:17:17,008 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:17:17,009 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:17:17,009 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:17:17,009 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:17:17,009 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 14:17:27,107 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:17:27,107 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:17:30,792 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:17:29 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'742'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'271240323bf132afc54e6f3ef259d1f9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=fupTmz20ldRg6QuAqm1rRHbnbKILhD97_4MTn1NYYlU-1705756649-1-ASwCyTWnDdgKGrDe2AHnK4SZ9c7P6ntWlO2QZHMGlq+0NE5ELkguRaxWpCy2I2z/xZ6EmjOuW7+P4dG8xt0YCAU=; path=/; expires=Sat, 20-Jan-24 13:47:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=yAqV7hY.Y7z1M.qo_.dHi8hs5tcJ7VMKd_pipmdWAMI-1705756649444-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848798767d9c363b-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:17:30,793 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:17:30,793 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:17:30,793 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:17:30,793 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:17:30,793 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:17:30,793 DEBUG httpcore.connection close.started
2024-01-20 14:17:30,793 DEBUG httpcore.connection close.complete
2024-01-20 14:17:30,794 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:17:30,794 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:17:30,795 DEBUG openai._base_client Not retrying
2024-01-20 14:17:30,795 DEBUG openai._base_client Re-raising status error
2024-01-20 14:17:30,796 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:17:30,808 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 14:17:30,815 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 14:17:30,815 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:17:30,816 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:17:30,816 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:17:30,816 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:17:30,816 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:17:30,816 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:17:30,853 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D1E8ADE050>
2024-01-20 14:17:30,853 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D1E7B95AC0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:17:30,867 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D1E8ADE450>
2024-01-20 14:17:30,867 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:17:30,867 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:17:30,867 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:17:30,867 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:17:30,867 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:17:44,086 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 13:17:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'13076'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9124'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'5.256s'), (b'x-request-id', b'5cba158a6f2306c00801eadb15bb51b1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848799134b42363b-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:17:44,087 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 14:17:44,087 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:17:44,087 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:17:44,087 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:17:44,087 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:17:44,087 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 14:17:46,523 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 13:17:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'15444'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'8288'), (b'x-ratelimit-reset-requests', b'17.21s'), (b'x-ratelimit-reset-tokens', b'10.268s'), (b'x-request-id', b'f31c1f5e34a2f59a904e45924eebd326'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84879913ae128fe9-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:17:46,524 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 14:17:46,524 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:17:46,525 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:17:46,525 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:17:46,525 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:17:46,525 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 14:31:45,777 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 14:31:45,778 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 14:31:46,004 INFO transcription All nescessary class variables are declared and working!
2024-01-20 14:31:52,519 DEBUG pydub.converter subprocess.call(['ffmpeg', '-y', '-f', 'mp3', '-i', 'C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\DATA\\videoplayback (1)\\videoplayback (1).mp3', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
2024-01-20 14:32:00,512 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_db1bd1d4-4531-4010-9f04-243b1c4ebee6.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:32:00,515 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_c02fc165-e98c-499f-9c64-3e7e90a9fbba.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:32:00,517 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_a6487399-06a7-4037-8b2a-2e5a3078b390.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:32:00,519 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_c169943b-964c-4ebf-ad23-113988e7f963.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:32:00,522 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_4c40155f-e983-41ba-9e9d-c128db7e5340.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:32:00,526 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_2798e401-56fb-4659-b994-210a881a36a2.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:32:00,528 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_77a6eff7-46cf-4760-a2d6-1029655daad4.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:32:00,532 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_c07ad408-a9ff-41e7-8f3c-2e0ba7ea44b9.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:32:00,533 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_8a9b2b45-bf07-42da-88e3-bd37c45b9c3f.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:32:00,537 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_bc0fcbae-6f8f-4bce-ac8a-8664cbea85f4.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:32:00,541 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_8a4c8936-1952-4ff7-a74f-0079afd4e64c.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:32:00,544 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_009b8cb3-bbc0-4528-b290-2dcfdf0a2b54.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:32:00,547 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_c9622f9b-fd9a-400a-84f1-89a2b4ed6421.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:32:00,666 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:32:00,698 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:32:00,711 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:32:00,720 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:32:00,721 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:32:00,733 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:32:00,736 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:32:00,748 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:32:00,749 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:32:00,750 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:32:00,758 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA4B6EA50>
2024-01-20 14:32:00,758 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:32:00,758 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027FFFF35AC0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:32:00,761 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:32:00,763 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:32:00,764 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA82AFAD0>
2024-01-20 14:32:00,764 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA82AF650>
2024-01-20 14:32:00,764 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA4EA7AD0>
2024-01-20 14:32:00,764 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027FFFF35AC0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:32:00,764 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027FFFF35AC0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:32:00,764 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027FFFF35AC0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:32:00,766 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA8265C50>
2024-01-20 14:32:00,766 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA4E8BF90>
2024-01-20 14:32:00,766 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027FFFF35AC0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:32:00,766 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA8265F50>
2024-01-20 14:32:00,766 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027FFFF35AC0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:32:00,766 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027FFFF35AC0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:32:00,772 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA4B6EAD0>
2024-01-20 14:32:00,772 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:32:00,773 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:32:00,773 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:32:00,773 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA8264510>
2024-01-20 14:32:00,774 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA4F52450>
2024-01-20 14:32:00,774 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027FFFF35AC0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:32:00,774 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027FFFF35AC0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:32:00,776 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA8266410>
2024-01-20 14:32:00,776 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA8265B50>
2024-01-20 14:32:00,777 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027FFFF35AC0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:32:00,777 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027FFFF35AC0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:32:00,789 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA4F50B50>
2024-01-20 14:32:00,789 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:32:00,790 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:32:00,790 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:32:00,799 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA4F501D0>
2024-01-20 14:32:00,799 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027FFFF35AC0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:32:00,801 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA82AEFD0>
2024-01-20 14:32:00,801 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:32:00,801 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA82AEBD0>
2024-01-20 14:32:00,801 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:32:00,801 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA82AEB10>
2024-01-20 14:32:00,801 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:32:00,801 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:32:00,801 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:32:00,802 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:32:00,802 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:32:00,802 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:32:00,802 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:32:00,821 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA8266850>
2024-01-20 14:32:00,821 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:32:00,821 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:32:00,821 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:32:00,822 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA8265FD0>
2024-01-20 14:32:00,822 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:32:00,822 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA4F50C50>
2024-01-20 14:32:00,822 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:32:00,823 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA4F52950>
2024-01-20 14:32:00,823 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA82652D0>
2024-01-20 14:32:00,823 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:32:00,823 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA8267150>
2024-01-20 14:32:00,823 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA829D350>
2024-01-20 14:32:00,823 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:32:00,823 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027FFFF35AC0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:32:00,823 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:32:00,824 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:32:00,824 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:32:00,824 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:32:00,824 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:32:00,825 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:32:00,825 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:32:00,825 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:32:00,825 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:32:00,825 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:32:00,826 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:32:00,835 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA82AFA90>
2024-01-20 14:32:00,835 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:32:00,836 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:32:00,836 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:32:00,845 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027FA4F509D0>
2024-01-20 14:32:00,846 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:32:00,846 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:32:00,846 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:32:08,667 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:32:08,668 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:32:10,076 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sat, 20 Jan 2024 13:32:08 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'179'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'200'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f05fa06311da537b86cee1bfad681e11'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=_1tVtWu7NDFrUt6k.RaIA.fxhIUKYF.orQ8bo1K6laA-1705757528-1-Afk8OKJrsPmZLxI6xkhhbcvn3HKsfDHt/bpL88HaBzTWvsLlxKh2OPoOKhBy6dYVtBbYEP2vL+ZHnGYOo6addWs=; path=/; expires=Sat, 20-Jan-24 14:02:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=XgoAFgkmaKwYSl2zaAHSCOoT_APPk64wCIoAAbwaS8Q-1705757528712-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487ae50cae492c5-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:32:10,078 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 400 Bad Request"
2024-01-20 14:32:10,079 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:32:10,079 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:32:10,079 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:32:10,079 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:32:10,079 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "400 Bad Request"
2024-01-20 14:32:10,079 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2024-01-20 14:32:10,081 DEBUG openai._base_client Not retrying
2024-01-20 14:32:10,081 DEBUG openai._base_client Re-raising status error
2024-01-20 14:32:10,081 ERROR transcription Error transcribing file part 12: Error code: 400 - {'error': {'message': 'The audio file could not be decoded or its format is not supported.', 'type': 'invalid_request_error', 'param': None, 'code': None}}
2024-01-20 14:35:15,517 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 14:35:15,519 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 14:35:15,749 INFO transcription All nescessary class variables are declared and working!
2024-01-20 14:35:20,383 DEBUG pydub.converter subprocess.call(['ffmpeg', '-y', '-f', 'mp3', '-i', 'C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\DATA\\videoplayback (1)\\videoplayback (1).mp3', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
2024-01-20 14:35:25,195 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_b0b83007-0435-4941-aaa1-1f3d9cf9112b.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:35:25,198 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_374d79d7-974a-4c33-9ec7-d62c643b3fd5.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:35:25,200 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_5e5c0df1-48be-494f-b178-8fb321865b3b.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:35:25,202 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_25ae0a2a-4808-44e3-8187-1341d4a60f2c.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:35:25,205 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_899addd1-76d9-431f-88ef-c2c3264a3e4b.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:35:25,208 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_10352f14-6135-44ec-a504-3c459f99dd27.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:35:25,210 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_ce63c61b-6dac-4726-8699-125034866074.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:35:25,212 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_be2a27ea-7928-49d1-a32c-812a125b0f23.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:35:25,215 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_e3f4e2e7-220b-4ef6-99eb-1c382d8f9447.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:35:25,217 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_bb592755-5b1e-4288-afc8-8222d1b04cea.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:35:25,219 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_911dd098-c4e6-4b5a-b143-5179928dc7be.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:35:25,222 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_abf8fdb0-8647-4760-b6b5-00e6839aafea.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:35:25,224 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_0414d755-8a1a-449b-8bf9-11b449274e19.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:35:25,451 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:35:25,468 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:35:25,477 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:35:25,486 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:35:25,487 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:35:25,491 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:35:25,499 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:35:25,509 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:35:25,511 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:35:25,512 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:35:25,513 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:35:25,514 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:35:25,515 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:35:25,522 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C300106510>
2024-01-20 14:35:25,522 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C370EE97F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:35:25,525 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C371B12D10>
2024-01-20 14:35:25,525 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C370EE97F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:35:25,533 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C300106090>
2024-01-20 14:35:25,533 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C300106810>
2024-01-20 14:35:25,533 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C370EE97F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:35:25,534 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C370EE97F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:35:25,535 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C3785461D0>
2024-01-20 14:35:25,535 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C3784BF990>
2024-01-20 14:35:25,535 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C370EE97F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:35:25,535 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C378545ED0>
2024-01-20 14:35:25,535 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C370EE97F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:35:25,535 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C370EE97F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:35:25,536 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C300105FD0>
2024-01-20 14:35:25,537 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:35:25,537 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C378547550>
2024-01-20 14:35:25,537 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:35:25,537 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C370EE97F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:35:25,537 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:35:25,542 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C37850A510>
2024-01-20 14:35:25,542 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C37850B150>
2024-01-20 14:35:25,542 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C370EE97F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:35:25,542 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C378547AD0>
2024-01-20 14:35:25,542 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C370EE97F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:35:25,542 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C370EE97F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:35:25,543 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C300104A10>
2024-01-20 14:35:25,543 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C3001070D0>
2024-01-20 14:35:25,543 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C370EE97F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:35:25,543 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C370EE97F0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:35:25,546 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C300106450>
2024-01-20 14:35:25,546 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:35:25,546 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:35:25,546 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:35:25,564 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C378546E50>
2024-01-20 14:35:25,564 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C300106290>
2024-01-20 14:35:25,564 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:35:25,564 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C378544B10>
2024-01-20 14:35:25,564 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:35:25,565 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C378547190>
2024-01-20 14:35:25,565 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C378545BD0>
2024-01-20 14:35:25,565 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C378545A90>
2024-01-20 14:35:25,565 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C378544C90>
2024-01-20 14:35:25,565 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C378545C10>
2024-01-20 14:35:25,565 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:35:25,565 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:35:25,565 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C37850B210>
2024-01-20 14:35:25,566 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:35:25,566 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:35:25,566 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:35:25,566 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C300106850>
2024-01-20 14:35:25,566 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:35:25,566 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:35:25,566 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:35:25,567 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C3000F5B10>
2024-01-20 14:35:25,567 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:35:25,567 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:35:25,567 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:35:25,567 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:35:25,567 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:35:25,568 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:35:25,568 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:35:25,568 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:35:25,568 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:35:25,569 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:35:25,569 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:35:25,569 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:35:25,569 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:35:25,569 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:35:25,570 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:35:25,570 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:35:25,570 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:35:25,571 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:35:25,571 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:35:25,571 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:35:25,571 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:35:25,572 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:35:25,572 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:36:49,173 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 14:36:49,175 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 14:36:49,400 INFO transcription All nescessary class variables are declared and working!
2024-01-20 14:36:54,253 DEBUG pydub.converter subprocess.call(['ffmpeg', '-y', '-f', 'mp3', '-i', 'C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\DATA\\videoplayback (1)\\videoplayback (1).mp3', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
2024-01-20 14:37:06,978 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_939062a4-3b00-40bc-9c1b-a3305091cfd3.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:37:06,981 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_116f06e7-1243-42e4-96a4-f7a0a7c52a0e.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:37:06,983 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_553cc332-50f1-48b7-bc43-696143b96a29.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:37:06,986 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_b73f3a57-e7b8-4932-bb01-d988ee5db153.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:37:06,988 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_855d57e5-c958-4546-999f-b1d8e49ada15.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:37:06,990 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_956536b4-d689-4ff1-80ec-6e188d781979.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:37:06,992 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_e084cf3d-97b8-4843-9e1f-1dc541b94d47.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:37:06,995 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_786ac38a-1c11-436b-9346-6db071aa8fd9.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:37:06,997 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_5a607602-904e-45c0-8049-ab6a968048ff.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:37:07,000 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_6100ca1f-5dfb-4016-8704-b10e867857d2.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:37:07,002 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_095b27a7-12f5-470b-a6e9-2d6babf744c3.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:37:07,005 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_e0404287-04b8-4176-ac2f-cac23a0fe62f.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:37:07,007 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_d0268296-97a3-4b20-8546-973f9bd84204.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:37:07,226 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:37:07,226 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:37:07,228 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:37:07,238 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:37:07,243 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:37:07,247 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:37:07,252 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:37:07,254 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:37:07,257 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:37:07,257 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:37:07,259 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:37:07,264 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:37:07,264 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:37:07,314 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE120E50>
2024-01-20 14:37:07,314 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:37:07,319 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE105890>
2024-01-20 14:37:07,319 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE104650>
2024-01-20 14:37:07,319 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:37:07,319 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE065B90>
2024-01-20 14:37:07,319 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE104AD0>
2024-01-20 14:37:07,319 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE120D50>
2024-01-20 14:37:07,319 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:37:07,320 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:37:07,320 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:37:07,320 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:37:07,325 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE120E10>
2024-01-20 14:37:07,325 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE121010>
2024-01-20 14:37:07,325 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE121590>
2024-01-20 14:37:07,325 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE120CD0>
2024-01-20 14:37:07,325 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE122810>
2024-01-20 14:37:07,325 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:37:07,325 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:37:07,325 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:37:07,326 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:37:07,326 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:37:07,336 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE121D50>
2024-01-20 14:37:07,336 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:37:07,336 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:37:07,336 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:37:07,339 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0F6350>
2024-01-20 14:37:07,339 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:37:07,339 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0F6790>
2024-01-20 14:37:07,339 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:37:07,339 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:37:07,339 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0F6650>
2024-01-20 14:37:07,339 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:37:07,340 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE121050>
2024-01-20 14:37:07,340 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CDD5D150>
2024-01-20 14:37:07,340 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:37:07,340 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0F6510>
2024-01-20 14:37:07,340 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:37:07,340 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:37:07,340 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:37:07,340 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:37:07,341 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:37:07,341 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:37:07,342 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:37:07,342 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:37:07,342 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:37:07,343 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0F7AD0>
2024-01-20 14:37:07,343 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:37:07,343 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0F6D90>
2024-01-20 14:37:07,344 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0F7ED0>
2024-01-20 14:37:07,344 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:37:07,344 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:37:07,344 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:37:07,344 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0F63D0>
2024-01-20 14:37:07,344 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0F7C50>
2024-01-20 14:37:07,344 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:37:07,344 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:37:07,345 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0F7990>
2024-01-20 14:37:07,345 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:37:07,345 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:37:07,345 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:37:07,345 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:37:07,345 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:37:07,346 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:37:07,346 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:37:07,346 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:37:07,347 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:37:07,347 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:37:07,347 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:37:07,347 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:37:07,360 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE121110>
2024-01-20 14:37:07,360 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:37:07,360 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:37:07,360 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:37:07,362 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE145290>
2024-01-20 14:37:07,362 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:37:07,362 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:37:07,362 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:37:16,184 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:37:16,184 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:37:17,977 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sat, 20 Jan 2024 13:37:16 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'179'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'304'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9363864ba3784951e3e0f45fbd1ae60d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=PPC9u1Wm_3SlB_6p6xVWyvAgbuAkGX6RbQ2IzFNf3Tk-1705757836-1-AYzvcTbjDR/6IbF3pc6h7jS4/Osvj2JiSgnOVi70vR/0SBXVXfmxKQTwBsKXs96gQs130f1rDi1i1pILO/HADko=; path=/; expires=Sat, 20-Jan-24 14:07:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=VhKUz3fvfNh3PEPPMqPu2t5u2x7cMGJXSPym1efQAco-1705757836606-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b5cc9a269b83-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:37:17,979 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 400 Bad Request"
2024-01-20 14:37:17,979 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:37:17,979 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:37:17,979 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:37:17,979 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:37:17,980 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "400 Bad Request"
2024-01-20 14:37:17,980 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2024-01-20 14:37:17,981 DEBUG openai._base_client Not retrying
2024-01-20 14:37:17,981 DEBUG openai._base_client Re-raising status error
2024-01-20 14:37:17,982 ERROR transcription Error transcribing file part 12: Error code: 400 - {'error': {'message': 'The audio file could not be decoded or its format is not supported.', 'type': 'invalid_request_error', 'param': None, 'code': None}}
2024-01-20 14:38:27,920 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:38:27,920 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:38:27,930 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:38:27,930 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:38:28,776 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:38:28,776 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:38:29,080 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:38:29,080 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:38:29,906 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:38:29,906 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:38:30,108 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:38:30,108 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:38:30,452 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:38:30,452 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:38:30,619 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:38:30,620 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:38:30,831 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:38:30,831 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:38:31,072 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:38:29 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'628'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'48'), (b'x-ratelimit-reset-requests', b'2.39s'), (b'x-request-id', b'902d8e6116abe98bfc80bc4f740efac2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=QIIRufL3xjicF2mBOohx_2qDivowwkKEMb_SWnrJljo-1705757909-1-AcFKWpon5OHkw7tSpaFACAjNpga9blbthCMmftQlvZDKIq59OS+tyOBOYo7mTkvYK842tyq3xPcUruYxDzBxK7U=; path=/; expires=Sat, 20-Jan-24 14:08:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=z3eGCVkFW0iore3nqsKFCkXnNjfr7ZLZ3R70DKP7EKs-1705757909700-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b5cc6e2b9bd7-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:38:31,073 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:38:31,073 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:38:31,073 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:38:31,074 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:38:31,074 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:38:31,074 DEBUG httpcore.connection close.started
2024-01-20 14:38:31,074 DEBUG httpcore.connection close.complete
2024-01-20 14:38:31,074 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:38:31,074 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:38:31,075 DEBUG openai._base_client Not retrying
2024-01-20 14:38:31,075 DEBUG openai._base_client Re-raising status error
2024-01-20 14:38:31,075 ERROR transcription Error transcribing file part 6: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:38:31,364 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:38:29 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'766'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'418b2ffe7a6a6b716998c29c299812ed'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=W9hGRw0KMWrfYLf6E2SD9EVWic.FlolhfXcrLpystcY-1705757909-1-Aci4myGI7CeuliV6UCf6QRGhPByRYB5OD8550RF8nKxt3SF68W7v/62fJaGitpaAA+M2LMuaBzF2rHiVDCyBY2w=; path=/; expires=Sat, 20-Jan-24 14:08:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=zb3nM.hBaFnUdTsZ9AvZQTS.JAXfrphXENac.mpCots-1705757909992-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b5cc783d3734-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:38:31,365 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:38:31,365 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:38:31,365 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:38:31,365 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:38:31,365 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:38:31,366 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:38:31,366 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:38:31,366 DEBUG openai._base_client Not retrying
2024-01-20 14:38:31,366 DEBUG openai._base_client Re-raising status error
2024-01-20 14:38:31,366 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:38:31,570 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:38:31,570 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:38:31,736 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:38:31,736 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:38:32,156 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:38:30 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'660'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'48'), (b'x-ratelimit-reset-requests', b'2.11s'), (b'x-request-id', b'cb5a4975bee28cb3740d4f12618f3969'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=NEMIY19YNc2ji7_9hov0DIawB.l83R.7zm9DEdUIGJs-1705757910-1-AbN/fLN5UPoHX05S8Zxh8ydeClvwPiL05BghM0FNXGJjYh7kvlSE/m/sqzN9jjqcWRJEEV1W2PgPYxmIdHxZBE4=; path=/; expires=Sat, 20-Jan-24 14:08:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Sm5Oe05FINsjPmJ6aOJgONZA.WSxtIABJyCCwyj7cyk-1705757910784-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b5cc7951915c-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:38:32,157 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:38:32,157 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:38:32,157 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:38:32,157 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:38:32,157 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:38:32,157 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:38:32,157 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:38:32,158 DEBUG openai._base_client Not retrying
2024-01-20 14:38:32,158 DEBUG openai._base_client Re-raising status error
2024-01-20 14:38:32,158 ERROR transcription Error transcribing file part 10: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:38:32,506 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:38:31 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'644'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'47'), (b'x-ratelimit-reset-requests', b'2.964s'), (b'x-request-id', b'1f9113d2cbd4b44dd515c69c78213814'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=RAuL2lxIJCCi1Xv9tZtNTg5eKv0SLGSEOn0V7f_tXHA-1705757911-1-AR1qTJoEKnb0d1vDdUOqDYHzDEUsbafOzTrIk2Qf3iyh5QaIQNEcpkhFrWeFMIMa5X2BZLwtPv1Fr5V2YKxCqK8=; path=/; expires=Sat, 20-Jan-24 14:08:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=LyDJZj7sX1PjPVjBC2gOb57DSvigZmrXpb6pyLR9iNo-1705757911134-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b5cc6d5a2ba8-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:38:32,507 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:38:32,507 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:38:32,507 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:38:32,507 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:38:32,507 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:38:32,507 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:38:32,507 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:38:32,508 DEBUG openai._base_client Not retrying
2024-01-20 14:38:32,508 DEBUG openai._base_client Re-raising status error
2024-01-20 14:38:32,508 ERROR transcription Error transcribing file part 4: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:38:32,771 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:38:32,771 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:38:33,214 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:38:31 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'766'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'46'), (b'x-ratelimit-reset-requests', b'3.622s'), (b'x-request-id', b'1af8c80d5c8138241ab7da051831a993'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=t5_PC2Cep6Fogyc5Re5B6vHz0xcCkiPCaq1E0H7Cwb0-1705757911-1-AWIsTw0FPqh7I2r9Rd+mb0BUCKvIkB/c3Vl1qk/DhcWcMmuYHwxf8tCsfvtn6A7mAW97tfnl9kfAAYQLL9T1xKc=; path=/; expires=Sat, 20-Jan-24 14:08:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=NIKpciRJy0DHwAWDBzxfIidKsnMf2UHIKvR9N_Ak_VM-1705757911842-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b5cc6d8591e3-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:38:33,215 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:38:33,215 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:38:33,215 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:38:33,215 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:38:33,215 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:38:33,216 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:38:33,216 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:38:33,216 DEBUG openai._base_client Not retrying
2024-01-20 14:38:33,216 DEBUG openai._base_client Re-raising status error
2024-01-20 14:38:33,217 ERROR transcription Error transcribing file part 8: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:38:33,509 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:38:32 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'596'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'46'), (b'x-ratelimit-reset-requests', b'4.76s'), (b'x-request-id', b'621dfd694fc21959d769125fbeafcba5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=56hUQJqdtUSDQpkinHYDztifAiTl7W_iUVUqOa0Agjg-1705757912-1-Ac0fiG1WJHCJfAhJq1RTIANaEPsU/seYG4o8gmJG4oJCOJQs1h5mUkAQMnoR6p+MHRodcrWOKGQQk9N5GGmwvKY=; path=/; expires=Sat, 20-Jan-24 14:08:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=RdvocT2BUmk7vO3DtaEO_5qCwaioxuagD3TE8efGHSA-1705757912137-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b5cc7e672c5e-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:38:33,510 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:38:33,510 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:38:33,511 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:38:33,511 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:38:33,511 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:38:33,511 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:38:33,511 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:38:33,512 DEBUG openai._base_client Not retrying
2024-01-20 14:38:33,512 DEBUG openai._base_client Re-raising status error
2024-01-20 14:38:33,512 ERROR transcription Error transcribing file part 11: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:38:33,991 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:38:32 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'763'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'45'), (b'x-ratelimit-reset-requests', b'5.785s'), (b'x-request-id', b'98069cd3f0faecaabe3d48d64577e007'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=zDpufrcop4GmNaZPnlkcNw9xQAWzOH.NimrxzV3EfR4-1705757912-1-AQ/wodJF3jvbJ5QZpT/V8NcIEBazcMJgJ67dxtGJBbEkDuUEmGu8lsPMTXhhuVS7EvTBv07oEinZo+pJmzBmp2A=; path=/; expires=Sat, 20-Jan-24 14:08:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=zBeeZPdSrXtHly5LTd_LwEDBdidc8IIafbWffj1LIEs-1705757912618-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b5cc7b86bb80-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:38:33,992 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:38:33,992 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:38:33,992 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:38:33,992 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:38:33,992 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:38:33,993 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:38:33,993 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:38:33,993 DEBUG openai._base_client Not retrying
2024-01-20 14:38:33,993 DEBUG openai._base_client Re-raising status error
2024-01-20 14:38:33,993 ERROR transcription Error transcribing file part 3: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:38:34,223 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:38:32 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'747'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'44'), (b'x-ratelimit-reset-requests', b'6.587s'), (b'x-request-id', b'1a5e5a7073d48404bb8aff4c374e6036'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=bXo4PJm7why1LHXGrRzWMRYbRoY6a7qv66eW5IU0pAg-1705757912-1-AV0aebJoyF8rEgzR+PeDBxY1aW+Ecen8OSZIbvOGy0nR1tvVBQbf7x7XPkDicvtRqTiAhq0R+XnQ6bcRnLUc/uo=; path=/; expires=Sat, 20-Jan-24 14:08:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=rLbVJm4uY0YU.kiuc3JBp8JLeiHmpk8k1he3jJtpiJI-1705757912851-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b5ccadf29be0-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:38:34,224 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:38:34,224 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:38:34,224 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:38:34,224 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:38:34,224 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:38:34,224 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:38:34,225 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:38:34,225 DEBUG openai._base_client Not retrying
2024-01-20 14:38:34,225 DEBUG openai._base_client Re-raising status error
2024-01-20 14:38:34,225 ERROR transcription Error transcribing file part 5: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:38:34,313 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:38:32 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'703'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'43'), (b'x-ratelimit-reset-requests', b'7.734s'), (b'x-request-id', b'dabfdeb5219bd907106fbbaa25da568a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=DCo0QP2SqGrzizzBWHklJXwykkzyv8fuaeqpShc6DqY-1705757912-1-Ac2Taqc/+O3vCVqchcpwvfiZXWxcrQbvNJIMwlah7gCtlvyaI1Ij9PkipncmkHSjqVGTUhTr03StjGxsVtYAsvE=; path=/; expires=Sat, 20-Jan-24 14:08:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=YpztkZ5mD2jyf_ahUn6e91RC0Q9Jc6aVfdIELMgl4uE-1705757912941-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b5cc5e09040c-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:38:34,314 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:38:34,314 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:38:34,314 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:38:34,314 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:38:34,314 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:38:34,315 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:38:34,315 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:38:34,315 DEBUG openai._base_client Not retrying
2024-01-20 14:38:34,315 DEBUG openai._base_client Re-raising status error
2024-01-20 14:38:34,316 ERROR transcription Error transcribing file part 7: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:38:34,904 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:38:33 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'643'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'42'), (b'x-ratelimit-reset-requests', b'9.365s'), (b'x-request-id', b'0e8d580193c2dada98d76b052f74e684'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=FoEw9pQjN1Xao2ytomIMFtdZFaIwLYNlJkLYXyJQmq0-1705757913-1-AV9KJzvqWCCQmaQ/YHvx3yl5lbQODSYSrLw6y2U1J0DJ1bmf7x6Zb+iGgr4T/pT5vw+tKGXRy87pSYeq9/pkmqE=; path=/; expires=Sat, 20-Jan-24 14:08:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=js4Mxdqf8gK3dbvQUZYKNpB.6gdCb__eCV3cxdhprRE-1705757913532-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b5cc7e559bf4-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:38:34,905 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:38:34,905 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:38:34,905 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:38:34,905 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:38:34,905 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:38:34,905 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:38:34,905 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:38:34,906 DEBUG openai._base_client Not retrying
2024-01-20 14:38:34,906 DEBUG openai._base_client Re-raising status error
2024-01-20 14:38:34,906 ERROR transcription Error transcribing file part 2: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:38:34,950 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:38:33 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'646'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'43'), (b'x-ratelimit-reset-requests', b'8.216s'), (b'x-request-id', b'f2e25a15cb0e18102842149a98cec5d7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Gkm2dFUcBJQCtWBZmPxWHYEbv1OKkRx1A5j19BDnaI0-1705757913-1-AXbWW7EW1s3icnUnKSe64pvOTtI2H+Dv4mlrWLjRsnO/cxQBBUP87vlrK7CezicpG9u38m14j8vdItMsxYdDPns=; path=/; expires=Sat, 20-Jan-24 14:08:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=R9EcB6S2vK1OmDUJoUe7raJh3424U069EO_v38ftOgs-1705757913577-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b5cc7d0c6904-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:38:34,950 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:38:34,950 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:38:34,951 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:38:34,951 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:38:34,951 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:38:34,951 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:38:34,951 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:38:34,951 DEBUG openai._base_client Not retrying
2024-01-20 14:38:34,951 DEBUG openai._base_client Re-raising status error
2024-01-20 14:38:34,952 ERROR transcription Error transcribing file part 1: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:38:35,495 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:38:34 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'648'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'42'), (b'x-ratelimit-reset-requests', b'9.554s'), (b'x-request-id', b'eeb76069c2818ad1c05dc3fa2e85d083'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=1C98j39.kv5LMJD1wL_PPGPHQZPAwYvGdBNEcdAfcg8-1705757914-1-ATUBuOJ1jInOoGc4PcJ6r6KGIB5k6dgHYMku0mv+EeT/2+gTbDLJgqk3v88qXczRBDiMJYj4M7Ltpfjkzaz1Uw8=; path=/; expires=Sat, 20-Jan-24 14:08:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=PfH_tOaQMd6mikPDQe0NFj0_Ejrn.beFyQOIrNtWB00-1705757914122-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b5cc7b10916b-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:38:35,496 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:38:35,496 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:38:35,496 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:38:35,496 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:38:35,496 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:38:35,496 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:38:35,496 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:38:35,497 DEBUG openai._base_client Not retrying
2024-01-20 14:38:35,497 DEBUG openai._base_client Re-raising status error
2024-01-20 14:38:35,497 ERROR transcription Error transcribing file part 9: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:38:35,521 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \n'}], 'model': 'gpt-4'}}
2024-01-20 14:38:35,542 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \n'}], 'model': 'gpt-4'}}
2024-01-20 14:38:35,544 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:38:35,545 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:38:35,545 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:38:35,545 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:38:35,545 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:38:35,545 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:38:35,546 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:38:35,546 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:38:35,546 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:38:35,546 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:38:37,803 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 13:38:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'2061'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'9790'), (b'x-ratelimit-reset-requests', b'17.278s'), (b'x-ratelimit-reset-tokens', b'1.258s'), (b'x-request-id', b'8d8c5be892cddb62d0ce98a5763f4ac0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b7f3bc64915c-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:38:37,804 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 14:38:37,804 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:38:37,804 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:38:37,804 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:38:37,804 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:38:37,804 DEBUG httpcore.connection close.started
2024-01-20 14:38:37,805 DEBUG httpcore.connection close.complete
2024-01-20 14:38:37,805 DEBUG httpcore.connection close.started
2024-01-20 14:38:37,805 DEBUG httpcore.connection close.complete
2024-01-20 14:38:37,805 DEBUG httpcore.connection close.started
2024-01-20 14:38:37,805 DEBUG httpcore.connection close.complete
2024-01-20 14:38:37,805 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 14:38:38,876 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 13:38:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'3087'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9910'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'540ms'), (b'x-request-id', b'b9650e96f6fa4b32f5ed7b99fec3d3d0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b7f3b9552c5e-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:38:38,877 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 14:38:38,877 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:38:38,877 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:38:38,877 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:38:38,877 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:38:38,877 DEBUG httpcore.connection close.started
2024-01-20 14:38:38,878 DEBUG httpcore.connection close.complete
2024-01-20 14:38:38,878 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 14:39:45,323 DEBUG pydub.converter subprocess.call(['ffmpeg', '-y', '-f', 'mp3', '-i', 'C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\DATA\\videoplayback (1)\\videoplayback (1).mp3', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
2024-01-20 14:39:58,180 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_b65ca0c1-05bf-4ef7-9f9d-58e5e7dd1e05.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:39:58,181 DEBUG httpcore.connection close.started
2024-01-20 14:39:58,182 DEBUG httpcore.connection close.complete
2024-01-20 14:39:58,183 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_e931812c-67e0-4e70-b56c-a905f337b755.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:39:58,184 DEBUG httpcore.connection close.started
2024-01-20 14:39:58,185 DEBUG httpcore.connection close.complete
2024-01-20 14:39:58,185 DEBUG httpcore.connection close.started
2024-01-20 14:39:58,186 DEBUG httpcore.connection close.complete
2024-01-20 14:39:58,186 DEBUG httpcore.connection close.started
2024-01-20 14:39:58,187 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_7ba6f0a4-4206-4e5c-b6bd-435515e62ad1.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:39:58,187 DEBUG httpcore.connection close.complete
2024-01-20 14:39:58,189 DEBUG httpcore.connection close.started
2024-01-20 14:39:58,190 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_4ca7381c-0807-4644-a4ba-68e1d44d3702.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:39:58,190 DEBUG httpcore.connection close.complete
2024-01-20 14:39:58,192 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_4591574c-a4b7-43f2-bf30-dc235d18a5e4.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:39:58,192 DEBUG httpcore.connection close.started
2024-01-20 14:39:58,193 DEBUG httpcore.connection close.complete
2024-01-20 14:39:58,194 DEBUG httpcore.connection close.started
2024-01-20 14:39:58,195 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_c55d2a63-242e-46aa-8fb5-aea15daac34e.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:39:58,195 DEBUG httpcore.connection close.complete
2024-01-20 14:39:58,196 DEBUG httpcore.connection close.started
2024-01-20 14:39:58,197 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_fb773b21-c2fa-4adb-a2e7-dac2b3955560.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:39:58,198 DEBUG httpcore.connection close.complete
2024-01-20 14:39:58,198 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:39:58,198 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:39:58,199 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:39:58,199 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:39:58,199 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:39:58,200 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:39:58,200 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_e7660e3e-c09e-444b-96f2-7a24126b130b.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:39:58,201 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:39:58,202 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_cb9f7105-b2a2-40ed-a0b9-84a217d03d60.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:39:58,204 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:39:58,206 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_b71614cd-0dc6-4b46-b642-b90a332c9029.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:39:58,206 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:39:58,208 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:39:58,209 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_9b4a00ef-a8bf-43f8-b1b9-d04ca67b75f5.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:39:58,210 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:39:58,212 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_1a2b7d19-d9e9-430c-ab71-ffc032b37413.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:39:58,213 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:39:58,214 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_d7f7575f-1d52-4e0f-9c69-0b444274da0b.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:39:58,215 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:39:58,276 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0EC1D0>
2024-01-20 14:39:58,276 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:39:58,282 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE120B50>
2024-01-20 14:39:58,282 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0F7010>
2024-01-20 14:39:58,282 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:39:58,282 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0EC710>
2024-01-20 14:39:58,282 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:39:58,283 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:39:58,284 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235D1460090>
2024-01-20 14:39:58,284 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235D144F290>
2024-01-20 14:39:58,284 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:39:58,284 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE08D290>
2024-01-20 14:39:58,284 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE1207D0>
2024-01-20 14:39:58,285 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE140B50>
2024-01-20 14:39:58,285 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0F6E50>
2024-01-20 14:39:58,285 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0F5650>
2024-01-20 14:39:58,285 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235D14822D0>
2024-01-20 14:39:58,285 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235D1480E10>
2024-01-20 14:39:58,285 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:39:58,285 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:39:58,285 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:39:58,285 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:39:58,285 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:39:58,286 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:39:58,286 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:39:58,286 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:39:58,299 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0F7AD0>
2024-01-20 14:39:58,299 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:39:58,299 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:39:58,299 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:39:58,303 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0EC310>
2024-01-20 14:39:58,303 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:39:58,304 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0EF450>
2024-01-20 14:39:58,304 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:39:58,304 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:39:58,304 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:39:58,304 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:39:58,304 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:39:58,305 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235D144D490>
2024-01-20 14:39:58,305 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:39:58,305 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:39:58,306 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:39:58,360 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE08D390>
2024-01-20 14:39:58,360 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE08C3D0>
2024-01-20 14:39:58,360 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE08F9D0>
2024-01-20 14:39:58,360 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:39:58,360 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0F6490>
2024-01-20 14:39:58,361 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:39:58,361 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE140B90>
2024-01-20 14:39:58,361 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:39:58,361 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE08E3D0>
2024-01-20 14:39:58,361 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CDD5D090>
2024-01-20 14:39:58,361 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235D14800D0>
2024-01-20 14:39:58,361 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:39:58,361 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:39:58,362 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:39:58,362 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:39:58,362 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE087090>
2024-01-20 14:39:58,362 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:39:58,362 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:39:58,362 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:39:58,363 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:39:58,363 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:39:58,363 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:39:58,363 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:39:58,363 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:39:58,363 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:39:58,363 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:39:58,364 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:39:58,364 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:39:58,364 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:39:58,365 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:39:58,365 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:39:58,365 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:39:58,366 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:39:58,366 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:39:58,366 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:39:58,366 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:40:05,950 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:40:05,950 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:40:07,182 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sat, 20 Jan 2024 13:40:05 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'179'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'211'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e726c692225204f0886bb906e40d2660'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b9f93df99b63-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:40:07,182 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 400 Bad Request"
2024-01-20 14:40:07,183 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:40:07,183 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:40:07,183 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:40:07,183 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:40:07,183 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "400 Bad Request"
2024-01-20 14:40:07,183 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2024-01-20 14:40:07,184 DEBUG openai._base_client Not retrying
2024-01-20 14:40:07,184 DEBUG openai._base_client Re-raising status error
2024-01-20 14:40:07,184 ERROR transcription Error transcribing file part 12: Error code: 400 - {'error': {'message': 'The audio file could not be decoded or its format is not supported.', 'type': 'invalid_request_error', 'param': None, 'code': None}}
2024-01-20 14:41:20,258 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:41:20,258 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:41:25,308 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:41:25,308 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:41:26,365 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:41:24 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'632'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'be65045965f55f529a0ccb0158d3e963'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b9f8ee8d3801-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:41:26,366 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:41:26,366 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:41:26,366 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:41:26,366 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:41:26,366 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:41:26,366 DEBUG httpcore.connection close.started
2024-01-20 14:41:26,366 DEBUG httpcore.connection close.complete
2024-01-20 14:41:26,366 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:41:26,366 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:41:26,367 DEBUG openai._base_client Not retrying
2024-01-20 14:41:26,367 DEBUG openai._base_client Re-raising status error
2024-01-20 14:41:26,367 ERROR transcription Error transcribing file part 2: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:41:27,583 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:41:27,583 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:41:27,887 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:41:27,887 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:41:28,740 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:41:28,740 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:41:28,983 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:41:28,983 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:41:29,049 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:41:29,049 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:41:29,143 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:41:27 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'609'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f820af1ddc14bbd7d5b99602c01de18c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b9f8eb2a39c4-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:41:29,143 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:41:29,143 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:41:29,144 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:41:29,144 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:41:29,144 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:41:29,144 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:41:29,144 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:41:29,145 DEBUG openai._base_client Not retrying
2024-01-20 14:41:29,145 DEBUG openai._base_client Re-raising status error
2024-01-20 14:41:29,145 ERROR transcription Error transcribing file part 7: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:41:29,439 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:41:29,440 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:41:29,670 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:41:29,671 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:41:30,070 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:41:30,070 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:41:30,213 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:41:30,213 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:41:30,233 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:41:30,233 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:41:31,293 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:41:29 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'595'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'82ac64cf5ae8b11c73b6d1ddd725b72d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b9f93b329b82-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:41:31,293 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:41:31,293 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:41:31,293 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:41:31,294 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:41:31,294 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:41:31,294 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:41:31,294 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:41:31,294 DEBUG openai._base_client Not retrying
2024-01-20 14:41:31,295 DEBUG openai._base_client Re-raising status error
2024-01-20 14:41:31,295 ERROR transcription Error transcribing file part 11: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:41:31,803 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:41:30 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'707'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'48'), (b'x-ratelimit-reset-requests', b'2.182s'), (b'x-request-id', b'62b6554b1e7345ab93e9cd1520f35afb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b9f939411e50-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:41:31,803 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:41:31,804 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:41:31,804 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:41:31,804 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:41:31,804 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:41:31,804 DEBUG httpcore.connection close.started
2024-01-20 14:41:31,804 DEBUG httpcore.connection close.complete
2024-01-20 14:41:31,804 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:41:31,804 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:41:31,805 DEBUG openai._base_client Not retrying
2024-01-20 14:41:31,805 DEBUG openai._base_client Re-raising status error
2024-01-20 14:41:31,805 ERROR transcription Error transcribing file part 8: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:41:32,104 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:41:30 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'707'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'47'), (b'x-ratelimit-reset-requests', b'2.895s'), (b'x-request-id', b'a47183d7e427a5278b1823bb34c87a15'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b9f8ea20383e-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:41:32,104 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:41:32,104 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:41:32,105 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:41:32,105 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:41:32,105 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:41:32,105 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:41:32,105 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:41:32,105 DEBUG openai._base_client Not retrying
2024-01-20 14:41:32,106 DEBUG openai._base_client Re-raising status error
2024-01-20 14:41:32,106 ERROR transcription Error transcribing file part 6: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:41:32,191 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:41:30 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'677'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'45'), (b'x-ratelimit-reset-requests', b'5.989s'), (b'x-request-id', b'0eefe27d18746a2c4e6fcbdc127a58ff'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b9f93af39972-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:41:32,191 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:41:32,191 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:41:32,191 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:41:32,191 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:41:32,192 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:41:32,192 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:41:32,192 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:41:32,192 DEBUG openai._base_client Not retrying
2024-01-20 14:41:32,192 DEBUG openai._base_client Re-raising status error
2024-01-20 14:41:32,193 ERROR transcription Error transcribing file part 10: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:41:32,203 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:41:30 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'584'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'46'), (b'x-ratelimit-reset-requests', b'3.86s'), (b'x-request-id', b'7243a76156666e72215a6d9e280fe651'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b9f93cf3bb5b-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:41:32,204 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:41:32,204 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:41:32,204 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:41:32,204 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:41:32,204 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:41:32,204 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:41:32,204 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:41:32,205 DEBUG openai._base_client Not retrying
2024-01-20 14:41:32,205 DEBUG openai._base_client Re-raising status error
2024-01-20 14:41:32,205 ERROR transcription Error transcribing file part 4: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:41:32,526 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:41:31 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'693'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'45'), (b'x-ratelimit-reset-requests', b'5.016s'), (b'x-request-id', b'26d0b30c3dafea394954b1c98b0bedca'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b9f8dafd368a-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:41:32,526 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:41:32,526 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:41:32,526 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:41:32,527 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:41:32,527 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:41:32,527 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:41:32,527 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:41:32,527 DEBUG openai._base_client Not retrying
2024-01-20 14:41:32,528 DEBUG openai._base_client Re-raising status error
2024-01-20 14:41:32,528 ERROR transcription Error transcribing file part 3: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:41:33,368 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:41:31 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'811'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'44'), (b'x-ratelimit-reset-requests', b'6.653s'), (b'x-request-id', b'a5b2681c892720b13a613fa6f2859ebe'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b9f94f7d1c85-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:41:33,369 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:41:33,369 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:41:33,369 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:41:33,369 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:41:33,369 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:41:33,369 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:41:33,369 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:41:33,370 DEBUG openai._base_client Not retrying
2024-01-20 14:41:33,370 DEBUG openai._base_client Re-raising status error
2024-01-20 14:41:33,370 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:41:33,703 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:41:32 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'691'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'42'), (b'x-ratelimit-reset-requests', b'8.5s'), (b'x-request-id', b'7531fa6cddcfacc03a65ac6d8936a739'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b9f93ff39268-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:41:33,703 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:41:33,704 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:41:33,704 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:41:33,704 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:41:33,704 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:41:33,704 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:41:33,704 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:41:33,705 DEBUG openai._base_client Not retrying
2024-01-20 14:41:33,705 DEBUG openai._base_client Re-raising status error
2024-01-20 14:41:33,705 ERROR transcription Error transcribing file part 5: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:41:33,760 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:41:32 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'717'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'43'), (b'x-ratelimit-reset-requests', b'7.42s'), (b'x-request-id', b'b3457a7c02665fc4fa2a54decb2e4901'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b9f94cad9a15-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:41:33,761 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:41:33,761 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:41:33,761 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:41:33,761 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:41:33,761 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:41:33,761 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:41:33,761 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:41:33,762 DEBUG openai._base_client Not retrying
2024-01-20 14:41:33,762 DEBUG openai._base_client Re-raising status error
2024-01-20 14:41:33,762 ERROR transcription Error transcribing file part 9: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:41:34,082 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:41:32 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'604'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'42'), (b'x-ratelimit-reset-requests', b'9.252s'), (b'x-request-id', b'a5e699cc33aadde52849ddf136f3a981'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487b9f938815c74-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:41:34,082 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:41:34,083 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:41:34,083 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:41:34,083 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:41:34,083 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:41:34,083 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:41:34,083 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:41:34,084 DEBUG openai._base_client Not retrying
2024-01-20 14:41:34,084 DEBUG openai._base_client Re-raising status error
2024-01-20 14:41:34,084 ERROR transcription Error transcribing file part 1: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:41:34,109 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \n'}], 'model': 'gpt-4'}}
2024-01-20 14:41:34,123 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:41:34,129 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \n'}], 'model': 'gpt-4'}}
2024-01-20 14:41:34,129 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:41:34,131 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:41:34,131 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:41:34,131 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:41:34,131 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:41:34,131 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:41:34,132 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:41:34,132 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:41:34,132 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:41:36,545 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 13:41:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'2203'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'9792'), (b'x-ratelimit-reset-requests', b'17.262s'), (b'x-ratelimit-reset-tokens', b'1.242s'), (b'x-request-id', b'b85dd0e2842e8351398bd773120b8041'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487bc4fdec69972-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:41:36,546 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 13:41:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'2223'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9880'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'720ms'), (b'x-request-id', b'2870d3ac114f34ded7026e318631efa7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487bc4fce919b82-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:41:36,546 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 14:41:36,547 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 14:41:36,547 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:41:36,549 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:41:36,549 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:41:36,549 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:41:36,549 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:41:36,549 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:41:36,549 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:41:36,549 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:41:36,550 DEBUG httpcore.connection close.started
2024-01-20 14:41:36,550 DEBUG httpcore.connection close.complete
2024-01-20 14:41:36,550 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 14:41:36,551 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 14:42:56,276 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_2fc052c5-a673-4fab-b1ea-f0c24544ae59.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:42:56,278 DEBUG httpcore.connection close.started
2024-01-20 14:42:56,279 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_dc6d670b-48e6-4233-9609-595105ee3e4f.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:42:56,279 DEBUG httpcore.connection close.complete
2024-01-20 14:42:56,281 DEBUG httpcore.connection close.started
2024-01-20 14:42:56,282 DEBUG httpcore.connection close.complete
2024-01-20 14:42:56,283 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_29d679b0-2823-4cba-ad49-05cab97c99cd.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:42:56,283 DEBUG httpcore.connection close.started
2024-01-20 14:42:56,285 DEBUG httpcore.connection close.complete
2024-01-20 14:42:56,285 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_cf268781-166f-48da-abe8-86177683e0d3.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:42:56,286 DEBUG httpcore.connection close.started
2024-01-20 14:42:56,288 DEBUG httpcore.connection close.complete
2024-01-20 14:42:56,289 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_45365dc0-dec2-4632-93e7-ca3b09befbc1.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:42:56,290 DEBUG httpcore.connection close.started
2024-01-20 14:42:56,291 DEBUG httpcore.connection close.complete
2024-01-20 14:42:56,291 DEBUG httpcore.connection close.started
2024-01-20 14:42:56,292 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_7ed76d44-b686-4f30-b491-740483f81815.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:42:56,293 DEBUG httpcore.connection close.complete
2024-01-20 14:42:56,293 DEBUG httpcore.connection close.started
2024-01-20 14:42:56,294 DEBUG httpcore.connection close.complete
2024-01-20 14:42:56,294 DEBUG httpcore.connection close.started
2024-01-20 14:42:56,295 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_314edefa-9bc7-4ef9-a0de-415e873bdb61.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:42:56,295 DEBUG httpcore.connection close.complete
2024-01-20 14:42:56,297 DEBUG httpcore.connection close.started
2024-01-20 14:42:56,297 DEBUG httpcore.connection close.complete
2024-01-20 14:42:56,298 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_7b94cfc7-dc16-4720-86b6-4f93ed5a14cf.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:42:56,298 DEBUG httpcore.connection close.started
2024-01-20 14:42:56,300 DEBUG httpcore.connection close.complete
2024-01-20 14:42:56,300 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:42:56,301 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_f8fcb998-72c0-4ae9-a203-ca5063c67772.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:42:56,301 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:42:56,301 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:42:56,302 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:42:56,303 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:42:56,303 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:42:56,304 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:42:56,304 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:42:56,305 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_397b49e1-abbb-401e-846c-4ff72b134102.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:42:56,305 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:42:56,307 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_0c8f2b38-8bd9-4709-b3ae-b74f301e9773.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:42:56,309 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:42:56,309 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_24ac3c2a-3a42-4a46-a9f6-f019dd37ba22.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:42:56,311 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:42:56,312 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:42:56,313 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_8a7f7917-be0d-42fa-867e-f1e76a8cb811.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:42:56,314 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:42:56,380 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235D1480650>
2024-01-20 14:42:56,380 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:42:56,382 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0D75D0>
2024-01-20 14:42:56,382 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:42:56,388 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE141E50>
2024-01-20 14:42:56,389 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE121F50>
2024-01-20 14:42:56,389 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0EE7D0>
2024-01-20 14:42:56,389 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0F4F10>
2024-01-20 14:42:56,389 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0EEC50>
2024-01-20 14:42:56,389 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0852D0>
2024-01-20 14:42:56,389 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE08CDD0>
2024-01-20 14:42:56,389 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:42:56,389 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0D6A10>
2024-01-20 14:42:56,389 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:42:56,389 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:42:56,389 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:42:56,390 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:42:56,390 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:42:56,390 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:42:56,390 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:42:56,392 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE086BD0>
2024-01-20 14:42:56,392 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:42:56,403 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE087090>
2024-01-20 14:42:56,403 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:42:56,403 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE121950>
2024-01-20 14:42:56,404 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:42:56,404 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:42:56,404 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:42:56,404 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:42:56,404 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:42:56,408 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0EF3D0>
2024-01-20 14:42:56,408 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0F4ED0>
2024-01-20 14:42:56,408 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:42:56,408 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0ED250>
2024-01-20 14:42:56,408 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:42:56,408 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:42:56,409 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:42:56,409 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE08DE10>
2024-01-20 14:42:56,409 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:42:56,409 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:42:56,410 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:42:56,410 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:42:56,433 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE10AE10>
2024-01-20 14:42:56,433 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:42:56,433 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:42:56,433 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:42:56,433 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0D5650>
2024-01-20 14:42:56,433 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:42:56,434 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:42:56,434 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:42:56,462 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE10A250>
2024-01-20 14:42:56,462 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE08FE50>
2024-01-20 14:42:56,463 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:42:56,463 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:42:56,463 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:42:56,463 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:42:56,463 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:42:56,464 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:42:56,963 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE10AD50>
2024-01-20 14:42:56,963 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE10AB50>
2024-01-20 14:42:56,963 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:42:56,963 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:42:56,963 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE109ED0>
2024-01-20 14:42:56,963 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:42:56,964 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:42:56,964 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:42:56,964 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:42:56,964 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE10A550>
2024-01-20 14:42:56,964 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:42:56,964 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:42:56,964 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE085C90>
2024-01-20 14:42:56,965 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:42:56,965 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:42:56,965 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:42:56,966 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:42:56,966 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:42:56,966 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:42:56,966 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:43:10,061 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:43:10,061 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:43:11,810 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sat, 20 Jan 2024 13:43:10 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'179'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'234'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'58ec5bff7219b5779348d21f9990705c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487be5579d32c32-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:43:11,811 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 400 Bad Request"
2024-01-20 14:43:11,811 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:43:11,811 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:43:11,811 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:43:11,811 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:43:11,812 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "400 Bad Request"
2024-01-20 14:43:11,812 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2024-01-20 14:43:11,812 DEBUG openai._base_client Not retrying
2024-01-20 14:43:11,812 DEBUG openai._base_client Re-raising status error
2024-01-20 14:43:11,813 ERROR transcription Error transcribing file part 12: Error code: 400 - {'error': {'message': 'The audio file could not be decoded or its format is not supported.', 'type': 'invalid_request_error', 'param': None, 'code': None}}
2024-01-20 14:44:08,940 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:44:08,940 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:44:10,402 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:44:10,402 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:44:12,266 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:44:12,266 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:44:12,276 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:44:12,276 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:44:12,703 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:44:11 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'677'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'fc16c52207049b6e5d7be7abc3a85326'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487be523c46922c-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:44:12,704 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:44:12,704 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:44:12,704 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:44:12,704 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:44:12,704 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:44:12,704 DEBUG httpcore.connection close.started
2024-01-20 14:44:12,705 DEBUG httpcore.connection close.complete
2024-01-20 14:44:12,705 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:44:12,705 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:44:12,705 DEBUG openai._base_client Not retrying
2024-01-20 14:44:12,705 DEBUG openai._base_client Re-raising status error
2024-01-20 14:44:12,706 ERROR transcription Error transcribing file part 11: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:44:14,192 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:44:14,192 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:44:14,427 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:44:13 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'670'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'43438519d90d2507bf89d979d46b31e8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487be525c149bd7-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:44:14,428 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:44:14,428 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:44:14,428 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:44:14,428 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:44:14,428 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:44:14,428 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:44:14,428 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:44:14,429 DEBUG openai._base_client Not retrying
2024-01-20 14:44:14,429 DEBUG openai._base_client Re-raising status error
2024-01-20 14:44:14,429 ERROR transcription Error transcribing file part 4: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:44:14,752 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:44:14,752 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:44:15,054 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:44:13 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'661'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'48'), (b'x-ratelimit-reset-requests', b'1.345s'), (b'x-request-id', b'82d46f198f3d3d7b347cc50629c7fcff'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487be523e46365f-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:44:15,054 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:44:15,055 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:44:15,055 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:44:15,055 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:44:15,055 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:44:15,055 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:44:15,055 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:44:15,056 DEBUG openai._base_client Not retrying
2024-01-20 14:44:15,056 DEBUG openai._base_client Re-raising status error
2024-01-20 14:44:15,056 ERROR transcription Error transcribing file part 8: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:44:15,294 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:44:15,294 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:44:15,332 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:44:15,333 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:44:15,560 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:44:14 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'616'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'48'), (b'x-ratelimit-reset-requests', b'1.99s'), (b'x-request-id', b'c1deccf56fdd908275b1add38a5d3685'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487be521a0b6903-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:44:15,560 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:44:15,561 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:44:15,561 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:44:15,561 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:44:15,561 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:44:15,561 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:44:15,561 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:44:15,562 DEBUG openai._base_client Not retrying
2024-01-20 14:44:15,562 DEBUG openai._base_client Re-raising status error
2024-01-20 14:44:15,562 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:44:17,635 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:44:16 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'735'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'48'), (b'x-ratelimit-reset-requests', b'1.851s'), (b'x-request-id', b'd03a964ce9b6977f4a9a75d112d626c8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487be523c23bb83-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:44:17,635 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:44:17,635 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:44:17,636 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:44:17,636 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:44:17,636 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:44:17,636 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:44:17,636 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:44:17,637 DEBUG openai._base_client Not retrying
2024-01-20 14:44:17,637 DEBUG openai._base_client Re-raising status error
2024-01-20 14:44:17,637 ERROR transcription Error transcribing file part 6: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:44:17,811 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:44:16 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'639'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'48'), (b'x-ratelimit-reset-requests', b'2.152s'), (b'x-request-id', b'13ff7832988b76a532309f04f7e23797'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487be525fadbba7-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:44:17,811 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:44:17,811 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:44:17,811 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:44:17,812 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:44:17,812 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:44:17,812 DEBUG httpcore.connection close.started
2024-01-20 14:44:17,812 DEBUG httpcore.connection close.complete
2024-01-20 14:44:17,812 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:44:17,812 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:44:17,813 DEBUG openai._base_client Not retrying
2024-01-20 14:44:17,813 DEBUG openai._base_client Re-raising status error
2024-01-20 14:44:17,813 ERROR transcription Error transcribing file part 9: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:44:18,500 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:44:17 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'718'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'47'), (b'x-ratelimit-reset-requests', b'3.175s'), (b'x-request-id', b'18a6a334f36e63600430ecdf40cbb2ce'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487be521ea95c44-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:44:18,500 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:44:18,501 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:44:18,501 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:44:18,501 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:44:18,501 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:44:18,501 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:44:18,501 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:44:18,502 DEBUG openai._base_client Not retrying
2024-01-20 14:44:18,502 DEBUG openai._base_client Re-raising status error
2024-01-20 14:44:18,502 ERROR transcription Error transcribing file part 3: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:44:18,728 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:44:17 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'682'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'46'), (b'x-ratelimit-reset-requests', b'4.304s'), (b'x-request-id', b'01fd0f61bb55f72a11875d09011253b1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487be523d3ebb53-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:44:18,728 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:44:18,729 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:44:18,729 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:44:18,729 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:44:18,729 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:44:18,729 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:44:18,729 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:44:18,730 DEBUG openai._base_client Not retrying
2024-01-20 14:44:18,730 DEBUG openai._base_client Re-raising status error
2024-01-20 14:44:18,730 ERROR transcription Error transcribing file part 1: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:44:25,129 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:44:25,130 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:44:27,139 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:44:27,139 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:44:28,514 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:44:28,514 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:44:29,109 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:44:27 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'685'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1f749007322e549c39f056940fc67b4e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487be557dba9048-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:44:29,109 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:44:29,109 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:44:29,109 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:44:29,110 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:44:29,110 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:44:29,110 DEBUG httpcore.connection close.started
2024-01-20 14:44:29,110 DEBUG httpcore.connection close.complete
2024-01-20 14:44:29,110 DEBUG httpcore.connection close.started
2024-01-20 14:44:29,110 DEBUG httpcore.connection close.complete
2024-01-20 14:44:29,110 DEBUG httpcore.connection close.started
2024-01-20 14:44:29,110 DEBUG httpcore.connection close.complete
2024-01-20 14:44:29,110 DEBUG httpcore.connection close.started
2024-01-20 14:44:29,111 DEBUG httpcore.connection close.complete
2024-01-20 14:44:29,111 DEBUG httpcore.connection close.started
2024-01-20 14:44:29,111 DEBUG httpcore.connection close.complete
2024-01-20 14:44:29,111 DEBUG httpcore.connection close.started
2024-01-20 14:44:29,111 DEBUG httpcore.connection close.complete
2024-01-20 14:44:29,111 DEBUG httpcore.connection close.started
2024-01-20 14:44:29,111 DEBUG httpcore.connection close.complete
2024-01-20 14:44:29,111 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:44:29,111 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:44:29,112 DEBUG openai._base_client Not retrying
2024-01-20 14:44:29,112 DEBUG openai._base_client Re-raising status error
2024-01-20 14:44:29,112 ERROR transcription Error transcribing file part 10: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:44:29,703 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:44:29,703 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:44:30,283 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:44:28 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'775'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'25ffed471904bdd1c00d0528084a1454'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487be557a66718b-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:44:30,283 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:44:30,283 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:44:30,284 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:44:30,284 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:44:30,284 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:44:30,284 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:44:30,284 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:44:30,284 DEBUG openai._base_client Not retrying
2024-01-20 14:44:30,284 DEBUG openai._base_client Re-raising status error
2024-01-20 14:44:30,285 ERROR transcription Error transcribing file part 7: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:44:31,263 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:44:29 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'542'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ac1c9fee0059a427d97fc4a4ad78a567'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487be5579804d55-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:44:31,264 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:44:31,264 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:44:31,265 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:44:31,265 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:44:31,265 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:44:31,265 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:44:31,265 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:44:31,266 DEBUG openai._base_client Not retrying
2024-01-20 14:44:31,266 DEBUG openai._base_client Re-raising status error
2024-01-20 14:44:31,266 ERROR transcription Error transcribing file part 5: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:44:32,475 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:44:31 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'640'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'48'), (b'x-ratelimit-reset-requests', b'1.275s'), (b'x-request-id', b'3568e6b89a4b256dcf86787bbf4dbe6a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487be559fc74dc1-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:44:32,475 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:44:32,475 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:44:32,475 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:44:32,476 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:44:32,476 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:44:32,476 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:44:32,476 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:44:32,476 DEBUG openai._base_client Not retrying
2024-01-20 14:44:32,476 DEBUG openai._base_client Re-raising status error
2024-01-20 14:44:32,477 ERROR transcription Error transcribing file part 2: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:44:32,505 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \n'}], 'model': 'gpt-4'}}
2024-01-20 14:44:32,507 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:44:32,512 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \n'}], 'model': 'gpt-4'}}
2024-01-20 14:44:32,513 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:44:32,514 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:44:32,514 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:44:32,514 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:44:32,514 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:44:32,514 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:44:32,514 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:44:32,515 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:44:32,515 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:44:34,597 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 13:44:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'1898'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9910'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'540ms'), (b'x-request-id', b'72213be5fbdf8b130a13f212b2ae9916'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487c0aabea0718b-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:44:34,597 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 14:44:34,598 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:44:34,598 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:44:34,598 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:44:34,598 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:44:34,598 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 14:44:35,082 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 13:44:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'2372'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'9790'), (b'x-ratelimit-reset-requests', b'17.276s'), (b'x-ratelimit-reset-tokens', b'1.256s'), (b'x-request-id', b'55181acf9b06792a1f0142bea8a059bc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487c0aaae699048-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:44:35,082 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 14:44:35,083 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:44:35,083 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:44:35,083 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:44:35,083 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:44:35,083 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 14:49:14,098 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_2136c6c5-d065-4cec-ade3-ba7f0cb5665c.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:49:14,101 DEBUG httpcore.connection close.started
2024-01-20 14:49:14,102 DEBUG httpcore.connection close.complete
2024-01-20 14:49:14,103 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_e30d40c9-1b4c-4744-b602-a2839270acbb.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:49:14,103 DEBUG httpcore.connection close.started
2024-01-20 14:49:14,105 DEBUG httpcore.connection close.complete
2024-01-20 14:49:14,105 DEBUG httpcore.connection close.started
2024-01-20 14:49:14,105 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_12a0a9b7-de5f-4ff9-b2ab-b7434c08a1b5.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:49:14,106 DEBUG httpcore.connection close.complete
2024-01-20 14:49:14,107 DEBUG httpcore.connection close.started
2024-01-20 14:49:14,108 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_13efd3fe-ce72-472a-9d24-49cf70a81004.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:49:14,109 DEBUG httpcore.connection close.complete
2024-01-20 14:49:14,110 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:49:14,110 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:49:14,110 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:49:14,111 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:49:14,112 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_f693cd66-108a-46dc-88d5-ad5384ff10a0.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:49:14,114 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:49:14,115 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_2183bad1-e789-48dd-9b33-2ef5a03ee473.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:49:14,116 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:49:14,117 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_fe675625-04c9-4764-bc42-b9c9389abec5.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:49:14,118 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:49:14,119 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_88cad152-deec-4c83-98a8-2df015d5c58b.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:49:14,121 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:49:14,122 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_8276bd90-e0d4-47fc-8e10-b9746c94b543.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:49:14,123 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:49:14,126 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_ec77f3e3-973e-47bd-9fe6-f47987ee7a4e.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:49:14,128 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:49:14,128 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_b293b16a-d8fe-40f3-a568-6c6c9d26c015.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:49:14,130 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:49:14,131 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_66db10de-4b07-4ecf-8a71-985d959d05e3.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:49:14,133 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_bd742656-6680-432d-b8c1-057bde20b3c7.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:49:14,181 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:49:14,182 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:49:14,190 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE08ED10>
2024-01-20 14:49:14,190 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:49:14,192 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235D144CD90>
2024-01-20 14:49:14,192 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:49:14,194 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE142F10>
2024-01-20 14:49:14,194 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0A9650>
2024-01-20 14:49:14,194 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:49:14,194 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0ECA10>
2024-01-20 14:49:14,194 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE141050>
2024-01-20 14:49:14,194 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:49:14,194 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0F66D0>
2024-01-20 14:49:14,194 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE087210>
2024-01-20 14:49:14,194 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE107710>
2024-01-20 14:49:14,194 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE1404D0>
2024-01-20 14:49:14,194 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE10BED0>
2024-01-20 14:49:14,195 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:49:14,195 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:49:14,195 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:49:14,195 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:49:14,195 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:49:14,195 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:49:14,196 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:49:14,201 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0A9C50>
2024-01-20 14:49:14,201 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0A8750>
2024-01-20 14:49:14,201 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:49:14,202 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:49:14,213 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0A9110>
2024-01-20 14:49:14,213 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0ABF90>
2024-01-20 14:49:14,213 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE08D190>
2024-01-20 14:49:14,213 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:49:14,213 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE09A550>
2024-01-20 14:49:14,213 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:49:14,213 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:49:14,214 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0AAA50>
2024-01-20 14:49:14,214 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:49:14,214 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:49:14,214 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:49:14,214 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:49:14,214 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:49:14,215 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:49:14,215 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:49:14,215 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:49:14,215 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:49:14,215 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:49:14,215 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:49:14,216 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:49:14,218 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0F4FD0>
2024-01-20 14:49:14,219 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:49:14,219 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0ABED0>
2024-01-20 14:49:14,219 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:49:14,219 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:49:14,219 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:49:14,219 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0A9250>
2024-01-20 14:49:14,220 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0A99D0>
2024-01-20 14:49:14,220 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0AA190>
2024-01-20 14:49:14,220 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0A8F50>
2024-01-20 14:49:14,220 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:49:14,220 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:49:14,220 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:49:14,221 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0A9910>
2024-01-20 14:49:14,221 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:49:14,221 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:49:14,221 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:49:14,221 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:49:14,222 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:49:14,222 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:49:14,222 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:49:14,222 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:49:14,223 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:49:14,223 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:49:14,223 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:49:14,223 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:49:14,223 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:49:14,224 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:49:14,232 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE0A8C90>
2024-01-20 14:49:14,232 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:49:14,232 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:49:14,232 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:49:21,011 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:49:21,011 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:49:22,152 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sat, 20 Jan 2024 13:49:20 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'179'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'225'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'fefbb447709cf9a7d45f7ccda770fb20'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487c78b59fc922f-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:49:22,152 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 400 Bad Request"
2024-01-20 14:49:22,152 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:49:22,153 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:49:22,153 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:49:22,153 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:49:22,153 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "400 Bad Request"
2024-01-20 14:49:22,153 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2024-01-20 14:49:22,154 DEBUG openai._base_client Not retrying
2024-01-20 14:49:22,154 DEBUG openai._base_client Re-raising status error
2024-01-20 14:49:22,154 ERROR transcription Error transcribing file part 12: Error code: 400 - {'error': {'message': 'The audio file could not be decoded or its format is not supported.', 'type': 'invalid_request_error', 'param': None, 'code': None}}
2024-01-20 14:50:37,063 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:50:37,063 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:50:38,050 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:50:38,050 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:50:38,456 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:50:38,457 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:50:39,154 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:50:39,155 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:50:39,962 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:50:39,963 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:50:40,102 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:50:40,102 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:50:40,472 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:50:40,472 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:50:40,640 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:50:40,641 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:50:40,664 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:50:40,664 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:50:40,856 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:50:39 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'816'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e26c14ea0095a6a1b88b2124dc1a6161'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487c78b6fde6ae6-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:50:40,857 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:50:40,857 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:50:40,857 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:50:40,857 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:50:40,857 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:50:40,857 DEBUG httpcore.connection close.started
2024-01-20 14:50:40,857 DEBUG httpcore.connection close.complete
2024-01-20 14:50:40,858 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:50:40,858 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:50:40,858 DEBUG openai._base_client Not retrying
2024-01-20 14:50:40,858 DEBUG openai._base_client Re-raising status error
2024-01-20 14:50:40,859 ERROR transcription Error transcribing file part 9: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:50:40,991 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:50:40,991 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:50:41,187 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:50:41,187 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:50:41,379 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:50:41,379 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:50:41,711 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:50:40 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'483'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f345b4de4bf1cb13440772267d1489d5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487c78b4e751c85-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:50:41,711 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:50:41,711 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:50:41,711 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:50:41,712 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:50:41,712 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:50:41,712 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:50:41,712 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:50:41,712 DEBUG openai._base_client Not retrying
2024-01-20 14:50:41,712 DEBUG openai._base_client Re-raising status error
2024-01-20 14:50:41,713 ERROR transcription Error transcribing file part 5: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:50:41,775 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:50:40 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'619'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'48'), (b'x-ratelimit-reset-requests', b'2.038s'), (b'x-request-id', b'8b19750e3149c0818e8a80f31303cb8d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487c78b6b4b9b8e-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:50:41,776 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:50:41,776 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:50:41,776 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:50:41,776 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:50:41,776 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:50:41,776 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:50:41,777 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:50:41,777 DEBUG openai._base_client Not retrying
2024-01-20 14:50:41,777 DEBUG openai._base_client Re-raising status error
2024-01-20 14:50:41,777 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:50:42,733 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:50:41 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'773'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'47'), (b'x-ratelimit-reset-requests', b'3.025s'), (b'x-request-id', b'c08aa5221a56569c779e7bc1073fbfad'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487c78b4e7f18e0-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:50:42,734 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:50:42,734 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:50:42,734 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:50:42,734 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:50:42,734 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:50:42,735 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:50:42,735 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:50:42,735 DEBUG openai._base_client Not retrying
2024-01-20 14:50:42,735 DEBUG openai._base_client Re-raising status error
2024-01-20 14:50:42,735 ERROR transcription Error transcribing file part 3: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:50:43,128 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:50:41 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'708'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'46'), (b'x-ratelimit-reset-requests', b'4.434s'), (b'x-request-id', b'87a940808172811985d4cd0ce0a29f05'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487c78b6e691e5c-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:50:43,128 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:50:43,129 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:50:43,129 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:50:43,129 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:50:43,129 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:50:43,129 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:50:43,129 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:50:43,130 DEBUG openai._base_client Not retrying
2024-01-20 14:50:43,130 DEBUG openai._base_client Re-raising status error
2024-01-20 14:50:43,130 ERROR transcription Error transcribing file part 4: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:50:43,233 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:50:41 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'626'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'47'), (b'x-ratelimit-reset-requests', b'3.417s'), (b'x-request-id', b'adf803a7107eb61f8f80c55061c46804'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487c78b690a9968-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:50:43,234 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:50:43,234 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:50:43,234 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:50:43,234 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:50:43,234 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:50:43,234 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:50:43,235 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:50:43,235 DEBUG openai._base_client Not retrying
2024-01-20 14:50:43,235 DEBUG openai._base_client Re-raising status error
2024-01-20 14:50:43,235 ERROR transcription Error transcribing file part 1: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:50:43,574 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:50:42 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'597'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'42'), (b'x-ratelimit-reset-requests', b'8.608s'), (b'x-request-id', b'9801a15b210cf534eb08d51913d6d39e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487c78b5a935b68-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:50:43,574 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:50:43,575 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:50:43,575 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:50:43,575 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:50:43,575 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:50:43,575 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:50:43,575 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:50:43,576 DEBUG openai._base_client Not retrying
2024-01-20 14:50:43,576 DEBUG openai._base_client Re-raising status error
2024-01-20 14:50:43,576 ERROR transcription Error transcribing file part 10: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:50:43,849 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:50:42 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'705'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'45'), (b'x-ratelimit-reset-requests', b'5.439s'), (b'x-request-id', b'9e7b2742c94eb39600cfbeffa315c997'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487c78b7f549951-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:50:43,849 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:50:43,849 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:50:43,849 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:50:43,850 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:50:43,850 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:50:43,850 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:50:43,850 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:50:43,850 DEBUG openai._base_client Not retrying
2024-01-20 14:50:43,850 DEBUG openai._base_client Re-raising status error
2024-01-20 14:50:43,851 ERROR transcription Error transcribing file part 11: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:50:44,179 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:50:42 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'709'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'44'), (b'x-ratelimit-reset-requests', b'6.28s'), (b'x-request-id', b'8add09b7be2383994b4e5adc897f98c8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487c78b6dc75b86-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:50:44,179 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:50:44,180 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:50:44,180 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:50:44,180 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:50:44,180 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:50:44,180 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:50:44,180 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:50:44,181 DEBUG openai._base_client Not retrying
2024-01-20 14:50:44,181 DEBUG openai._base_client Re-raising status error
2024-01-20 14:50:44,181 ERROR transcription Error transcribing file part 6: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:50:44,477 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:50:43 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'687'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'43'), (b'x-ratelimit-reset-requests', b'7.447s'), (b'x-request-id', b'055038a588496dc7deb386bd5f7147d2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487c78b6ddb2c39-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:50:44,478 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:50:44,478 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:50:44,478 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:50:44,478 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:50:44,478 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:50:44,479 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:50:44,479 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:50:44,479 DEBUG openai._base_client Not retrying
2024-01-20 14:50:44,479 DEBUG openai._base_client Re-raising status error
2024-01-20 14:50:44,480 ERROR transcription Error transcribing file part 2: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:50:44,665 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:50:43 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'471'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'41'), (b'x-ratelimit-reset-requests', b'10.294s'), (b'x-request-id', b'81ed3beb1847e82eeccb4b66b9c73d4c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487c78b68054d3d-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:50:44,666 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:50:44,666 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:50:44,666 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:50:44,666 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:50:44,666 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:50:44,667 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:50:44,667 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:50:44,667 DEBUG openai._base_client Not retrying
2024-01-20 14:50:44,667 DEBUG openai._base_client Re-raising status error
2024-01-20 14:50:44,668 ERROR transcription Error transcribing file part 7: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:50:44,706 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:50:43 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'614'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'42'), (b'x-ratelimit-reset-requests', b'9.127s'), (b'x-request-id', b'd7676cdb94953aa9f5977f12dc6faaac'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487c78b4d39195e-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:50:44,706 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:50:44,706 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:50:44,707 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:50:44,707 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:50:44,707 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:50:44,707 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:50:44,707 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:50:44,708 DEBUG openai._base_client Not retrying
2024-01-20 14:50:44,708 DEBUG openai._base_client Re-raising status error
2024-01-20 14:50:44,708 ERROR transcription Error transcribing file part 8: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:50:44,737 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \n'}], 'model': 'gpt-4'}}
2024-01-20 14:50:44,739 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:50:44,744 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \n'}], 'model': 'gpt-4'}}
2024-01-20 14:50:44,744 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:50:44,745 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:50:44,746 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:50:44,746 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:50:44,746 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:50:44,746 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:50:44,746 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:50:44,746 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:50:44,746 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:50:46,740 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 13:50:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'1778'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'9789'), (b'x-ratelimit-reset-requests', b'17.285s'), (b'x-ratelimit-reset-tokens', b'1.265s'), (b'x-request-id', b'19b53ef5ab503d4d394d4ad43ab04acd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487c9c1190b5b68-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:50:46,741 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 14:50:46,741 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:50:46,741 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:50:46,741 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:50:46,741 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:50:46,741 DEBUG httpcore.connection close.started
2024-01-20 14:50:46,741 DEBUG httpcore.connection close.complete
2024-01-20 14:50:46,742 DEBUG httpcore.connection close.started
2024-01-20 14:50:46,742 DEBUG httpcore.connection close.complete
2024-01-20 14:50:46,742 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 14:50:47,816 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 13:50:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'2854'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9880'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'720ms'), (b'x-request-id', b'87a5949fe0cd9649918f5aa96de4c2b9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487c9c1186c9951-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:50:47,817 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 14:50:47,817 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:50:47,817 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:50:47,818 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:50:47,818 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:50:47,818 DEBUG httpcore.connection close.started
2024-01-20 14:50:47,818 DEBUG httpcore.connection close.complete
2024-01-20 14:50:47,818 DEBUG httpcore.connection close.started
2024-01-20 14:50:47,818 DEBUG httpcore.connection close.complete
2024-01-20 14:50:47,818 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 14:52:04,308 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\DATA\\audio_segment_test\\audio_segment_test.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 14:52:04,309 DEBUG httpcore.connection close.started
2024-01-20 14:52:04,309 DEBUG httpcore.connection close.complete
2024-01-20 14:52:04,309 DEBUG httpcore.connection close.started
2024-01-20 14:52:04,310 DEBUG httpcore.connection close.complete
2024-01-20 14:52:04,310 DEBUG httpcore.connection close.started
2024-01-20 14:52:04,310 DEBUG httpcore.connection close.complete
2024-01-20 14:52:04,310 DEBUG httpcore.connection close.started
2024-01-20 14:52:04,310 DEBUG httpcore.connection close.complete
2024-01-20 14:52:04,310 DEBUG httpcore.connection close.started
2024-01-20 14:52:04,310 DEBUG httpcore.connection close.complete
2024-01-20 14:52:04,310 DEBUG httpcore.connection close.started
2024-01-20 14:52:04,310 DEBUG httpcore.connection close.complete
2024-01-20 14:52:04,311 DEBUG httpcore.connection close.started
2024-01-20 14:52:04,311 DEBUG httpcore.connection close.complete
2024-01-20 14:52:04,311 DEBUG httpcore.connection close.started
2024-01-20 14:52:04,311 DEBUG httpcore.connection close.complete
2024-01-20 14:52:04,311 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:52:04,404 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235D1481090>
2024-01-20 14:52:04,405 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:52:04,426 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235D145B5D0>
2024-01-20 14:52:04,426 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:52:04,426 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:52:04,426 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:52:26,644 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:52:26,644 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:52:30,083 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 13:52:28 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'710'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8221b09c974e2eb53d6af294493f32cc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487cbb32c3f2c53-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:52:30,084 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 14:52:30,084 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:52:30,084 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:52:30,084 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:52:30,084 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:52:30,084 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 14:52:30,084 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 14:52:30,085 DEBUG openai._base_client Not retrying
2024-01-20 14:52:30,085 DEBUG openai._base_client Re-raising status error
2024-01-20 14:52:30,085 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214678 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 14:52:30,094 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \n'}], 'model': 'gpt-4'}}
2024-01-20 14:52:30,096 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:52:30,097 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:52:30,097 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:52:30,102 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \n'}], 'model': 'gpt-4'}}
2024-01-20 14:52:30,103 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 14:52:30,103 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:52:30,103 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:52:30,135 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235CE07AA50>
2024-01-20 14:52:30,135 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000235CD145A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 14:52:30,154 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000235D144FC10>
2024-01-20 14:52:30,154 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 14:52:30,155 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 14:52:30,155 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 14:52:30,155 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 14:52:30,155 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 14:52:31,436 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 13:52:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'1092'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'9799'), (b'x-ratelimit-reset-requests', b'17.22s'), (b'x-ratelimit-reset-tokens', b'1.2s'), (b'x-request-id', b'7fef31a39410cb482f8ed29ef5fdb11c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487cc53eb3b9bd4-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:52:31,437 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 14:52:31,437 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:52:31,437 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:52:31,437 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:52:31,437 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:52:31,438 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 14:52:31,830 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 13:52:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'1545'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9880'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'720ms'), (b'x-request-id', b'e61ec89e8c9f529f8fdc53261cdfd9e8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487cc538ab52c53-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 14:52:31,831 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 14:52:31,831 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 14:52:31,832 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 14:52:31,832 DEBUG httpcore.http11 response_closed.started
2024-01-20 14:52:31,832 DEBUG httpcore.http11 response_closed.complete
2024-01-20 14:52:31,832 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 15:18:41,328 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 15:18:41,330 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 15:18:41,578 INFO transcription All nescessary class variables are declared and working!
2024-01-20 15:19:44,671 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_bad9ba4e-d7bf-4b08-b9c8-a72bc2347b0a.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 15:19:44,674 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_c262841a-118e-4a78-8f3a-60432893f607.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 15:19:44,716 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 15:19:44,716 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 15:19:44,793 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017E70629BD0>
2024-01-20 15:19:44,793 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000017E6C931AC0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 15:19:44,795 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017E70629B90>
2024-01-20 15:19:44,795 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000017E6C931AC0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 15:19:44,803 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017E70629650>
2024-01-20 15:19:44,804 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 15:19:44,804 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 15:19:44,804 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 15:19:44,818 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017E70629290>
2024-01-20 15:19:44,818 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 15:19:44,818 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 15:19:44,819 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 15:19:47,392 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 15:19:47,392 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 15:19:57,708 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 14:19:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'9048'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'83374852c36bf40113dee35b9904513f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=WSZgokQ03e0tKlgweoPWTKW.3Qynisqky8GlwIkbmkg-1705760396-1-AYcLDq1mPcBb6sGiqu979jCTykhx2wP65YS/5ykCpLRYKNQY5Th82x2qp65wBiHMhtFojcIIoPhQtqyHf64mxYc=; path=/; expires=Sat, 20-Jan-24 14:49:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=XqtS85qSVK3x9lPJNCVr.QHp3dOztF7wXq0WhzqesvE-1705760396287-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487f43c49c59b7d-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 15:19:57,710 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 15:19:57,710 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 15:19:57,710 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 15:19:57,711 DEBUG httpcore.http11 response_closed.started
2024-01-20 15:19:57,711 DEBUG httpcore.http11 response_closed.complete
2024-01-20 15:19:57,711 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 15:20:07,800 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 15:20:07,800 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 15:20:10,462 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 14:20:09 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'544'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a7368f87e764e6397f735d755abd844a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=mccLKG3oIXgPwyb6JOIlKu4yT8h2CTgbJVQu8Rpqd6k-1705760409-1-AbYyIIjXZm+9G+eCHNTu+K0OrS+c46Qy52+ZGkwyTvrE3j2hEsX9AuYggo1cRAXRbiqYPUfofu18bLQY2ihtvD4=; path=/; expires=Sat, 20-Jan-24 14:50:09 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=oSz1GHo3OI9ym9cUjArc2H0v76FiLneqUuR2.k83KL0-1705760409042-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487f43c38b23737-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 15:20:10,463 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 15:20:10,463 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 15:20:10,463 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 15:20:10,463 DEBUG httpcore.http11 response_closed.started
2024-01-20 15:20:10,464 DEBUG httpcore.http11 response_closed.complete
2024-01-20 15:20:10,464 DEBUG httpcore.connection close.started
2024-01-20 15:20:10,464 DEBUG httpcore.connection close.complete
2024-01-20 15:20:10,464 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 15:20:10,464 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 15:20:10,466 DEBUG openai._base_client Not retrying
2024-01-20 15:20:10,466 DEBUG openai._base_client Re-raising status error
2024-01-20 15:20:10,466 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 15:20:10,479 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 15:20:10,486 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 15:20:10,487 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 15:20:10,488 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 15:20:10,488 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 15:20:10,488 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 15:20:10,488 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 15:20:10,488 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 15:20:11,508 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017E706AA590>
2024-01-20 15:20:11,508 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000017E6C931AC0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 15:20:11,524 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017E706A8B50>
2024-01-20 15:20:11,525 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 15:20:11,525 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 15:20:11,525 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 15:20:11,525 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 15:20:11,525 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 15:20:33,894 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 14:20:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'22940'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9124'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'5.256s'), (b'x-request-id', b'69ec7bd69408f95a0819af3b84ae0aca'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487f4dccc873737-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 15:20:33,895 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 15:20:33,895 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 15:20:33,896 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 15:20:33,896 DEBUG httpcore.http11 response_closed.started
2024-01-20 15:20:33,896 DEBUG httpcore.http11 response_closed.complete
2024-01-20 15:20:33,896 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 15:20:36,597 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 14:20:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'24868'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'8404'), (b'x-ratelimit-reset-requests', b'16.512s'), (b'x-ratelimit-reset-tokens', b'9.57s'), (b'x-request-id', b'4e16e5ea608521b19f5cf745ab0ed581'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8487f4e34b419a24-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 15:20:36,597 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 15:20:36,598 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 15:20:36,598 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 15:20:36,598 DEBUG httpcore.http11 response_closed.started
2024-01-20 15:20:36,598 DEBUG httpcore.http11 response_closed.complete
2024-01-20 15:20:36,598 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 15:21:45,705 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 15:21:45,707 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 15:21:45,943 INFO transcription All nescessary class variables are declared and working!
2024-01-20 15:30:30,672 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 15:30:30,674 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 15:30:30,920 INFO transcription All nescessary class variables are declared and working!
2024-01-20 15:30:39,132 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_d58bf777-72a7-4fc2-b6a4-7934c56c12c8.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 15:30:39,135 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_a945deee-38d0-4492-b1d5-24ec0151ab2a.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 15:30:39,175 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 15:30:39,176 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 15:30:39,261 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002D274FA1CD0>
2024-01-20 15:30:39,261 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000002D274059A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 15:30:39,266 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002D274FA35D0>
2024-01-20 15:30:39,267 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000002D274059A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 15:30:39,287 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002D274FA29D0>
2024-01-20 15:30:39,288 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 15:30:39,288 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 15:30:39,288 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 15:30:39,293 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002D274FA3550>
2024-01-20 15:30:39,293 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 15:30:39,293 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 15:30:39,293 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 15:30:40,017 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 15:30:40,017 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 15:30:50,734 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 14:30:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'9137'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3149c5b7489310296643e99303b7589a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=PImaixczssVWVTPiFnMvAvF4tdOdYcPqh8zdARdjff8-1705761049-1-AT72EzxDbh8LJymD+ftlGElPoznqSSfqwVxYzHr4fOqwVGx80MtyDrtKA7aDDw1GZpxnd2YiFqXsINJRp296gSE=; path=/; expires=Sat, 20-Jan-24 15:00:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=mXX.b27EegglBi3ycA8lEmIw.TjXnxXAhzzJupxu.KA-1705761049301-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84880436bb1c373a-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 15:30:50,736 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 15:30:50,736 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 15:30:50,736 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 15:30:50,737 DEBUG httpcore.http11 response_closed.started
2024-01-20 15:30:50,737 DEBUG httpcore.http11 response_closed.complete
2024-01-20 15:30:50,737 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 15:31:03,791 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 15:31:03,791 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 15:31:06,879 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 14:31:05 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'568'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'80ec65d0105942f30729d7975e9d8806'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.QSo7FUgO2lzS4h7PuK7TyB4KmBwxIykmoDNP1lLSfs-1705761065-1-AfdqBQaZgVWcOoJCPNGV5B7FcpTTKA3OHguNKdC3ug4AcJ6svtYamiQQON5Q8Xo30xy68lwlf2FW6DpmdCvjstM=; path=/; expires=Sat, 20-Jan-24 15:01:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=RsEktno_eF9v1_RwTGWyEp2WZNA3MBw3a8EjHNg3ryE-1705761065446-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84880436ce352bc9-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 15:31:06,880 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 15:31:06,880 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 15:31:06,880 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 15:31:06,880 DEBUG httpcore.http11 response_closed.started
2024-01-20 15:31:06,880 DEBUG httpcore.http11 response_closed.complete
2024-01-20 15:31:06,880 DEBUG httpcore.connection close.started
2024-01-20 15:31:06,880 DEBUG httpcore.connection close.complete
2024-01-20 15:31:06,880 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 15:31:06,881 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 15:31:06,882 DEBUG openai._base_client Not retrying
2024-01-20 15:31:06,882 DEBUG openai._base_client Re-raising status error
2024-01-20 15:31:06,882 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 15:31:06,897 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 15:31:06,903 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 15:31:06,904 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 15:31:06,905 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 15:31:06,905 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 15:31:06,905 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 15:31:06,905 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 15:31:06,905 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 15:31:06,935 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002D274C5E850>
2024-01-20 15:31:06,935 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000002D274059A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 15:31:06,955 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002D27501C8D0>
2024-01-20 15:31:06,955 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 15:31:06,956 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 15:31:06,956 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 15:31:06,956 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 15:31:06,956 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 15:31:25,889 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 14:31:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'18793'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9124'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'5.256s'), (b'x-request-id', b'1b8ae244ec07347b00768e428d0f7a6d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848804e35c7a2bc9-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 15:31:25,890 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 15:31:25,890 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 15:31:25,891 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 15:31:25,891 DEBUG httpcore.http11 response_closed.started
2024-01-20 15:31:25,891 DEBUG httpcore.http11 response_closed.complete
2024-01-20 15:31:25,891 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 15:31:34,272 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 14:31:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'27119'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'8286'), (b'x-ratelimit-reset-requests', b'17.223s'), (b'x-ratelimit-reset-tokens', b'10.281s'), (b'x-request-id', b'b5c0be29e2b60f431bf71338ed051641'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848804e3ad4f916b-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 15:31:34,272 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 15:31:34,272 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 15:31:34,274 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 15:31:34,274 DEBUG httpcore.http11 response_closed.started
2024-01-20 15:31:34,274 DEBUG httpcore.http11 response_closed.complete
2024-01-20 15:31:34,274 DEBUG httpcore.connection close.started
2024-01-20 15:31:34,274 DEBUG httpcore.connection close.complete
2024-01-20 15:31:34,275 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 15:32:56,434 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 15:32:56,436 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 15:32:56,661 INFO transcription All nescessary class variables are declared and working!
2024-01-20 15:33:04,690 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_7ebe3d77-44c2-49a8-a898-9fe48167871a.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 15:33:04,692 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_924ebe4b-56a7-46d6-ade4-c1548d788150.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 15:33:04,733 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 15:33:04,734 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 15:33:04,828 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023278694050>
2024-01-20 15:33:04,828 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000232755681D0>
2024-01-20 15:33:04,828 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000023274A59A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 15:33:04,828 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000023274A59A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 15:33:04,839 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000232786C2950>
2024-01-20 15:33:04,840 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 15:33:04,840 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 15:33:04,840 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 15:33:04,845 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000232786C2410>
2024-01-20 15:33:04,846 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 15:33:04,846 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 15:33:04,846 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 15:33:05,553 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 15:33:05,554 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 15:33:16,680 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 14:33:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'9515'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c83bf910e332f0a5c2926da7d019bf1a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=YVXinE0WHApJoKMVFhpEyFUMbhqNyEaBcqOxb8ViabY-1705761195-1-AfXOjUqqElZroJaKRAmkVoibuy+HcZewKePfE0zgK8WdTwDQBjRxiZAAybihB4NznQfYWpnGxED53qYXqRnv19Q=; path=/; expires=Sat, 20-Jan-24 15:03:15 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=6k3AKaRPYyU5A6mztr1_TZRF0t5AkIbe.EjIOtenSlc-1705761195244-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848807c46b0e906d-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 15:33:16,681 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 15:33:16,682 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 15:33:16,682 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 15:33:16,682 DEBUG httpcore.http11 response_closed.started
2024-01-20 15:33:16,682 DEBUG httpcore.http11 response_closed.complete
2024-01-20 15:33:16,682 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 15:33:28,740 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 15:33:28,741 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 15:33:31,432 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 14:33:29 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'570'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9223c00b7045fc02fbe6002228364d15'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=JROqPkD7ZF6v1VhJ3srxDkBbCy_EVYV08f6jz9CHwFo-1705761209-1-AdZP6fQkDGLlVfXP6jJh7UjcVo6Wl5yqkonKSDss1V9FGPZGBydwqYJ8KHN1+Xbmt+VemihW7+rwc237DzbYpGs=; path=/; expires=Sat, 20-Jan-24 15:03:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=GWcUjzE8cHtJGsGO1468h2kHYnyM1uPdG.qRq_8JlhE-1705761209995-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848807c4595671df-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 15:33:31,432 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 15:33:31,432 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 15:33:31,433 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 15:33:31,433 DEBUG httpcore.http11 response_closed.started
2024-01-20 15:33:31,433 DEBUG httpcore.http11 response_closed.complete
2024-01-20 15:33:31,433 DEBUG httpcore.connection close.started
2024-01-20 15:33:31,433 DEBUG httpcore.connection close.complete
2024-01-20 15:33:31,433 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 15:33:31,433 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 15:33:31,435 DEBUG openai._base_client Not retrying
2024-01-20 15:33:31,435 DEBUG openai._base_client Re-raising status error
2024-01-20 15:33:31,435 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 15:33:31,448 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 15:33:31,456 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 15:33:31,456 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 15:33:31,457 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 15:33:31,457 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 15:33:31,458 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 15:33:31,458 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 15:33:31,458 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 15:33:31,493 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002327873E290>
2024-01-20 15:33:31,493 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000023274A59A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 15:33:31,504 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002327873E6D0>
2024-01-20 15:33:31,504 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 15:33:31,504 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 15:33:31,504 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 15:33:31,504 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 15:33:31,504 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 15:33:44,077 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 14:33:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'12179'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'8312'), (b'x-ratelimit-reset-requests', b'17.069s'), (b'x-ratelimit-reset-tokens', b'10.127s'), (b'x-request-id', b'6c8b574ea4f56e14766429616b743248'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8488086c5d0271df-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 15:33:44,078 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 15:33:44,078 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 15:33:44,078 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 15:33:44,078 DEBUG httpcore.http11 response_closed.started
2024-01-20 15:33:44,078 DEBUG httpcore.http11 response_closed.complete
2024-01-20 15:33:44,079 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 15:33:50,299 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 14:33:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'18585'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9153'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'5.082s'), (b'x-request-id', b'b025a92bd9b5c11ac9239459e1d4bfc5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8488086b0f0d9b82-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 15:33:50,300 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 15:33:50,300 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 15:33:50,300 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 15:33:50,301 DEBUG httpcore.http11 response_closed.started
2024-01-20 15:33:50,301 DEBUG httpcore.http11 response_closed.complete
2024-01-20 15:33:50,301 DEBUG httpcore.connection close.started
2024-01-20 15:33:50,301 DEBUG httpcore.connection close.complete
2024-01-20 15:33:50,301 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 15:36:05,787 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 15:36:05,789 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 15:36:06,019 INFO transcription All nescessary class variables are declared and working!
2024-01-20 15:41:16,268 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 15:41:16,270 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 15:41:16,502 INFO transcription All nescessary class variables are declared and working!
2024-01-20 15:50:40,910 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 15:50:40,912 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 15:50:41,133 INFO transcription All nescessary class variables are declared and working!
2024-01-20 15:51:27,392 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_53080ab5-7496-4103-927b-810aa0c864d5.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 15:51:27,394 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_a908196b-b76b-4145-a9c6-ee89a905a992.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 15:51:27,431 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 15:51:27,433 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 15:51:27,526 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F280A1C610>
2024-01-20 15:51:27,526 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F2FFE716D0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 15:51:27,529 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F28780C1D0>
2024-01-20 15:51:27,529 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F2FFE716D0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 15:51:27,552 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F28780C8D0>
2024-01-20 15:51:27,553 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 15:51:27,553 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F28780C250>
2024-01-20 15:51:27,553 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 15:51:27,554 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 15:51:27,554 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 15:51:27,554 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 15:51:27,554 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 15:51:31,071 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 15:51:31,071 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 15:51:40,654 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 14:51:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'8924'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9a7cf9d44098df1d4cd9c4e37546e77a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=X7PVd813WOJOXhYDfkcp0KNtkI5cwx77092yjWb_r50-1705762299-1-AeY34gdCKZBWxZNnfC6XYQa0YSMivbqXQZYLjq2JslhRjTGZl2qwr1H1KUNDRysFORa257fUaXZ4FNO/Gkw4ibY=; path=/; expires=Sat, 20-Jan-24 15:21:39 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Ulg1X44j6XgXB20RI4UPaxfZeQRYwRa_TxYI9qNVxyM-1705762299197-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848822b03b625da0-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 15:51:40,655 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 15:51:40,656 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 15:51:40,656 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 15:51:40,656 DEBUG httpcore.http11 response_closed.started
2024-01-20 15:51:40,656 DEBUG httpcore.http11 response_closed.complete
2024-01-20 15:51:40,657 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 15:51:54,089 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 15:51:54,089 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 15:51:57,530 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 14:51:56 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'530'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f36922b88490ecfd7ad24f841f26511a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=MaY86wcuqT.9DpQTW7FJyru05ilRtIup8e2pKsRKcxw-1705762316-1-AdKMXgY4fHuYkfVePnTZ1a9nfRxRVuWv7j6icyxTjHZ2RctCILiIg1k3CujYiBRnFnYCS1cX7HGlcGfrZeVMkpQ=; path=/; expires=Sat, 20-Jan-24 15:21:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=aY_4f4Jf9c4dnJ8eco0eDqbRhnokpZPNSdGkTAo6Ts4-1705762316074-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848822b03e826928-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 15:51:57,531 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 15:51:57,531 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 15:51:57,531 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 15:51:57,531 DEBUG httpcore.http11 response_closed.started
2024-01-20 15:51:57,531 DEBUG httpcore.http11 response_closed.complete
2024-01-20 15:51:57,531 DEBUG httpcore.connection close.started
2024-01-20 15:51:57,531 DEBUG httpcore.connection close.complete
2024-01-20 15:51:57,531 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 15:51:57,531 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 15:51:57,534 DEBUG openai._base_client Not retrying
2024-01-20 15:51:57,534 DEBUG openai._base_client Re-raising status error
2024-01-20 15:51:57,534 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 15:51:57,548 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 15:51:57,555 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 15:51:57,555 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 15:51:57,556 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 15:51:57,556 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 15:51:57,556 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 15:51:57,556 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 15:51:57,557 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 15:51:57,595 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F28789E210>
2024-01-20 15:51:57,595 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F2FFE716D0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 15:51:57,608 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F28789E650>
2024-01-20 15:51:57,608 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 15:51:57,609 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 15:51:57,609 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 15:51:57,609 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 15:51:57,609 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 15:52:08,873 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 14:52:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'11127'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9124'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'5.256s'), (b'x-request-id', b'05647365cd4e3545b716744c81f61163'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8488236bbe786928-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 15:52:08,873 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 15:52:08,873 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 15:52:08,874 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 15:52:08,874 DEBUG httpcore.http11 response_closed.started
2024-01-20 15:52:08,874 DEBUG httpcore.http11 response_closed.complete
2024-01-20 15:52:08,875 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 15:52:14,567 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 14:52:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'16763'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'8286'), (b'x-ratelimit-reset-requests', b'17.225s'), (b'x-ratelimit-reset-tokens', b'10.283s'), (b'x-request-id', b'0c4ffe5f3a01074a2797824cb806ed7d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8488236c0fee9b21-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 15:52:14,568 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 15:52:14,568 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 15:52:14,568 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 15:52:14,568 DEBUG httpcore.http11 response_closed.started
2024-01-20 15:52:14,568 DEBUG httpcore.http11 response_closed.complete
2024-01-20 15:52:14,569 DEBUG httpcore.connection close.started
2024-01-20 15:52:14,569 DEBUG httpcore.connection close.complete
2024-01-20 15:52:14,569 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 15:54:27,798 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 15:54:27,800 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 15:54:28,050 INFO transcription All nescessary class variables are declared and working!
2024-01-20 15:54:34,276 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_a61579a7-8713-42f3-a505-504d5a3605a0.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 15:54:34,279 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_f27dd83d-e786-4776-9e52-514ca84ae786.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 15:54:34,317 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 15:54:34,319 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 15:54:34,392 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001807C7DB310>
2024-01-20 15:54:34,393 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001807BBB16D0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 15:54:34,394 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001800381E950>
2024-01-20 15:54:34,394 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001807BBB16D0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 15:54:34,407 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001800381E890>
2024-01-20 15:54:34,407 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 15:54:34,407 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 15:54:34,407 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 15:54:34,413 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001800381ED10>
2024-01-20 15:54:34,413 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 15:54:34,413 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 15:54:34,413 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 15:54:37,477 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 15:54:37,478 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 15:54:47,939 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 14:54:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'9135'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1edc0b6104cb58605915b2f61262769e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=E1FNgXCU2JEtlM1oR.FMUtZiz8Dn7.zAuyRCeDBSQs0-1705762486-1-AR792yjN9KQr46Pc0L8UhvI7Rq5utWQ+k8T3ZyG0TkeXqghNubnR1+FASiYke6XDXioruUmGW9kUc4VYdrAby6M=; path=/; expires=Sat, 20-Jan-24 15:24:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=NR5X1UzKR1Bq1H0jkDHxlAZYlfja5MwYZWhryiksj5w-1705762486479-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848827400f3f30d5-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 15:54:47,941 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 15:54:47,941 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 15:54:47,941 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 15:54:47,941 DEBUG httpcore.http11 response_closed.started
2024-01-20 15:54:47,941 DEBUG httpcore.http11 response_closed.complete
2024-01-20 15:54:47,941 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 15:54:59,728 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 15:54:59,729 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 15:55:03,920 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 14:55:02 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'575'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'66ea5a2b1451382b8b464d6a8607c3ca'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=2ylVYOy7AP94IZnUrzGHGZ7gbQuY2lLeO1Dsxh8K_PU-1705762502-1-AWHVowaBaQaJGSD8Ojr0NtqBWE3kCFS+8HoAusgosWrSB79hBuXpCfT5eTxMtaebU/3N/fYqyqJEG3pg0qPOSy4=; path=/; expires=Sat, 20-Jan-24 15:25:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=A4fhbBuWvvHjf0Cj8Cp8vfKlmRtlt4D1sXAXp5gUJcs-1705762502459-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848827401c078fda-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 15:55:03,921 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 15:55:03,921 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 15:55:03,921 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 15:55:03,921 DEBUG httpcore.http11 response_closed.started
2024-01-20 15:55:03,921 DEBUG httpcore.http11 response_closed.complete
2024-01-20 15:55:03,921 DEBUG httpcore.connection close.started
2024-01-20 15:55:03,922 DEBUG httpcore.connection close.complete
2024-01-20 15:55:03,922 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 15:55:03,922 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 15:55:03,923 DEBUG openai._base_client Not retrying
2024-01-20 15:55:03,923 DEBUG openai._base_client Re-raising status error
2024-01-20 15:55:03,924 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 15:55:03,937 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 15:55:03,945 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 15:55:03,947 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 15:55:03,947 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 15:55:03,948 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 15:55:03,948 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 15:55:03,948 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 15:55:03,948 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 15:55:03,969 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000180038AE490>
2024-01-20 15:55:03,969 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001807BBB16D0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 15:55:03,982 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000180038AE950>
2024-01-20 15:55:03,982 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 15:55:03,982 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 15:55:03,982 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 15:55:03,983 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 15:55:03,983 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 15:55:18,712 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 14:55:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'14557'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9124'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'5.256s'), (b'x-request-id', b'06c8ece79df1caef4e7f7662ba3b8323'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848827f8abed8fda-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 15:55:18,713 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 15:55:18,713 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 15:55:18,713 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 15:55:18,713 DEBUG httpcore.http11 response_closed.started
2024-01-20 15:55:18,713 DEBUG httpcore.http11 response_closed.complete
2024-01-20 15:55:18,713 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 15:55:27,267 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 14:55:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'23076'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'8285'), (b'x-ratelimit-reset-requests', b'17.229s'), (b'x-ratelimit-reset-tokens', b'10.287s'), (b'x-request-id', b'de254304f0cbf27368f67fd2df4f1ea8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848827f8eeeb6969-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 15:55:27,267 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 15:55:27,268 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 15:55:27,268 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 15:55:27,268 DEBUG httpcore.http11 response_closed.started
2024-01-20 15:55:27,269 DEBUG httpcore.http11 response_closed.complete
2024-01-20 15:55:27,269 DEBUG httpcore.connection close.started
2024-01-20 15:55:27,269 DEBUG httpcore.connection close.complete
2024-01-20 15:55:27,269 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 16:04:09,737 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 16:04:09,739 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 16:04:09,973 INFO transcription All nescessary class variables are declared and working!
2024-01-20 16:04:24,271 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_80c10d98-ecca-4e83-b83b-e27f8f60bafa.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 16:04:24,274 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_c910f03d-2e97-4510-a849-08b5afcda4ee.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 16:04:24,314 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 16:04:24,315 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 16:04:24,416 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C9CF502ED0>
2024-01-20 16:04:24,416 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C9CAB399A0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 16:04:24,429 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C9CF4C7C50>
2024-01-20 16:04:24,429 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C9CAB399A0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 16:04:24,439 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C9CF502E50>
2024-01-20 16:04:24,439 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:04:24,440 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:04:24,440 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:04:24,443 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C9CF502890>
2024-01-20 16:04:24,443 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:04:24,443 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:04:24,443 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:04:26,920 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:04:26,920 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:04:36,850 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 15:04:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'9008'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9b2503bf20c79792265ca46acc879151'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=vs3ngubFGlpmVSQNFk_GLldAO7n9v8HxdbR23md66yU-1705763075-1-AX6VcYE4uoWl3Omt6EGW34D0wxgQmw/d7pZ3raB92L8/1+WsS4aq+6YZGwjxudHcDYv2TVh95sP1zgAx8BwzkP8=; path=/; expires=Sat, 20-Jan-24 15:34:35 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=_CYpodVSLi.XvDSfA7goFbzIq.L1XaetnRLDPH_bA2I-1705763075378-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848835a7b96fbb47-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:04:36,852 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 16:04:36,852 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:04:36,852 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:04:36,853 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:04:36,853 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:04:36,853 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 16:04:50,135 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:04:50,135 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:04:53,488 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 15:04:52 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'690'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9a180e7de3662bd2f9103892509deb59'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=OBfChnFOUmzm8DLHb2HGNE6ZlUQbzN7FsJSEGBTvdK8-1705763092-1-AbUjl1z/ogkyG+evFjpVsqInpc7eRnfuI9Q33HX240buay+dZhaj5S2vcWSZE+1xkEHoA549HQzQt7/ZWewF9cw=; path=/; expires=Sat, 20-Jan-24 15:34:52 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=JN8YB8HRv6u6XNMAvm9eFL64vMb4GFrDDS6hnCDHGBQ-1705763092016-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848835a7aa0e3a5e-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:04:53,488 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 16:04:53,488 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:04:53,489 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:04:53,489 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:04:53,489 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:04:53,489 DEBUG httpcore.connection close.started
2024-01-20 16:04:53,489 DEBUG httpcore.connection close.complete
2024-01-20 16:04:53,489 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 16:04:53,489 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 16:04:53,491 DEBUG openai._base_client Not retrying
2024-01-20 16:04:53,491 DEBUG openai._base_client Re-raising status error
2024-01-20 16:04:53,491 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 16:04:53,503 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 16:04:53,506 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:04:53,507 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:04:53,507 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:04:53,507 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:04:53,507 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:05:39,491 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 16:05:39,493 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 16:05:39,729 INFO transcription All nescessary class variables are declared and working!
2024-01-20 16:05:47,286 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_90a15f25-2cd4-4fe8-a64d-ccc387b4382a.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 16:05:47,289 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_ff9b4172-e23b-42f5-867a-286b0b92c3b0.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 16:05:47,331 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 16:05:47,332 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 16:05:47,430 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000245EA4B9E10>
2024-01-20 16:05:47,430 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000245E67F99A0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 16:05:47,447 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000245EA4E9350>
2024-01-20 16:05:47,447 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:05:47,447 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:05:47,447 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:05:47,452 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000245E740C110>
2024-01-20 16:05:47,452 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000245E67F99A0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 16:05:47,471 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000245EA4EA110>
2024-01-20 16:05:47,471 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:05:47,471 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:05:47,471 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:05:51,567 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:05:51,567 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:06:01,588 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 15:06:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'9051'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'aedc5fa2281f5acf04dbb24622951619'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=eWpLutF8MC2PKuDCL9or.7C6qmirxeyfx4qteE.644c-1705763160-1-AeXU4bgqHEwc9i7ni5objtAFILD2Rzom5FLUF9GaviP19wW1F+BRuPNVhEybegngnNJP7qomHj1ZS4soO9irPGI=; path=/; expires=Sat, 20-Jan-24 15:36:00 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=yky7gag0qwkOnRdnZYwEGoVBDoGA73oSJ779H1qZL9g-1705763160115-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848837ae9aee9195-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:06:01,590 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 16:06:01,590 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:06:01,590 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:06:01,591 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:06:01,591 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:06:01,591 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 16:06:10,283 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:06:10,284 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:06:14,032 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 15:06:12 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'947'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2fb983c51e67bb4f23d46cdf7c194c3c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=GtoNgiVpw_.yPJjKDRgeSzsH0OzioT_RhkuaXf5nNg4-1705763172-1-Abldn6kVik046kiubY6SrX9dj6Wgbbxo2ZeC7QKmuBwi0txs7igvw1r/VYvimHTJ2Lu3ihXWjAttrN81Bj53OFw=; path=/; expires=Sat, 20-Jan-24 15:36:12 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=1SJhuupcvGusjVC5ezOuNqGXRwt38JHrToIp6mB.aT4-1705763172559-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848837ae7e189174-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:06:14,033 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 16:06:14,033 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:06:14,033 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:06:14,033 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:06:14,033 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:06:14,034 DEBUG httpcore.connection close.started
2024-01-20 16:06:14,034 DEBUG httpcore.connection close.complete
2024-01-20 16:06:14,034 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 16:06:14,034 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 16:06:14,035 DEBUG openai._base_client Not retrying
2024-01-20 16:06:14,035 DEBUG openai._base_client Re-raising status error
2024-01-20 16:06:14,036 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 16:06:14,048 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 16:06:14,050 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:06:14,055 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 16:06:14,056 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 16:06:14,056 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:06:14,056 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:06:14,057 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:06:14,057 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:06:14,091 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000245E740C110>
2024-01-20 16:06:14,091 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000245E67F99A0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 16:06:14,109 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000245EA4ED210>
2024-01-20 16:06:14,109 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:06:14,109 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:06:14,109 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:06:14,110 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:06:14,110 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:06:25,427 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 15:06:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'11170'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9124'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'5.256s'), (b'x-request-id', b'09663b9af15b8fd9f172571ce2a63745'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84883854cac39174-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:06:25,429 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 16:06:25,429 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:06:25,429 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:06:25,429 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:06:25,430 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:06:25,430 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 16:06:27,254 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 15:06:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'12922'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'8288'), (b'x-ratelimit-reset-requests', b'17.208s'), (b'x-ratelimit-reset-tokens', b'10.266s'), (b'x-request-id', b'578c9590ec078e5aa78267165aa6623b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848838550f1f03a0-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:06:27,254 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 16:06:27,254 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:06:27,256 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:06:27,256 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:06:27,256 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:06:27,256 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 16:14:44,018 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 16:14:44,019 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 16:14:44,252 INFO transcription All nescessary class variables are declared and working!
2024-01-20 16:16:31,376 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_24b48513-800a-49dc-a1ae-0250f84c65e6.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 16:16:31,379 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_6e3a2d91-103d-46c2-b691-d3bb9ce9a9d6.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 16:16:31,427 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 16:16:31,428 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 16:16:31,517 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DB9A0492D0>
2024-01-20 16:16:31,517 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DBFE8759A0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 16:16:31,537 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DB9A048650>
2024-01-20 16:16:31,537 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:16:31,538 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:16:31,538 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:16:31,543 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DB9A049150>
2024-01-20 16:16:31,543 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DBFE8759A0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 16:16:31,561 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DB9A049910>
2024-01-20 16:16:31,561 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:16:31,561 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:16:31,561 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:16:33,293 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:16:33,293 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:16:43,901 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 15:16:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'8942'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'557eb8ffba13d610911ae26a4224870e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=5tE.hloemHaGl.0g1mr761ltGXmN8wSvpTSTLyuoPMA-1705763802-1-Abjd93Yz4K6CiACYi/gbnaicnAFKRI9b4G8v4/5Dz3n8BQbGzXi7rpX6bHI9pTpeMlevB2lk7OfadNnSkAajsHY=; path=/; expires=Sat, 20-Jan-24 15:46:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=I7wCXCbBBp9bRXPW0fXlGNgp8HIJiTcrhwl8dx3_.FE-1705763802415-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848847681bda04a3-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:16:43,902 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 16:16:43,903 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:16:43,903 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:16:43,903 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:16:43,903 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:16:43,903 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 16:16:56,222 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:16:56,222 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:16:59,826 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 15:16:58 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'581'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e850cace5eaca586a2485977c62d6483'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=1vnDccOq.MDg7KlzcuIR0gU6nTEttK5dW3Gt.9PPGBs-1705763818-1-ASAayqZe6+3WsXSdHVCh0PuhZ+xAjhaH6DYdmAKXCuUmBtTHjJlxBTZY5EvvgJe+oP6B6Ub0nUHf18r7y60phOg=; path=/; expires=Sat, 20-Jan-24 15:46:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=.KmVp9Gsf6vb6G_isnuEqqp0Uo0UHrLBtpzBljWq9HI-1705763818340-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848847680d3f18e0-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:16:59,826 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 16:16:59,827 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:16:59,827 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:16:59,827 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:16:59,827 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:16:59,827 DEBUG httpcore.connection close.started
2024-01-20 16:16:59,827 DEBUG httpcore.connection close.complete
2024-01-20 16:16:59,827 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 16:16:59,828 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 16:16:59,829 DEBUG openai._base_client Not retrying
2024-01-20 16:16:59,829 DEBUG openai._base_client Re-raising status error
2024-01-20 16:16:59,829 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 16:16:59,843 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 16:16:59,849 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 16:16:59,850 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:16:59,851 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 16:16:59,851 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:16:59,851 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:16:59,851 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:16:59,851 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:16:59,876 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DB9A04D290>
2024-01-20 16:16:59,876 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DBFE8759A0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 16:16:59,898 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DB9A0CDC90>
2024-01-20 16:16:59,898 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:16:59,898 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:16:59,898 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:16:59,899 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:16:59,899 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:17:15,811 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 15:17:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'15753'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9124'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'5.256s'), (b'x-request-id', b'04cabef52f1bb60420d85951b8889c22'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84884818fdd518e0-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:17:15,812 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 16:17:15,812 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:17:15,812 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:17:15,812 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:17:15,812 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:17:15,812 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 16:17:19,899 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 15:17:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'19775'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'8286'), (b'x-ratelimit-reset-requests', b'17.224s'), (b'x-ratelimit-reset-tokens', b'10.282s'), (b'x-request-id', b'829784026c3dbf073b602ba6cb591aec'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848848194fa21c38-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:17:19,899 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 16:17:19,900 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:17:19,900 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:17:19,900 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:17:19,900 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:17:19,900 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 16:28:15,232 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 16:28:15,234 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 16:28:15,463 INFO transcription All nescessary class variables are declared and working!
2024-01-20 16:28:23,273 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_06d9429d-7612-4ec5-a73f-21bfece6b177.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 16:28:23,276 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_5da5ce8d-e80f-4faa-bc4c-e692193bb30a.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 16:28:23,317 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 16:28:23,318 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 16:28:23,419 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000026B785FF8D0>
2024-01-20 16:28:23,420 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000026B779D59A0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 16:28:23,420 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000026B003B2750>
2024-01-20 16:28:23,421 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000026B779D59A0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 16:28:23,443 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000026B003B2C50>
2024-01-20 16:28:23,443 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:28:23,444 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000026B003B31D0>
2024-01-20 16:28:23,444 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:28:23,444 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:28:23,444 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:28:23,445 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:28:23,445 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:28:26,388 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:28:26,388 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:28:36,822 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 15:28:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'9571'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'353f4c033fa10bcbea4dd7ad8485d113'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=WFeVI1PgBDViA2O5wQisnQOt4DVtBoSGdw3eWwfp63s-1705764515-1-AZM6VFE03krvQ2C+eciqzycNdS7fDrILTFMIDgT85HPqrfsP3+YEKuquALkvNhTdpdz07tIFzJ/rhXERyfhjTG0=; path=/; expires=Sat, 20-Jan-24 15:58:35 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=SZHSKo8tkuhrTQgDhfkkCI6kMNcFz8NsefeQbaM3hkE-1705764515323-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848858c94c8f1e62-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:28:36,823 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 16:28:36,824 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:28:36,824 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:28:36,824 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:28:36,824 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:28:36,825 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 16:28:48,034 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:28:48,034 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:28:50,649 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 15:28:49 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'592'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6211f4204bc3699aeb1fa717abaee0a9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=6MhPKYxiCLNv3BwyKNon.A2lD2Pf1WeKouKXUpvtkXA-1705764529-1-AbJ9CJSLiRXUgoRrSrWGsXJoGovsNFpOLe+BH76ZBe3cl0/VLKEp6I/1kT7/38MLzxAs/iLclhHhew/0CGOUbZk=; path=/; expires=Sat, 20-Jan-24 15:58:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Ualoxn1WTXraIs5T6ZPPDW.saABcNKkXI4.UYErLR6A-1705764529150-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848858c948871c3e-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:28:50,650 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 16:28:50,650 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:28:50,651 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:28:50,651 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:28:50,651 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:28:50,651 DEBUG httpcore.connection close.started
2024-01-20 16:28:50,651 DEBUG httpcore.connection close.complete
2024-01-20 16:28:50,651 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 16:28:50,651 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 16:28:50,653 DEBUG openai._base_client Not retrying
2024-01-20 16:28:50,653 DEBUG openai._base_client Re-raising status error
2024-01-20 16:28:50,653 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 16:31:04,217 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 16:31:04,218 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 16:31:04,440 INFO transcription All nescessary class variables are declared and working!
2024-01-20 16:31:24,203 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_00af73fc-361d-4345-98fc-0910b425d70e.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 16:31:24,206 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_df0283ac-8f59-4823-a3d1-1a12ae9e7218.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 16:31:24,244 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 16:31:24,246 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 16:31:24,374 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000221C8C5B950>
2024-01-20 16:31:24,374 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000221C8C3C190>
2024-01-20 16:31:24,375 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000221C80219A0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 16:31:24,375 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000221C80219A0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 16:31:24,398 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000221CF610510>
2024-01-20 16:31:24,398 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:31:24,399 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:31:24,399 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:31:24,401 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000221CF610950>
2024-01-20 16:31:24,401 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:31:24,401 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:31:24,401 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:31:27,150 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:31:27,150 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:31:37,193 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 15:31:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'8870'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'44f559b80b5e77bbb13c3ebc215d3650'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=IrvH3.YHvXa7O.2Rf4EVy4mFW3jdijBHB3LltVCQbbU-1705764695-1-ARUxIbBHA2Wiq+tEeHlB4K4pByBbSh1tgUrZuUnQD62BF1BEHTMKVfaGLjfXlF4LVsQKXHjD2x+UcHXQOw3liVw=; path=/; expires=Sat, 20-Jan-24 16:01:35 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=IU1.rNUElykzA6EdTHDcxxfj_ka57lcmHAvvHRiYnKw-1705764695690-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84885d34390d8ff4-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:31:37,195 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 16:31:37,195 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:31:37,195 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:31:37,195 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:31:37,196 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:31:37,196 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 16:31:48,008 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:31:48,008 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:31:51,634 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 15:31:50 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'553'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1330682d8da877493f3187fb9f4613e8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=mBT9jtnT1Zg2J7AM7UL81uwu405oBSh2RToEYbgNJKE-1705764710-1-AddnDuRLMHy8YY1iQev0F1cd2DufHjTKy8VAbR+y8u+lyp1lIgNB0qFFy4bARXwnlaVDfTQ6auvLJjj94Gy35Uo=; path=/; expires=Sat, 20-Jan-24 16:01:50 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=0_LvWjZj_5EusHSywjoaauYHQRpp3qo7aQtVi4x5AYE-1705764710131-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84885d343bf318e9-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:31:51,634 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 16:31:51,634 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:31:51,635 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:31:51,635 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:31:51,635 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:31:51,635 DEBUG httpcore.connection close.started
2024-01-20 16:31:51,635 DEBUG httpcore.connection close.complete
2024-01-20 16:31:51,635 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 16:31:51,635 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 16:31:51,637 DEBUG openai._base_client Not retrying
2024-01-20 16:31:51,637 DEBUG openai._base_client Re-raising status error
2024-01-20 16:31:51,637 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 16:32:47,826 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 16:32:47,828 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 16:32:48,051 INFO transcription All nescessary class variables are declared and working!
2024-01-20 16:33:27,480 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_4097c31c-6fdc-4d85-a132-4c28b9abea24.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 16:33:27,482 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_c9833eea-01b8-470e-9abc-3b1b6bfc4d5f.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 16:33:27,525 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 16:33:27,525 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 16:33:27,620 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000176638C7E90>
2024-01-20 16:33:27,620 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001765C3059A0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 16:33:27,621 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000176638C4150>
2024-01-20 16:33:27,622 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001765C3059A0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 16:33:27,644 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000176638F92D0>
2024-01-20 16:33:27,645 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:33:27,645 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000176638F9B50>
2024-01-20 16:33:27,645 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:33:27,645 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:33:27,646 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:33:27,646 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:33:27,646 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:33:29,818 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:33:29,819 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:33:40,057 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 15:33:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'8868'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ad353281eec2310912de7f5836254d15'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=PhYMNuDQuJudB7qsbfbwVh94GYOa2Bu3F8kYYSd81N0-1705764818-1-AYZ9w9n8zidXN5exbt26R4E728Xu9Ay99w2m7vgbsZM5D62709rksdmE2mTKxfsS0FEneMCHcWDl4qcjuM0vOKY=; path=/; expires=Sat, 20-Jan-24 16:03:38 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=KnQx7xrOG1mJyVdcxdJ0CJVGQ.EG.vtfVUT0OfSSh1Y-1705764818552-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848860367c849180-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:33:40,059 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 16:33:40,059 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:33:40,059 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:33:40,060 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:33:40,060 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:33:40,060 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 16:33:53,150 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:33:53,150 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:33:56,684 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 15:33:55 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'614'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'eada02f2c78a94461105de49b6e4006b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=pUHX31hLCWV3oFLP3RAHBlWx14I9cfkMTiwKMjXmPcU-1705764835-1-AQu69TmJZz7AEMcbHWUyNjCvKxJNAsp398UTx3phlwEP7xbsvgjKv4zm/cr90tg+IK3x5rB3FnDEqNcdDMF7HBc=; path=/; expires=Sat, 20-Jan-24 16:03:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=CeCWNDlXrCT35gx6IIkdoqOT9GLLCrzfYVDejciu0yM-1705764835179-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848860367deb5d49-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:33:56,685 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 16:33:56,685 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:33:56,685 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:33:56,685 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:33:56,685 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:33:56,685 DEBUG httpcore.connection close.started
2024-01-20 16:33:56,685 DEBUG httpcore.connection close.complete
2024-01-20 16:33:56,685 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 16:33:56,686 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 16:33:56,687 DEBUG openai._base_client Not retrying
2024-01-20 16:33:56,687 DEBUG openai._base_client Re-raising status error
2024-01-20 16:33:56,687 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 16:33:56,700 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 16:33:56,707 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 16:33:56,708 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:33:56,708 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 16:33:56,709 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:33:56,709 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:33:56,709 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:33:56,709 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:33:56,728 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001766397A7D0>
2024-01-20 16:33:56,728 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001765C3059A0> server_hostname='api.openai.com' timeout=5.0
2024-01-20 16:33:56,754 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001766397AB90>
2024-01-20 16:33:56,755 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:33:56,755 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:33:56,755 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:33:56,755 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:33:56,755 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:34:15,006 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 15:34:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'18084'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9124'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'5.256s'), (b'x-request-id', b'0fc7f207591c7e372617f4ba43be0fe3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848860ec2fd85d49-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:34:15,007 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 16:34:15,007 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:34:15,008 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:34:15,008 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:34:15,008 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:34:15,008 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 16:34:17,479 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 15:34:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'20518'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'8282'), (b'x-ratelimit-reset-requests', b'17.244s'), (b'x-ratelimit-reset-tokens', b'10.302s'), (b'x-request-id', b'1f836aebf82c136fe7e521048b5b1909'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848860ec6e655d6f-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:34:17,479 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 16:34:17,480 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:34:17,480 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:34:17,480 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:34:17,480 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:34:17,480 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 16:44:19,474 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 16:44:19,475 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 16:44:19,715 INFO transcription All nescessary class variables are declared and working!
2024-01-20 16:44:25,463 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_d5a0a547-1a57-4083-9deb-f14e113dfee0.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 16:44:25,466 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_aacc148f-b096-48d3-b73e-c72ac5cc0bc5.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 16:44:25,504 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 16:44:25,506 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 16:44:25,591 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002069B4C7DD0>
2024-01-20 16:44:25,591 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000206FFA4D760> server_hostname='api.openai.com' timeout=5.0
2024-01-20 16:44:25,598 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002069B4ECA50>
2024-01-20 16:44:25,599 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000206FFA4D760> server_hostname='api.openai.com' timeout=5.0
2024-01-20 16:44:25,617 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002069B4EC490>
2024-01-20 16:44:25,617 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:44:25,618 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:44:25,618 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:44:25,623 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002069B4EC610>
2024-01-20 16:44:25,623 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:44:25,623 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:44:25,623 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:44:27,781 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:44:27,781 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:44:38,179 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 15:44:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'9022'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e71e873601960930d3987f10dbaf512b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=vNhv.m8MIGqzFLvV_4P7uiqvWXW9fdC0K2lQTZ0XAxk-1705765476-1-Ac8D5/N4+9F1w/q4itkjcJ8tVwUXoma/bG7zY+Hfp49PC0u+OtA5v4RlpXhGfY9y0Rlg5unUf7HoUpzXG1WrqEk=; path=/; expires=Sat, 20-Jan-24 16:14:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=rYv0f.5YKMgHZ5q4bZhWAya4cw1TRVqkjmIn.uAhyXo-1705765476661-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84887046ce4392b7-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:44:38,180 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 16:44:38,181 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:44:38,181 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:44:38,181 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:44:38,181 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:44:38,182 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 16:44:51,149 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:44:51,150 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:44:53,838 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 15:44:52 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'641'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8618e8213703853771b3e5045131e53a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=cOVcgRuOqU4tO2Vby0AtylR_KlBq4FCUU215IopxDHM-1705765492-1-AUsiXYyLqopcXF+7Tbhtak7Pmp6MQnfxnP1na5aAMbLxccY5Yq8A/hYFXWMR7rEbYtxkWt8Db/0d0sIMYiHFaZg=; path=/; expires=Sat, 20-Jan-24 16:14:52 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=3Y7x83gflNDl_JNY5ET920t0i6bG2NQ6_3Y2Q.QJYws-1705765492318-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'84887046bdab5c92-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:44:53,839 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 16:44:53,839 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:44:53,839 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:44:53,840 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:44:53,840 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:44:53,840 DEBUG httpcore.connection close.started
2024-01-20 16:44:53,840 DEBUG httpcore.connection close.complete
2024-01-20 16:44:53,840 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 16:44:53,840 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 16:44:53,842 DEBUG openai._base_client Not retrying
2024-01-20 16:44:53,842 DEBUG openai._base_client Re-raising status error
2024-01-20 16:44:53,843 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 16:47:13,065 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 16:47:13,067 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 16:47:13,303 INFO transcription All nescessary class variables are declared and working!
2024-01-20 16:47:18,183 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_958bf560-4e91-42f6-9450-fc6060d57bfd.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 16:47:18,186 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_9c215aa5-983b-4087-b6fb-22cb375ab5bb.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 16:47:18,223 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 16:47:18,225 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 16:47:18,308 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001497EFAC610>
2024-01-20 16:47:18,308 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001497E379A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 16:47:18,313 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001497EFBBF90>
2024-01-20 16:47:18,313 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001497E379A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 16:47:18,325 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001492D980590>
2024-01-20 16:47:18,325 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:47:18,326 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:47:18,326 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:47:18,336 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001492D980850>
2024-01-20 16:47:18,336 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 16:47:18,336 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 16:47:18,336 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 16:47:21,273 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:47:21,273 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:47:31,463 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 15:47:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'8905'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'dc43397daeca9485e517ac14464e5adc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=QPJvOUDsvWfMbvzo3O6B6QhMGvCokiy2d7_6NGLw03g-1705765649-1-AclN7zxkr7zEpy3kp4yPR6uSWZqkDvK7e/il8rHUp8otZy7H/Y8ktmIPdZ1+zAHgMOljn4G8iwVdkh9UTMo1jJM=; path=/; expires=Sat, 20-Jan-24 16:17:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=AYOLNoUr5zRQjAS6wwyXc3n9RBlScBwZ99UjBdR8yws-1705765649942-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8488747e29981e5a-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:47:31,465 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 16:47:31,465 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:47:31,465 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:47:31,465 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:47:31,466 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:47:31,466 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 16:47:42,394 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 16:47:42,395 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 16:47:45,452 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 15:47:43 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'555'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ef4f33352654d1f70d5da19ae57cf9fd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Kw.oLo83nh7uk1uKltfXOk16QtjouHaTCc8xVXJX6B4-1705765663-1-ATDeFYr50Q5o2jx5W6WkKxpPJm5HHTd1CQZMj92UkEkepqoQZ4UdiTMQq9AN4JbGiM3Dc4N8YFLR6W1xSZC+3JI=; path=/; expires=Sat, 20-Jan-24 16:17:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=K8dZICTD7NMm19R0LThobopj6FK_6lbsfIWKGEzg948-1705765663931-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8488747e2c3e91de-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 16:47:45,453 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 16:47:45,453 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 16:47:45,453 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 16:47:45,453 DEBUG httpcore.http11 response_closed.started
2024-01-20 16:47:45,453 DEBUG httpcore.http11 response_closed.complete
2024-01-20 16:47:45,453 DEBUG httpcore.connection close.started
2024-01-20 16:47:45,453 DEBUG httpcore.connection close.complete
2024-01-20 16:47:45,454 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 16:47:45,454 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 16:47:45,455 DEBUG openai._base_client Not retrying
2024-01-20 16:47:45,455 DEBUG openai._base_client Re-raising status error
2024-01-20 16:47:45,456 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 21:36:41,952 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 21:36:41,965 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 21:36:42,256 INFO transcription All nescessary class variables are declared and working!
2024-01-20 21:36:48,296 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_a504672c-35d1-4420-b061-4d7e4ea7110c.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 21:36:48,299 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_7c3f16c8-46a0-4286-b16a-0d0513a4468b.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 21:36:48,344 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 21:36:48,346 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 21:36:48,434 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6E764C3D0>
2024-01-20 21:36:48,434 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F6E00DD760> server_hostname='api.openai.com' timeout=5.0
2024-01-20 21:36:48,443 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6E764C790>
2024-01-20 21:36:48,443 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F6E00DD760> server_hostname='api.openai.com' timeout=5.0
2024-01-20 21:36:48,461 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6E764C690>
2024-01-20 21:36:48,461 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:36:48,462 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 21:36:48,462 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 21:36:48,464 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F6E764C290>
2024-01-20 21:36:48,464 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:36:48,464 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 21:36:48,465 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 21:36:49,982 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 21:36:49,982 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:37:01,138 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 20:36:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'9103'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4fd3043d2e271bf7f0ecf643985b3e0e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=8XRNXxYtjtYDEZsJBDhB0NXNhhpjiqJgVXBXvPmYRXA-1705783019-1-AWs0N1nH891oK//ce0YVI40wGTEnzs6V2JUis3b6ku45oQqlgiSI2K7FFkUWBUM9Q1tgpUSNIVVu2fS8uLxjuN8=; path=/; expires=Sat, 20-Jan-24 21:06:59 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=9uakH4EEIApRgzlRCad3_MpIquuILPz88dnLNjP7efI-1705783019296-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848a1c8f88109116-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:37:01,140 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 21:37:01,140 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:37:01,141 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 21:37:01,141 DEBUG httpcore.http11 response_closed.started
2024-01-20 21:37:01,141 DEBUG httpcore.http11 response_closed.complete
2024-01-20 21:37:01,141 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 21:37:12,234 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 21:37:12,234 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:37:15,742 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 20:37:13 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'594'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5a7d28befe9958a81ef11e853927f08f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Mytc3Ac87eIAw74KZF8bctidTSjgsOEyNwJH1Bqpq0g-1705783033-1-AUIKqebSMW18mIUkLkg7RIXz8b5hkqMCA8w3IU/aMtFqUyzwGjN12gF3Zbu6NfXsOZxEQU7Olb9ZCeL6AVhb1z0=; path=/; expires=Sat, 20-Jan-24 21:07:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=GV56MPfvByRnz5cx19Qm85kFhCR5_R3GGW0BkmtLxIw-1705783033900-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848a1c8f7c909b67-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:37:15,743 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 21:37:15,743 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:37:15,743 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 21:37:15,743 DEBUG httpcore.http11 response_closed.started
2024-01-20 21:37:15,743 DEBUG httpcore.http11 response_closed.complete
2024-01-20 21:37:15,743 DEBUG httpcore.connection close.started
2024-01-20 21:37:15,744 DEBUG httpcore.connection close.complete
2024-01-20 21:37:15,744 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 21:37:15,744 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 21:37:15,746 DEBUG openai._base_client Not retrying
2024-01-20 21:37:15,746 DEBUG openai._base_client Re-raising status error
2024-01-20 21:37:15,747 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 21:38:21,496 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 21:38:21,498 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 21:38:21,740 INFO transcription All nescessary class variables are declared and working!
2024-01-20 21:38:28,211 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_02b0ac0b-d8b9-4cdf-bb40-6c2e4d949ab6.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 21:38:28,214 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_f67bdb34-cc4c-4db5-a51c-f0c1f00fad5d.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 21:38:28,254 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 21:38:28,257 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 21:38:28,331 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027406B032D0>
2024-01-20 21:38:28,331 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000002747FD29A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 21:38:28,342 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027406B39F90>
2024-01-20 21:38:28,342 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:38:28,343 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 21:38:28,343 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 21:38:28,359 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027406B00990>
2024-01-20 21:38:28,359 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000002747FD29A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 21:38:28,373 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027406B3B050>
2024-01-20 21:38:28,373 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:38:28,374 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 21:38:28,374 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 21:38:30,396 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 21:38:30,396 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:38:40,926 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 20:38:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'9081'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a774c12784c1780d72db3b96fdd14498'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=XthsKfIUMDdtok1AWJR_5uC7OIqdku3S_EV9lnJKPHI-1705783119-1-AdskD7Feh+BWCYChiXI/deiuwFCzwUDjd4O2277lOn7nzZ7O6NZ2yGYCVL3xAoBwe+kJf/yA/HwD6DSnu+Venz4=; path=/; expires=Sat, 20-Jan-24 21:08:39 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=_xzE8VMy04VghaPO4u.qNTh3Oo2WXJUDCJ4QHfMPkPM-1705783119081-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848a1effeed591d5-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:38:40,927 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 21:38:40,928 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:38:40,928 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 21:38:40,928 DEBUG httpcore.http11 response_closed.started
2024-01-20 21:38:40,928 DEBUG httpcore.http11 response_closed.complete
2024-01-20 21:38:40,929 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 21:38:53,072 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 21:38:53,072 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:38:55,698 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 20:38:53 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'623'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6b882946b5d047f2aae0cec0cdcb5b71'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=gCWqKNjPHri9xcYjn.d9mOcZ.qEBEd0bXASxulSCrkg-1705783133-1-AX8ttty27Bh3SCXWZi6k3IU3vYnsBc1MThKFWx/IaPCFPWJtMlA6tpIUQ6KSG419eokKBzPHw8kYmEq/2G/YPrM=; path=/; expires=Sat, 20-Jan-24 21:08:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=g1dwdy3agC9QG5QNJJD2PRqyVgAB0mP.Ay5G9y2IIzk-1705783133853-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848a1effbc595b50-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:38:55,699 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 21:38:55,699 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:38:55,699 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 21:38:55,699 DEBUG httpcore.http11 response_closed.started
2024-01-20 21:38:55,699 DEBUG httpcore.http11 response_closed.complete
2024-01-20 21:38:55,699 DEBUG httpcore.connection close.started
2024-01-20 21:38:55,700 DEBUG httpcore.connection close.complete
2024-01-20 21:38:55,700 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 21:38:55,700 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 21:38:55,701 DEBUG openai._base_client Not retrying
2024-01-20 21:38:55,701 DEBUG openai._base_client Re-raising status error
2024-01-20 21:38:55,702 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 21:39:41,514 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 21:39:41,516 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 21:39:41,753 INFO transcription All nescessary class variables are declared and working!
2024-01-20 21:40:17,101 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 21:40:17,103 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 21:40:17,329 INFO transcription All nescessary class variables are declared and working!
2024-01-20 21:40:54,171 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_7d9ee943-9e74-45c5-a997-d60e367bd319.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 21:40:54,173 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_f1abb50b-4216-49e4-a6d9-4b0b9c237e39.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 21:40:54,208 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 21:40:54,213 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 21:40:54,302 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025673D98210>
2024-01-20 21:40:54,302 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256729FD760> server_hostname='api.openai.com' timeout=5.0
2024-01-20 21:40:54,321 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025673D9AF50>
2024-01-20 21:40:54,321 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x00000256729FD760> server_hostname='api.openai.com' timeout=5.0
2024-01-20 21:40:54,326 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025673DCEE10>
2024-01-20 21:40:54,326 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:40:54,327 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 21:40:54,327 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 21:40:54,334 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025673DCED10>
2024-01-20 21:40:54,334 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:40:54,334 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 21:40:54,334 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 21:40:56,838 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 21:40:56,839 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:41:51,025 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 21:41:51,026 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 21:41:51,255 INFO transcription All nescessary class variables are declared and working!
2024-01-20 21:42:11,243 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_91830dbf-4dc0-4f19-a6a2-821c0a166c6b.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 21:42:11,246 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_4311b424-06c8-46e4-b317-64791aecf5e6.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 21:42:11,285 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 21:42:11,286 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 21:42:11,390 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B9A0403450>
2024-01-20 21:42:11,390 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B9FF60D760> server_hostname='api.openai.com' timeout=5.0
2024-01-20 21:42:11,392 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B9A04008D0>
2024-01-20 21:42:11,392 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B9FF60D760> server_hostname='api.openai.com' timeout=5.0
2024-01-20 21:42:11,414 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B9A0449450>
2024-01-20 21:42:11,414 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B9A044A350>
2024-01-20 21:42:11,414 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:42:11,414 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:42:11,415 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 21:42:11,415 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 21:42:11,415 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 21:42:11,415 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 21:42:13,609 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 21:42:13,610 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:42:23,371 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 20:42:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'9095'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f7293676e45150231b89aa120d12b63c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=i5.DYo44MXbybfz2TIdqpLMyeoXKEEYPVq11rJuY2Lo-1705783341-1-AatImmlomrKBeu7yNuEJ7AirMjt51Baf/RUSdTRnTUfL6VP6BaHzI/LDtgPtg4b5G62kMNY1FCxIcTKShMymZZo=; path=/; expires=Sat, 20-Jan-24 21:12:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=fpshKjqjjhzSDpHblIrz28fvY0fbpzmUBuhVH0tJ8L4-1705783341523-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848a2471efa06913-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:42:23,372 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 21:42:23,373 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:42:23,373 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 21:42:23,373 DEBUG httpcore.http11 response_closed.started
2024-01-20 21:42:23,373 DEBUG httpcore.http11 response_closed.complete
2024-01-20 21:42:23,374 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 21:42:33,500 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 21:42:33,500 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:42:36,456 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 20:42:34 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'535'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'278f7363f98edd151c9018b884e7cc4b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=cT2xkvpjGYNmLiWIJub5WNW_vUtMoqHdOgZj0pCnCN0-1705783354-1-AcKkF9Hkwb8gNNjfO5EqWrI0FHNrQBdYIcxTm13+P6ymRBvpcnUxtVlJlcGA1RISK3CZt7I6/QQpgbJcwBPPR74=; path=/; expires=Sat, 20-Jan-24 21:12:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=l8xOZmr16i.aBUpDOuXV1crYhzR.TcKLSUv9rVdLkn4-1705783354607-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848a2471e9f01c26-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:42:36,457 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 21:42:36,457 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:42:36,457 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 21:42:36,457 DEBUG httpcore.http11 response_closed.started
2024-01-20 21:42:36,457 DEBUG httpcore.http11 response_closed.complete
2024-01-20 21:42:36,457 DEBUG httpcore.connection close.started
2024-01-20 21:42:36,457 DEBUG httpcore.connection close.complete
2024-01-20 21:42:36,457 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 21:42:36,458 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 21:42:36,459 DEBUG openai._base_client Not retrying
2024-01-20 21:42:36,459 DEBUG openai._base_client Re-raising status error
2024-01-20 21:42:36,460 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 21:43:36,521 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 21:43:36,522 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 21:43:36,769 INFO transcription All nescessary class variables are declared and working!
2024-01-20 21:43:45,123 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_4cdfc852-515f-4342-bc7f-3f6d84461e30.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 21:43:45,126 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_70098e57-59ce-487c-9e3d-cc00b255bbea.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 21:43:45,164 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 21:43:45,165 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 21:43:45,238 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D1F310290>
2024-01-20 21:43:45,238 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024D7FD59A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 21:43:45,243 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D1F2F2FD0>
2024-01-20 21:43:45,243 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024D7FD59A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 21:43:45,261 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D1F310B90>
2024-01-20 21:43:45,262 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D1F3103D0>
2024-01-20 21:43:45,262 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:43:45,262 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:43:45,263 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 21:43:45,263 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 21:43:45,263 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 21:43:45,263 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 21:43:47,056 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 21:43:47,056 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:44:02,833 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 20:44:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'14157'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'bdec46f79769ec71c17c171609271712'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=rB.gE2jv0sLmUOc0ykv3MLm8EvA0GBxWBsNM30Al8uU-1705783440-1-ARX2rvJgXWFP/AYQHgWX/SmMM0FZSljcyS8OOGzU7JlAP6WjssuhMjJg53gOo6eS3z8bThwOnW4Xt4duxzCXp64=; path=/; expires=Sat, 20-Jan-24 21:14:00 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=BKUx2AkuO3b.QabjBJ9N1yEWM3CBeM8nGSp9kd37FM4-1705783440980-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848a26bc6ac2996f-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:44:02,835 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 21:44:02,835 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:44:02,836 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 21:44:02,836 DEBUG httpcore.http11 response_closed.started
2024-01-20 21:44:02,836 DEBUG httpcore.http11 response_closed.complete
2024-01-20 21:44:02,836 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 21:44:09,746 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 21:44:09,746 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:44:13,234 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 20:44:11 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'581'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4a6c251bd323f2424f2c632333b04c0c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=bcSd5BQU5FC7Z9eR8Hxcu9jtkex09Az4grVDImtlL4w-1705783451-1-AR4lGqEKm8OF6JSRCo2YCuCYU9MvCoI0gC/bPluuC7iMp+oYP8sxhdmykr/mZ3wjUjy/roqiPe5TI9OLtkgz1H8=; path=/; expires=Sat, 20-Jan-24 21:14:11 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=rsu_1tk.lplOVQvcFneYcAbt8fJ_krfFtYDj7Fv9pSo-1705783451384-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848a26bc68b52c36-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:44:13,235 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 21:44:13,235 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:44:13,236 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 21:44:13,236 DEBUG httpcore.http11 response_closed.started
2024-01-20 21:44:13,236 DEBUG httpcore.http11 response_closed.complete
2024-01-20 21:44:13,236 DEBUG httpcore.connection close.started
2024-01-20 21:44:13,236 DEBUG httpcore.connection close.complete
2024-01-20 21:44:13,236 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 21:44:13,236 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 21:44:13,238 DEBUG openai._base_client Not retrying
2024-01-20 21:44:13,238 DEBUG openai._base_client Re-raising status error
2024-01-20 21:44:13,239 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 21:44:13,252 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 21:44:13,259 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 21:44:13,259 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:44:13,260 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 21:44:13,261 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 21:44:13,261 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 21:44:13,261 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 21:44:13,261 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:44:13,287 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D1F39FFD0>
2024-01-20 21:44:13,287 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024D7FD59A30> server_hostname='api.openai.com' timeout=5.0
2024-01-20 21:44:13,310 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D1F39FF50>
2024-01-20 21:44:13,310 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:44:13,310 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 21:44:13,311 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 21:44:13,311 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 21:44:13,311 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:44:23,543 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 20:44:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'10081'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9124'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'5.256s'), (b'x-request-id', b'0b39b269c7d690a76e7eba05b15648d6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848a276b6c722c36-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:44:23,544 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 21:44:23,544 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:44:23,544 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 21:44:23,544 DEBUG httpcore.http11 response_closed.started
2024-01-20 21:44:23,544 DEBUG httpcore.http11 response_closed.complete
2024-01-20 21:44:23,544 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 21:44:28,037 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 20:44:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'14504'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'8289'), (b'x-ratelimit-reset-requests', b'17.206s'), (b'x-ratelimit-reset-tokens', b'10.264s'), (b'x-request-id', b'2649a5ec1569741ab9864ed729de858e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848a276bca249968-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:44:28,038 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 21:44:28,038 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:44:28,039 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 21:44:28,040 DEBUG httpcore.http11 response_closed.started
2024-01-20 21:44:28,040 DEBUG httpcore.http11 response_closed.complete
2024-01-20 21:44:28,040 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 21:45:32,985 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 21:45:32,987 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 21:45:33,228 INFO transcription All nescessary class variables are declared and working!
2024-01-20 21:46:23,101 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 21:46:23,103 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 21:46:23,351 INFO transcription All nescessary class variables are declared and working!
2024-01-20 21:48:06,237 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 21:48:06,238 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 21:48:06,471 INFO transcription All nescessary class variables are declared and working!
2024-01-20 21:48:11,127 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_01c3cbf9-2ec7-4385-b92c-49afc33e29f9.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 21:48:11,130 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_f76bf352-b599-4fc6-81c2-eeb791268eb6.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 21:48:11,171 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 21:48:11,171 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 21:48:11,309 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019452E79A10>
2024-01-20 21:48:11,309 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019452E5A390>
2024-01-20 21:48:11,309 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001944B88D760> server_hostname='api.openai.com' timeout=5.0
2024-01-20 21:48:11,309 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001944B88D760> server_hostname='api.openai.com' timeout=5.0
2024-01-20 21:48:11,324 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019452E79B50>
2024-01-20 21:48:11,324 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:48:11,325 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 21:48:11,325 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 21:48:11,346 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019452E79150>
2024-01-20 21:48:11,346 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:48:11,347 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 21:48:11,347 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 21:48:12,462 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 21:48:12,462 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:48:23,132 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 20:48:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'9319'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5a9e364c21fcc0a0360a2f6e613c7db6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=J6SX0IIP9Asf1VAbzXEvmMhxTJ62MaRk91k.7Uyl6_U-1705783701-1-AfGepHo4UTEvHM5ZWzVLxSjh1khYzQXLdD5jd/EraYsFPVS0ZDuKHPw4ieoy0/fDmzG4PmZfZ5vTs22elBkxlAc=; path=/; expires=Sat, 20-Jan-24 21:18:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Z6kdDvV5d4oqk_H.Fxub7z655ElZagLWn.Itl4mTmQU-1705783701277-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848a2d3b68922baf-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:48:23,133 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 21:48:23,134 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:48:23,134 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 21:48:23,134 DEBUG httpcore.http11 response_closed.started
2024-01-20 21:48:23,134 DEBUG httpcore.http11 response_closed.complete
2024-01-20 21:48:23,134 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 21:48:34,179 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 21:48:34,179 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:48:36,909 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 20:48:35 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'585'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'178bf75b23648609b87267de298c6980'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=5HMFcSk_2wq9tYoSrXIOyk4zdv5UlDIg2silL4ENWiA-1705783715-1-AXgnNhk4u2c8+ZspMiUofghRZJkSok9aYaWA41lwr73GTPBORZqIs1X+FEqPgu8UHr4Dk2Klxf/1tgTUIgCAkZc=; path=/; expires=Sat, 20-Jan-24 21:18:35 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=ExB_WeOccDvQ_nkTJbv33QPyg6iw5URWq.0fp1U.Oow-1705783715054-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848a2d3b4e6e1e68-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:48:36,910 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 21:48:36,910 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:48:36,910 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 21:48:36,910 DEBUG httpcore.http11 response_closed.started
2024-01-20 21:48:36,911 DEBUG httpcore.http11 response_closed.complete
2024-01-20 21:48:36,911 DEBUG httpcore.connection close.started
2024-01-20 21:48:36,911 DEBUG httpcore.connection close.complete
2024-01-20 21:48:36,911 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 21:48:36,911 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 21:48:36,913 DEBUG openai._base_client Not retrying
2024-01-20 21:48:36,913 DEBUG openai._base_client Re-raising status error
2024-01-20 21:48:36,913 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 21:48:36,926 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 21:48:36,933 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 21:48:36,933 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:48:36,934 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 21:48:36,934 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 21:48:36,934 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 21:48:36,935 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 21:48:36,935 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:48:36,954 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019452EFA7D0>
2024-01-20 21:48:36,954 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x000001944B88D760> server_hostname='api.openai.com' timeout=5.0
2024-01-20 21:48:36,974 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019452EFABD0>
2024-01-20 21:48:36,974 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 21:48:36,974 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 21:48:36,974 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 21:48:36,975 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 21:48:36,975 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 21:48:46,272 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 20:48:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'9141'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9124'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'5.256s'), (b'x-request-id', b'4110834f76601947e229934d492a0adc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848a2ddb5b7e1e68-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:48:46,273 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 21:48:46,273 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:48:46,274 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 21:48:46,274 DEBUG httpcore.http11 response_closed.started
2024-01-20 21:48:46,274 DEBUG httpcore.http11 response_closed.complete
2024-01-20 21:48:46,274 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 21:48:54,153 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 20:48:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'16978'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'8286'), (b'x-ratelimit-reset-requests', b'17.22s'), (b'x-ratelimit-reset-tokens', b'10.278s'), (b'x-request-id', b'cab625e12419061151142b96273d710c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848a2ddb9f3530d0-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 21:48:54,154 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 21:48:54,154 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 21:48:54,154 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 21:48:54,154 DEBUG httpcore.http11 response_closed.started
2024-01-20 21:48:54,154 DEBUG httpcore.http11 response_closed.complete
2024-01-20 21:48:54,155 DEBUG httpcore.connection close.started
2024-01-20 21:48:54,155 DEBUG httpcore.connection close.complete
2024-01-20 21:48:54,155 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 21:49:52,320 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 21:49:52,321 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 21:49:52,549 INFO transcription All nescessary class variables are declared and working!
2024-01-20 21:50:31,015 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 21:50:31,017 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 21:50:31,255 INFO transcription All nescessary class variables are declared and working!
2024-01-20 21:59:00,044 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 21:59:00,046 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 21:59:00,271 INFO transcription All nescessary class variables are declared and working!
2024-01-20 22:04:45,496 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:04:45,498 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 22:04:45,735 INFO transcription All nescessary class variables are declared and working!
2024-01-20 22:22:50,072 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:22:50,074 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 22:22:50,300 INFO transcription All nescessary class variables are declared and working!
2024-01-20 22:22:59,909 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_344de2b9-d3d0-4c74-90e6-cf460157eeb2.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 22:22:59,912 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='C:\\Users\\kai\\AppData\\Roaming\\TranscriptionApp\\TEMP\\temp_split_354eab4a-e779-4df0-8e76-3163a4caedfd.wav'>))], 'json_data': {'model': 'whisper-1'}}
2024-01-20 22:22:59,957 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 22:22:59,958 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 22:23:00,069 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020F6BFD0390>
2024-01-20 22:23:00,069 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F6452D880> server_hostname='api.openai.com' timeout=5.0
2024-01-20 22:23:00,087 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020F6BFD0410>
2024-01-20 22:23:00,087 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F6452D880> server_hostname='api.openai.com' timeout=5.0
2024-01-20 22:23:00,090 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020F6BFD08D0>
2024-01-20 22:23:00,090 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:23:00,091 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 22:23:00,091 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 22:23:00,100 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020F6BFD02D0>
2024-01-20 22:23:00,101 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:23:00,101 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 22:23:00,101 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 22:23:03,940 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 22:23:03,941 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:23:14,035 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 21:23:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'8840'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c1a2b5cedc3cd707e769a5ae819ca695'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=60sH0_WAbMv1Akuh0WCckyYqjAbC.TgPjEsfceGFb9o-1705785792-1-Ab2m2T9TxZOqwg0Dh9IJyGCdj7xl2hW3iX7RcfQ+Dql0N9EkdTEOOfUXVUYQnV6FbRtXDilY3PI6QeU4mM83VlE=; path=/; expires=Sat, 20-Jan-24 21:53:12 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=oc_JLm1CbpRi9pnqwGxDteoQq9egTeBckK.7WPmw2uA-1705785792140-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848a6039e8e9bbd4-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:23:14,037 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
2024-01-20 22:23:14,037 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:23:14,038 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 22:23:14,038 DEBUG httpcore.http11 response_closed.started
2024-01-20 22:23:14,038 DEBUG httpcore.http11 response_closed.complete
2024-01-20 22:23:14,038 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
2024-01-20 22:23:26,289 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 22:23:26,289 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:23:29,854 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 413, b'Payload Too Large', [(b'Date', b'Sat, 20 Jan 2024 21:23:27 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'171'), (b'Connection', b'keep-alive'), (b'openai-processing-ms', b'619'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8614265c2f243bdf081e74258bd4cf2b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=bqw4kDSV.bkNkdtICn0KqX46OG323XJMdOLPc2C8ppw-1705785807-1-AZNZokQ+IWGAuJh/m0qLCZQvbMCRoS0DRdfqbwRC5aSfw+BAUEl4f5Ka+vC4EfXVzVgEXaRt/7hUCpLeYvE/Lm4=; path=/; expires=Sat, 20-Jan-24 21:53:27 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=rHinRzkUosuo9f2YuCNDQ6DFimgu0cj0i7O2DCQMkOA-1705785807959-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848a6039de485d42-FRA'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:23:29,855 INFO httpx HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 413 Payload Too Large"
2024-01-20 22:23:29,855 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:23:29,856 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 22:23:29,856 DEBUG httpcore.http11 response_closed.started
2024-01-20 22:23:29,856 DEBUG httpcore.http11 response_closed.complete
2024-01-20 22:23:29,856 DEBUG httpcore.connection close.started
2024-01-20 22:23:29,856 DEBUG httpcore.connection close.complete
2024-01-20 22:23:29,856 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "413 Payload Too Large"
2024-01-20 22:23:29,856 DEBUG openai._base_client Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\openai\_base_client.py", line 926, in _request
    response.raise_for_status()
  File "d:\Documents\5__Work\venvs\TranscriptionAI\Lib\site-packages\httpx\_models.py", line 759, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '413 Payload Too Large' for url 'https://api.openai.com/v1/audio/transcriptions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/413
2024-01-20 22:23:29,858 DEBUG openai._base_client Not retrying
2024-01-20 22:23:29,858 DEBUG openai._base_client Re-raising status error
2024-01-20 22:23:29,858 ERROR transcription Error transcribing file part 0: Error code: 413 - {'error': {'message': 'Maximum content size limit (26214400) exceeded (26214707 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}
2024-01-20 22:23:29,871 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create highly detailed keynotes from each text you are provided with but still summarizing the complete text. Your output will always be a summary in the form of bulletpoints of the text.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your keynotes: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 22:23:29,878 DEBUG openai._base_client Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You will always respond in German! You are a specialised assistant very proficient in collecting every bit of important information from a text. You will create a highly detailed protocol of the provided Meeting Transcript.'}, {'role': 'user', 'content': 'This will be your basis on which you will create your protcol: \nOhne Scheiß, also bis zum Umfallen, bis zum Umfallen. Man denkt immer, irgendwo ist dann ein Ende, aber eine andere Perspektive auf einmal... Genau, und es geht los. Und da sind wir auch schon beim Thema, weil ich überlege nämlich wirklich, dass man vielleicht noch eine weitere Person in der Werkstatt hat, weil der Atkins macht sich sehr, sehr, sehr gut, muss ich sagen, in Sachen auch Projekte mit Staaten so jetzt auch, um dann auch einen Überblick gut behalten. Armando ist eh unantastbar, unantastbar. Wir haben den Diogo, das ist ein neuer Mitarbeiter in der Werkstatt, Kundenarbeit. Aber ich überlege, ob wir noch einen weiteren Mechaniker uns holen für auch Projektautos. Dann können wir nämlich wirklich nochmal anders, schneller, besser machen. Und da sehe ich nämlich auch eine hohe Entlastung für mich dann auch, weil ganz oft ist da ja die Achillesferse, die wir haben. Du musst lehnen, du willst lehnen, aber... Ich kann nicht. Die Jungs kommen nicht, weil die halt alle Projekte... Was ja ganz normal ist. Und ich denke, dass wenn wir das machen, dass wir da nochmal für alle Mann eine bessere Qualität haben, auch für euch, Material. Und das ist, denke ich mal, noch ein weiterer Schuss, den wir dort machen müssen. Also das Jahr steht auch ganz groß unter dem Thema Investieren. Dieses Jahr investieren wir... Dieses Jahr investieren wir als Unternehmen 3 Millionen, 3,2 Millionen Euro. Dieses Jahr. Mehr? Ich würde sagen, vielleicht sogar mehr. Ja? 3,5? Aber dann würde ich ja wirklich die Bremse ziehen. Dreieinhalb so, dreieinhalb mit Tendenz zu vier, würde ich sagen, könnte man schon. Und das ist, also investieren bedeutet, dass dieses Geld ist dann einfach... Genau. Das ist halt, das ist nicht weg. Das ist nur woanders, sag ich immer. Das Geld ist doch nur woanders. Und da ist kein Auto bei, da ist nichts bei, sondern das ist einfach nur, was für euch ist. Natürlich ist es der Wert des Unternehmens trägt es natürlich bei. Und der Instandhaltung der Gebäude und all sowas. Und Erweiterung auch natürlich. Aber das ist natürlich schon echt viel Geld. Aber ich bin ein... Ich bin ein Geschäftsführer, der gerne investiert, muss ich echt sagen. Oder? Ich war nie... Also ich bin schon gerne am Investieren. Und wenn du weißt, dass es was Sinnvolles ist, wo wir dann auch alle was von haben, also jetzt keine Investitionen, wo man sagt, einfach mal Kohle raushauen. Nö. Das ist auf jeden Fall nicht abgedeckt, ne? Nö, das stimmt. Okay, wir wünschen euch ein wunderschönes Wochenende. Morgen gibt es auch ein Video, wo wir ein Thema abschließen, was sehr lange gedauert hat. Wo wir uns auch ganz, ganz, ganz groß entschuldigen müssen bei der Firma, wo wir da morgen mit zusammengearbeitet haben, weil das wirklich nicht gut gelaufen ist. Da lief einiges schief. Aber nicht auf deren Seite, sondern eher auf allen anderen Seiten. Auf unserer und auf Lieferantenseite teilweise. Ja, deswegen. War blöd. Aber wir finden eBay trotzdem cool. Okay, bis morgen, tschüss.'}], 'model': 'gpt-4'}}
2024-01-20 22:23:29,878 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:23:29,879 DEBUG httpcore.connection connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-01-20 22:23:29,880 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 22:23:29,880 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 22:23:29,880 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 22:23:29,880 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:23:29,901 DEBUG httpcore.connection connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020F6C070410>
2024-01-20 22:23:29,901 DEBUG httpcore.connection start_tls.started ssl_context=<ssl.SSLContext object at 0x0000020F6452D880> server_hostname='api.openai.com' timeout=5.0
2024-01-20 22:23:29,921 DEBUG httpcore.connection start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020F6C070850>
2024-01-20 22:23:29,921 DEBUG httpcore.http11 send_request_headers.started request=<Request [b'POST']>
2024-01-20 22:23:29,922 DEBUG httpcore.http11 send_request_headers.complete
2024-01-20 22:23:29,922 DEBUG httpcore.http11 send_request_body.started request=<Request [b'POST']>
2024-01-20 22:23:29,922 DEBUG httpcore.http11 send_request_body.complete
2024-01-20 22:23:29,922 DEBUG httpcore.http11 receive_response_headers.started request=<Request [b'POST']>
2024-01-20 22:23:43,449 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 21:23:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'13311'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9124'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'5.256s'), (b'x-request-id', b'c46ad92a3f382772ec00094a62103908'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848a60f40a625d42-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:23:43,450 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 22:23:43,450 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:23:43,451 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 22:23:43,451 DEBUG httpcore.http11 response_closed.started
2024-01-20 22:23:43,451 DEBUG httpcore.http11 response_closed.complete
2024-01-20 22:23:43,451 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 22:23:50,634 DEBUG httpcore.http11 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Jan 2024 21:23:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b's-dvers-service-und-management-gmbh'), (b'openai-processing-ms', b'20520'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'8279'), (b'x-ratelimit-reset-requests', b'17.263s'), (b'x-ratelimit-reset-tokens', b'10.321s'), (b'x-request-id', b'8becfc7f22d99d4f0f081f65daadae61'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'848a60f4491b4dc4-FRA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-01-20 22:23:50,634 INFO httpx HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-01-20 22:23:50,635 DEBUG httpcore.http11 receive_response_body.started request=<Request [b'POST']>
2024-01-20 22:23:50,635 DEBUG httpcore.http11 receive_response_body.complete
2024-01-20 22:23:50,635 DEBUG httpcore.http11 response_closed.started
2024-01-20 22:23:50,635 DEBUG httpcore.http11 response_closed.complete
2024-01-20 22:23:50,635 DEBUG httpcore.connection close.started
2024-01-20 22:23:50,635 DEBUG httpcore.connection close.complete
2024-01-20 22:23:50,636 DEBUG openai._base_client HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-01-20 22:27:14,469 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:27:14,471 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 22:27:14,704 INFO transcription All nescessary class variables are declared and working!
2024-01-20 22:28:04,484 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:28:04,486 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 22:28:04,718 INFO transcription All nescessary class variables are declared and working!
2024-01-20 22:28:38,468 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:28:38,470 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 22:28:38,697 INFO transcription All nescessary class variables are declared and working!
2024-01-20 22:29:28,739 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:29:28,741 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 22:29:28,975 INFO transcription All nescessary class variables are declared and working!
2024-01-20 22:35:10,449 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:35:10,450 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 22:35:10,678 INFO transcription All nescessary class variables are declared and working!
2024-01-20 22:36:35,177 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:36:35,178 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 22:36:35,412 INFO transcription All nescessary class variables are declared and working!
2024-01-20 22:47:26,375 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:47:26,376 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 22:47:26,623 INFO transcription All nescessary class variables are declared and working!
2024-01-20 22:48:01,299 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:48:01,301 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 22:48:01,533 INFO transcription All nescessary class variables are declared and working!
2024-01-20 22:54:27,528 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:54:27,529 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 22:54:27,761 INFO transcription All nescessary class variables are declared and working!
2024-01-20 22:55:06,259 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:55:06,261 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 22:55:06,488 INFO transcription All nescessary class variables are declared and working!
2024-01-20 22:59:52,292 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 22:59:52,294 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 22:59:52,523 INFO transcription All nescessary class variables are declared and working!
2024-01-20 23:00:22,020 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 23:00:22,022 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 23:00:22,254 INFO transcription All nescessary class variables are declared and working!
2024-01-20 23:00:42,194 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 23:00:42,195 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 23:00:42,433 INFO transcription All nescessary class variables are declared and working!
2024-01-20 23:01:27,629 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 23:01:27,631 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 23:01:27,890 INFO transcription All nescessary class variables are declared and working!
2024-01-20 23:02:23,509 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 23:02:23,511 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 23:02:23,749 INFO transcription All nescessary class variables are declared and working!
2024-01-20 23:18:13,722 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 23:18:13,723 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 23:18:13,969 INFO transcription All nescessary class variables are declared and working!
2024-01-20 23:19:49,268 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 23:19:49,270 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 23:19:49,512 INFO transcription All nescessary class variables are declared and working!
2024-01-20 23:44:08,710 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-20 23:44:08,712 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-20 23:44:08,946 INFO transcription All nescessary class variables are declared and working!
2024-01-26 10:56:28,300 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-26 10:56:28,320 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-26 10:56:28,704 INFO transcription All nescessary class variables are declared and working!
2024-01-26 10:57:40,318 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-26 10:57:40,320 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-26 10:57:40,555 INFO transcription All nescessary class variables are declared and working!
2024-01-26 12:46:41,652 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-26 12:46:41,653 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-26 12:46:41,908 INFO transcription All nescessary class variables are declared and working!
2024-01-26 13:14:12,448 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-26 13:14:12,450 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-26 13:14:12,664 INFO transcription All nescessary class variables are declared and working!
2024-01-26 13:17:59,037 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-26 13:17:59,038 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-26 13:17:59,270 INFO transcription All nescessary class variables are declared and working!
2024-01-26 13:18:17,436 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-26 13:18:17,438 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-26 13:18:17,674 INFO transcription All nescessary class variables are declared and working!
2024-01-26 13:18:30,547 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-26 13:18:30,549 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-26 13:18:30,780 INFO transcription All nescessary class variables are declared and working!
2024-01-26 13:19:01,610 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-26 13:19:01,611 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-26 13:19:01,833 INFO transcription All nescessary class variables are declared and working!
2024-01-29 08:29:15,061 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-29 08:29:15,073 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-29 08:29:15,365 INFO transcription All nescessary class variables are declared and working!
2024-01-29 15:50:36,293 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-29 15:50:36,298 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-29 15:50:36,578 INFO transcription All nescessary class variables are declared and working!
2024-01-29 16:08:13,654 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-29 16:08:13,656 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-29 16:08:13,928 INFO transcription All nescessary class variables are declared and working!
2024-01-29 16:12:39,929 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-29 16:12:39,931 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-29 16:12:40,203 INFO transcription All nescessary class variables are declared and working!
2024-01-29 16:14:11,132 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-29 16:14:11,134 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-29 16:14:11,414 INFO transcription All nescessary class variables are declared and working!
2024-01-29 16:17:16,321 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-29 16:17:16,322 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-29 16:17:16,606 INFO transcription All nescessary class variables are declared and working!
2024-01-29 16:26:44,602 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-29 16:26:44,604 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-29 16:26:44,884 INFO transcription All nescessary class variables are declared and working!
2024-01-29 16:30:30,309 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-29 16:30:30,311 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-29 16:30:30,604 INFO transcription All nescessary class variables are declared and working!
2024-01-29 16:47:44,216 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-29 16:47:44,218 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-29 16:47:44,521 INFO transcription All nescessary class variables are declared and working!
2024-01-29 16:51:02,405 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-29 16:51:02,406 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-29 16:51:02,688 INFO transcription All nescessary class variables are declared and working!
2024-01-29 16:51:56,772 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-29 16:51:56,774 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-29 16:51:57,057 INFO transcription All nescessary class variables are declared and working!
2024-01-29 16:52:43,260 DEBUG httpx load_ssl_context verify=True cert=None trust_env=True http2=False
2024-01-29 16:52:43,262 DEBUG httpx load_verify_locations cafile='d:\\Documents\\5__Work\\venvs\\TranscriptionAI\\Lib\\site-packages\\certifi\\cacert.pem'
2024-01-29 16:52:43,533 INFO transcription All nescessary class variables are declared and working!
